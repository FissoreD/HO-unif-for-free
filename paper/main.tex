\documentclass[sigconf,natbib=false,review]{acmart}
\usepackage[]{biblatex}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
\addbibresource{bib.bib}

\usepackage{myTools}
\usepackage{macros}
\usepackage{enumitem}
\usepackage{intcalc}
\usepackage{nameref}

% TODO: set this fields
%\setcopyright{cc}
%\setcctype{by}
%\copyrightyear{2024}
%\acmYear{XXXX 2024}
%\acmBooktitle{YYY}
%\acmDOI{ZZZZZZZZZZZZ}

\def\githubUrl{\url{https://github.com/FissoreD/ho-unif-for-free}}

% \xspaceaddexceptions{]\}}

\def\elpi{\proglang{elpi}}
\def\coqelpi{\proglang{coq-elpi}}
\def\lambdaprolog{\proglang{$\lambda$-prolog}}
\def\coq{\proglang{coq}}

\newcommand{\library}[1]{\textit{#1}\xspace}
\def\stdpp{\library{stdpp}}
\def\iris{\library{iris}}

\newcommand*{\acronym}[1]{\texttt{#1}\xspace}

\newtheorem{invariant}{Invariant}
\crefname{invariant}{invariant}{invariants}
\crefname{equation}{property}{properties}


\def\ol{\acronym{ol}} % object language
\def\ml{\acronym{ml}} % meta language
\def\lf{\acronym{lf}} % logical framework
\def\ho{\acronym{ho}} % higher order
\def\Forall{$\forall$}

\newcommand{\appsep}{\ensuremath{\textcolor{lightgray}{\cdot}}}
\newcommand{\EqualRel}{\ensuremath{=}}
\newcommand{\nEqualRel}{\ensuremath{\new}}
\newcommand{\UnifRel}{\ensuremath{\simeq}}
\newcommand{\nUnifRel}{\ensuremath{\not\simeq}}

\newcommand{\Uo}{\texorpdfstring{\ensuremath{\UnifRel_o}\xspace}{unif\_o}}
\newcommand{\nUo}{\ensuremath{\nUnifRel_o}\xspace}
\newcommand{\Eo}{\ensuremath{\EqualRel_o}\xspace}
\newcommand{\nEo}{\ensuremath{\nEqualRel_o}\xspace}

\newcommand{\Ue}{\ensuremath{\UnifRel_\lambda}\xspace}
\newcommand{\nUe}{\ensuremath{\nUnifRel_\lambda}\xspace}
\newcommand{\Ee}{\ensuremath{\EqualRel_\lambda}\xspace}
\newcommand{\nEe}{\ensuremath{\nEqualRel_\lambda}\xspace}
\newcommand{\llambda}{\ensuremath{\mathcal{L}}\xspace}

\newcommand{\linkMacro}[1]{\ensuremath{#1}\texttt{-link}\xspace}

\newcommand{\linkbeta}{\linkMacro{\llambda}}
\newcommand{\linketa} {\linkMacro{\eta}}

\newcommand{\Fo}{\texorpdfstring{\ensuremath{\mathcal{F}_{\!o}\xspace}}{Fo}} % space non va
\newcommand{\Ho}{\texorpdfstring{\ensuremath{\mathcal{H}_o}\xspace}{Ho}}

\newcommand*{\eqtau}{\ensuremath{\mathrel{\overset{\mathrm{\tau}}{=}}}}

\newcommand{\linketaM}[3]{\ensuremath{#1 \vdash #2 =_\eta #3}}
\newcommand{\linkbetaM}[3]{\ensuremath{#1 \vdash #2 =_{\llambda} #3}}
\newcommand{\substCell}[3]{\ensuremath{#1 \vdash #2 = #3}}
\newcommand{\mapping}[3]{\ensuremath{#1 \mapsto #2^#3}}

\newcommand{\lhs}{lhs\xspace}
\newcommand{\rhs}{rhs\xspace}

\newcommand{\linkStore}{\texorpdfstring{\ensuremath{\mathbb{L}}\xspace}{L}}
\newcommand{\mapStore}{\texorpdfstring{\ensuremath{\mathbb{M}}\xspace}{M}}
\newcommand{\foUnifPb}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\hoUnifPb}{\ensuremath{\mathbb{T}}\xspace}

\include{pb_printer}

\begin{document}

% \title{HO unification from object language to meta language}
\title{Higher-Order unification for free!}
\subtitle{Reusing the meta-language unification for the object language}

\author{Davide Fissore}
\email{davide.fissore@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\author{Enrico Tassi}
\email{enrico.tassi@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\begin{abstract}
  Specifying and implementing a proof system from scratch requires significant effort.
  Logical Frameworks and Higher Order Logic Programming Languages provide
  dedicated, high-level Meta Languages (ML) to facilitate this task in two
  key ways: 1) variable binding and substitution are for free when ML binders
  represent object logic ones; 2) proof construction, and even proof search, is
  greatly simplified by leveraging the unification procedure provided by the ML.
  Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
  $\lambda$Prolog~\cite{miller_nadathur_2012} and
  Isabelle~\cite{10.1007/978-3-540-71067-7_7}
  which have been utilized to implement various formal systems such as
  First Order Logic~\cite{felty88cade},
  Set Theory~\cite{10.1007/BF00881873},
  Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
  Constructions~\cite{felty93lics}.

  The object logic we are interested in is % an extension of the latter,
  Coq's~\cite{Coq-refman} Calculus of Inductive Constructions (CIC), for which 
  we want to implement a higher-order unification-based 
  proof search procedure using the ML
  Elpi~\cite{dunchev15lpar}, a dialect of $\lambda$Prolog.
  Elpi's equational theory comprises
  $\eta\beta$ equivalence and comes equipped with a
  higher-order unification procedure \Ue restricted to the pattern
  fragment~\cite{miller92jsc}.
  Elpi comes with an encoding of CIC that works well
  for meta-programming~\cite{tassi:hal-01637063,tassi:hal-01897468,gregoire:hal-03800154,newtc}
  but restricts \Ue to roughly first-order unification problems only.
  We call this basic encoding \Fo.
  
  In this paper we propose a better-behaved encoding \Ho,
  and show how to map unification problems in \Fo{}
  to related problems in \Ho.
    As a result we obtain \Uo{}, a higher-order unification procedure for \Fo{}
    that honours $\eta\beta$-equivalence (for CIC functions), solves
  problems in the pattern fragment and allows
  for the use of heuristics to deal with problems outside the
  pattern fragment. Moreover, since \Uo{} delegates most of the work to \Ue,
  it can be used to efficiently simulate a logic program in \Fo{} by
  taking advantage of
  unification-related optimizations of the ML, such as clause indexing.

\end{abstract}

\keywords{Logic Programming, Meta-Programming, Higher-Order Unification, Proof Automation}

\maketitle

\section{Introduction}
\label{sec:intro}

Meta languages such as Elf~\cite{elf}, Twelf~\cite{twelf},
$\lambda$Prolog~\cite{miller_nadathur_2012} and
Isabelle~\cite{10.1007/978-3-540-71067-7_7}
have been utilized to specify various
logics~\cite{felty88cade,books/sp/NipkowPW02,10.1007/BF00881873,felty93lics}.
The use of these meta languages facilitates this task in two
key ways. The first and most well know one is that variable binding and
substitution come for free. %, exploited in all works mentioned above.
The second one is that these meta languages come equipped with some form
of unification, a cornerstone of proof construction and proof search.

% exploited only
%in the notable case of of Higher Order Logic~\cite{books/sp/NipkowPW02}:
%the meta language Isabelle is such a good match for HOL that it could used to
%implement an interactive proof system for the object logic, in addition to
%it specification.\\
The object logic we are interested in is Coq's~\cite{Coq-refman}
Calculus of Inductive Constructions (CIC) and we want to implement a
form of proof search known as type-class~\cite{wadler89,sozeau08} resolution.
Type-class solvers are unification based proof search procedures
reminiscent of Prolog that back-chain lemmas taken
from a database of ``type-class instances''. Given this
analogy with Logic Programming we want to leverage the
Elpi~\cite{tassi:hal-01637063} meta programming language,
a dialect of $\lambda$Prolog, already used to extend
Coq in various ways~\cite{tassi:hal-01637063,tassi:hal-01897468,gregoire:hal-03800154,newtc}.
In this paper we focus on one aspect of
this work, precisely \emph{how to reuse the higher-order unification procedure
of the meta language in order to simulate a higher-order logic program
for the object language}.

We take as an example the \coqIn{Decision} and \coqIn{Finite} type classes
from the Stdpp~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
library. The class  \coqIn{Decision}
identifies predicates equipped with a decision procedure, while
\coqIn{Finite} the types whose inhabitants can be enumerated in a (finite) list.
The following three type-class instances state that:
1) the type of natural numbers smaller than \coqIn{n}, called \coqIn{fin n},
is finite;
2) the predicate \coqIn{nfact n nf}, relating a natural number
\coqIn{n} to the number of its prime factors \coqIn{nf}, is decidable;
3) the universal closure of a predicate has a decision procedure if
its domain is finite and if the predicate is decidable.

\begin{coqcode}
Instance fin_fin: ~$\forall$~n, Finite (fin n).             (* r1 *)
Instance nfact_dec: ~$\forall$~n nf, Decision (nfact n nf). (* r2 *)
Instance forall_dec: ~$\forall$~A P, Finite A ~$\to$~            (* r3 *)
  ~$\forall$~x:A, Decision (P x) ~$\to$~ Decision (~$\forall$~x:A, P x).
\end{coqcode}

\noindent Given this database a type-class solver is expected to
prove the following statement automatically:

\begin{coqcode}
  Decision (~$\forall$~x: fin 7, nfact x 3)                   (* g *)
\end{coqcode}

\noindent
The proof found by the solver back-chains on rule 3 (the only rule
about the $\forall$ quantifier), and then solves the premises with
rules 1 and 2 respectively.
Note that rule 3 features a second order parameter \coqIn{P} that stands for
a function of type \coqIn{A ~$\to$~ Prop} (a predicate over \coqIn{A}).
The solver has to infer a value for \coqIn{P} by unifying the conclusion
of rule 3 with the goal, and in particular it has to solve the unification
problem \coqIn{P x = nfact x 3}. This higher order problem falls in the so
called pattern-fragment \llambda~\cite{miller92jsc} and admits a unique
solution $\customlabel{solution:intro}{\rho}$ that assigns
the term \elpiIn{~$\lambda$~x.nfact x 3} to \coqIn{P}.

In order to implement such a search in Elpi we shall describe the encoding
of CIC terms and then the encoding of instances as rules.
Elpi comes equipped with
an Higher Order Abstract Syntax (HOAS~\cite{10.1145/53990.54010}) datatype of CIC
terms, called \elpiIn{tm}, that features (among others) the following
constructors:

\begin{elpicode}
type lam  tm -> (tm -> tm) -> tm.     % lambda abstraction
type app  list tm -> tm.              % n-ary application
type all  tm -> (tm -> tm) -> tm.     % forall quantifier
type con  string -> tm.               % constants
\end{elpicode}

\noindent
Following the standard syntax of $\lambda$Prolog~\cite{miller_nadathur_2012}
the meta level binding of a variable \elpiIn{x} in an expression
\elpiIn{e} is written <<\elpiIn{x\ e}>>, while square brackets delimit a
list of terms separated by comma. For example the term
<<\coqIn{~$\forall$~y:t, nfact y 3}>> is encoded as follows:

\begin{elpicode}
all (con"t") y\ app [con"nfact", y, con"3"]
\end{elpicode}

\noindent
We now illustrate the encoding of the three instances above as higher-order
logic-programming rules: capital letters denote rule
parameters; \elpiIn{:-} separates the rule's head from the premises and
\elpiIn{pi w\ p} introduces a fresh nominal constant \elpiIn{w}
for the premise \elpiIn{p}.

\begin{elpicode}
finite   (app [con"fin", N]).                         ~\customlabel{clause:r1}{(r1)}~
decision (app [con"nfact", N, NF]).                   ~\customlabel{clause:r2}{(r2)}~
decision (all A x\ app [P, x]) :- finite A,           ~\customlabel{clause:r3}{(r3)}~
  pi w\ decision (app [P, w]).
\end{elpicode}

\noindent
Unfortunately this intuitive encoding of rule \ref{clause:r3} does not work
since it uses the predicate \coqIn{P} as a first order term: for the meta
language its type is \elpiIn{tm}. If we try to back-chain the rule
\ref{clause:r3} on the encoding of the goal \ref{goal:g} given below

\begin{elpicode}
decision (all (app [con"fin", con"7"]) x\              ~\customlabel{goal:g}{(g)}~
  app [con"nfact", x, con"3"]).
\end{elpicode}

\noindent
we obtain an unsolvable unification problem \ref{problem:p}:
the two lists of terms have different lengths!
%The root cause is that
%\ref{problem:p} is an higher order in CIC, but becomes
%first order in the meta language due to the ``naive'' encoding.

\begin{elpicode}
app [con"nfact", x, con"3"] = app [P, x]               ~\customlabel{problem:p}{(p)}~
\end{elpicode}

\noindent
In this paper we study a more sophisticated encoding of CIC terms and rules
that, on a first approximation, would reshape \ref{clause:r3} as follows:

\begin{elpicode}
decision (all A x\ Pm x) :- link Pm P A, finite A,    ~\customlabel{clause:r3a}{(r3')}~
  pi x\ decision (app [P, x]).
\end{elpicode}

\noindent
Since \elpiIn{Pm} is an higher-order unification variable
of type \elpiIn{tm -> tm},
with \elpiIn{x}
in its scope, the unification problem \ref{problem:pa}
admits one solution:

\begin{elpicode}
app [con"nfact", x, con"3"] = Pm x                    ~\customlabel{problem:pa}{(p')}~
Pm = x\ app [con"nfact", x, con"3"]                   ~\customlabel{solution:pm}{(\sigma)}~
\end{elpicode}

\noindent
Once the head of rule \ref{clause:r3a} unifies with the goal \ref{goal:g}
the premise <<\elpiIn{link Pm A P}>> brings the assignment \ref{solution:pm}
back to the domain \elpiIn{tm} of Coq terms, obtaining the expected solution
\ref{solution:intro}:

\begin{elpicode}
P = lam A x\ app [con"nfact", x, con"3"]
\end{elpicode}

\noindent
This simple example is sufficient to show that the encoding we seek
is not trivial and does not only concern the head of rules, but the entire sequence
of unification problems that constitute the execution of a logic program.
In fact
the solution for \elpiIn{P} above generates a
(Coq) $\beta$-redex in the second premise (the predicate
under the \elpiIn{pi w\ }\hspace{-0.4em}).
% We show below the premise before and
% after the instantiation of \elpiIn{P}:

% \begin{elpicode}
% decision (app [                   P                  , w])
% decision (app [lam A (a\ app [con"nfact", a, con"3"]), w])
% \end{elpicode}

% \noindent
In turn this redex prevents the rule \ref{clause:r2} to backchain properly since
the following unification problem has no solution:

\begin{elpicode}
app [ lam A (a\ app [con"nfact", a, con"3"]) , x] =
app [ con"nfact"                             , N, NF]
\end{elpicode}

\noindent
The root cause of the problems we sketched in this example
is a subtle mismatch between the equational theories of the meta language
and the object language, that in turns makes the 
unification procedures of the meta language weak.
The equational theory of the meta language Elpi encompasses
$\eta\beta$-equivalence and its unification procedure can solve higher-order
problems in the pattern fragment. Although 
the equational theory of CIC is much richer, for efficiency and predictability
reasons automatic proof search procedure typically employ a unification
procedure that only captures a $\eta\beta$-equivalence and only operates
in \llambda. The similarity is striking, but one needs some care in order to
simulate a logic program in CIC using the unification of Elpi.

\paragraph{Contributions}
In this paper we identify a minimal language \Fo{} in which the problems
sketched in the introduction can be formally described.
We detail an encoding of a logic program in \Fo{} to a strongly related
logic program in \Ho (the language of the meta-language) and we show that
the higher-order unification procedure of the meta language \Ue{} can be
efficiently used to simulate a higher-order unification procedure \Uo for
the object language that features $\eta\beta$-conversion. We show how \Uo
can be extended with heuristics to deal with problems outside the pattern
fragment.\\
Section~\ref{sec:problem-statement} formally states the problem and gives the
intuition behind our solution; \cref{sec:simulation} sets up a basic
simulation of first-order logic programs, \cref{sec:llam} and \cref{sec:eta}
extend it to higher-order logic programs in the pattern fragment
while \cref{sec:beta} goes beyond the pattern fragment.
Section \ref{sec:implementation} discusses the implementation in Elpi.\\
The $\lambda$Prolog code discussed in the paper can be accessed at the
address \githubUrl.

\section{Problem statement and solution} %%%%%%%%%%%%%%%%%%%%%%
\label{sec:problem-statement}

\newcommand{\specunif}[3]{
  \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    \exists \rho, %
      \rho #3_1 #1 \rho #3_2  %
        \Leftrightarrow #3_1 #2 #3_2 \mapsto \rho' \subseteq \rho
}


\newcommand{\unifcorrect}[3]{
  % \forall \rho #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    \{#3_1, #3_2\} \subseteq \llambda \Rightarrow
      #3_1 #2 #3_2 \mapsto \rho
        \Rightarrow
          \rho #3_1 #1 \rho #3_2  %
}

\newcommand{\unifcomplete}[3]{
  % \forall #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    \{#3_1, #3_2\} \subseteq \llambda \Rightarrow
      % \forall \rho, %
        \rho #3_1 #1 \rho #3_2  %
          \Rightarrow \exists \rho', #3_1 #2 #3_2 \mapsto \rho' \land \rho' \subseteq \rho
}
\newcommand{\maybeeta}{\texorpdfstring{\ensuremath{\Diamond\eta}\xspace}{maybeeta}}
\newcommand{\maybebeta}{\texorpdfstring{\ensuremath{\Diamond\beta_0}\xspace}{maybebeta}}
\newcommand{\notllambda}{\texorpdfstring{\ensuremath{\Diamond\llambda}\xspace}{maybellam}}
%\newcommand{\notllambda}{\ensuremath{\Diamond\beta}\xspace}

Even if we encountered the problem working on CIC we devise
a minimal setting to ease its study. In this setting we have
a \Fo{} language (for first order) with a rich equational
theory and a \Ho{} meta language with a simpler one.


\subsection{Preliminaries: \Fo{} and \Ho{}}

In order to reason about unification we provide a description of the
\Fo{} and \Ho languages where unification variables
are first class terms, i.e. they have a concrete syntax as
per \cref{code:common-terms}.
% We keep these languages
%minimal, for example, we omit the \elpiIn{all} quantifier of CIC we used
%in the example in Section~\ref{sec:intro} together with the type notation of
%terms carried by the \elpiIn{lam} constructor.
%
{
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-13pt}
\begin{figure}[b] %[H]
  \begin{tabular}{ll}
  \begin{minipage}{0.21\textwidth}
   \inputrawelpicode{code/fo_tm}
  \end{minipage}
  &
  \begin{minipage}{0.24\textwidth}
   \inputrawelpicode{code/ho_tm}
  \end{minipage}
  \end{tabular}\vspace{4pt}
  \caption{The \Fo{} and \Ho languages}\vspace{0.3em}
  \label{code:common-terms}
  \Description[code:common-terms]{code:common-terms}
\end{figure}
}
Unification variables
in \Fo{} (\elpiIn{fuva} term constructor) have no explicit scope:
the arguments of an higher order variable are given via the \elpiIn{fapp}
constructor. For example the term <<\coqIn{P x}>> is represented as
<<\elpiIn{fapp [fuva N, x]}>>, where \elpiIn{N} is the memory address
of \elpiIn{P} and \elpiIn{x} is a bound variable.\\
In \Ho the representation of <<\coqIn{P x}>> is instead <<\elpiIn{uva N [x]}>>,
since unification variables are higher order and come equipped with an
explicit scope.
%\todo{use faddr for Fo}
%
%faddr and addr are memory addresses, the details are given in bla,
%here they are just unique identifiers for unif variables and their types
%do now allow to mistake one for the other.
%\todo{cleanup}

\paragraph{Notational conventions}

When we write \Ho terms outside code blocks we follow the
usual $\lambda$-calculus notation, reserving $f, g, a, b$ for constants,
$x, y, z$ for bound variables and $X, Y, Z, F, G, H$ for unification variables.
However we need to
distinguish between the ``application'' of a unification variable
to its scope and the application of a term to a list of arguments.
We write the scope of unification variables in subscript
while we use juxtaposition for regular application.
Here a few examples:\\
\vspace{4pt}
{
\setlength{\tabcolsep}{1em}
\begin{tabular}{ll}
  $f\appsep a$                  & \elpiIn{app [con "f", con "a"]}\\
  $\lambda x.\lambda y.F_{x y}$ & \elpiIn{lam x\ lam y\ uva F [x, y]} \\
  $\lambda x.F_{x} \appsep a$   & \elpiIn{lam x\ app [uva F [x], con "a"]} \\
  $\lambda x.F_{x} \appsep x$   & \elpiIn{lam x\ app [uva F [x], x]} \\
\end{tabular}
}
\vspace{4pt}

\noindent
When it is clear from the context we shall use the same syntax for \Fo{} terms
(although we never subscripts unification variables).\\
We use $s$, $s_1$, \ldots for terms in \Fo{} and $t$, $t_1$ \ldots for
terms in \Ho{}.

\subsection{Equational theories an unification}

In order to specify unification we need to
define the equational theory and
substitution (unification-variable assignment).

\subsubsection{Term equality: \Eo and \Ee}
For both languages we extend the equational theory
over ground terms to the full language by adding the reflexivity of
unification variables (a variable is equal to itself).

The first four rules are common to both equalities
and define the usual congruence over terms. Since
we use an HOAS encoding they also capture $\alpha$-equivalence.
In addition to that \Eo has rules for $\eta$ and $\beta$-equivalence.

\input{code/feq}

\begin{elpicode}
  ~\PYG{k+kd}{type} \PYG{n+nf}{(\Ee)} \PYG{k+kt}{tm -> tm -> o}~.
  con C ~\Ee~fcon C.
  app A ~\Ee~fapp B :- forall2 ~(\Ee)~ A B.
  lam F ~\Ee~flam G :- pi x\ x ~\Ee~x => F x ~\Ee~G x.
  uva N A ~\Ee~fuva N B :- forall2 ~(\Ee)~ A B.
\end{elpicode}

\noindent
The main point in showing these equality tests is to remark how
weaker \Ee is, and to identify the four rules that need special
treatment in the implementation of \Uo.
For brevity we omit the code of \elpiIn{beta}:
it is sufficient to know that <<\elpiIn{beta F L R}>> computes in \elpiIn{R} the
weak head normal form of <<\elpiIn{app [F|L]}>>.
Note that the symbol \elpiIn{|} separates the head of a list from the tail.
\todo{explain forall2}

\paragraph{Substitution: $\rho s$ and $\sigma t$}

We write $\sigma = \{~ X \mapsto t ~\}$ for the substitution that assigns
the term $t$ to the variable $X$.
We write $\sigma t$ for the application of
the substitution to a term $t$, and $\sigma X = \{~ \sigma t ~|~ t \in X ~\}$ when
$X$ is a set of terms.
We write $\sigma \subseteq \sigma'$ when $\sigma$ is more
general than $\sigma'$.
% The domain of a substitution is the set of unification variables for which
% it provides an assignment.
% We write $\sigma \cup \sigma'$ to denote the concatenation of
% two substitutions whose domains are disjoint.
We shall use $\rho$ for \Fo{} substitutions,
and $\sigma$ for the \Ho ones.
For brevity, in this section we consider
the substitution for \Fo{} and \Ho{} identical.
We defer to \cref{sec:grounwork} a more precise description
pointing out theirs differences.

\paragraph{Term unification: \Uo vs. \Ue}

% Although we provide an implementation of the meta-language unification \Ue
% in the supplementary material (that we used for testing purposes) we only
% describe its signature here.
\Ho{}'s unification signature is:

\input{code/ue_type}

\noindent
We write 
$\sigma t_1 \Ue \sigma t_2 \mapsto \sigma'$ when
$\sigma t_1$ and $\sigma t_2$ unify with substitution $\sigma'$.
Note that $\sigma'$ is a refined (i.e. extended) version of $\sigma$; this is
reflected by signature above that relates two substitutions.
We write $t_1 \Ue t_2 \mapsto \sigma'$ when
the initial substitution $\sigma$ is empty.
% Note that if $\sigma t_1 \Ue \sigma t_2 \mapsto \sigma'$ then
% the domains of $\sigma$ and $\sigma'$ are disjoint.
We write \llambda as the set of terms that are in the pattern-fragment, i.e.
every higher-order variable is applied to a list of distinct names.

The meta language of choice is expected to provide 
an implementation of \Ue that satisfies
the following properties:
%~\ref{prop:correct-ml} and~\ref{prop:complete-ml}.
\begin{gather}
  \unifcorrect{\Ee}{\Ue}{t} \label{prop:correct-ml}\\
  \unifcomplete{\Ee}{\Ue}{t}\label{prop:complete-ml}
\end{gather}

\noindent
Even if we provide an implementation of the object-language unification
\Uo{} in \cref{sec:founif}, our real goal is the simulation of an entire
logic program.

\subsection{The problem: logic-program simulation}
We represent a logic program \emph{run} in \Fo{} as
a sequence of \emph{steps} of length $\mathcal{N}$.
At each step $p$ we unify two terms, $\foUnifPb_{p_l}$ and
$\foUnifPb_{p_r}$, taken from the list of all unification
problems \foUnifPb.
% \footnote{If the same rule is used multiple times in a run we
% consider as many copies as needed of the terms composing the
% rules, with fresh unification variables each time. Also, we do not
% model backtracking directly, but rather the fact that a step in a run may
% fail, and in that case the entire run is said to fail. A regular logic program
% that succeeds is modeled as a many runs, with possibly overlapping starts,
% where at least one run does not end in a failure. }
The composition of these steps starting from the
empty substitution $\rho_0$ produces the final
substitution $\rho_\mathcal{N}$, that is the result of the
logic-program execution.
%
\newcommand{\C}[4]{\ensuremath{\langle #1 \rangle}\mapsto(#2,#3,#4)}
\newcommand{\D}[4]{\ensuremath{\langle #1,#2,#3 \rangle^{-1}\mapsto #4}}
\newcommand{\progress}{\ensuremath{\mathrm{progress}}\xspace}
\newcommand{\fstep}{\ensuremath{\mathrm{fstep}}\xspace}
\newcommand{\hstep}{\ensuremath{\mathrm{hstep}}\xspace}
\newcommand{\frun}{\ensuremath{\mathrm{frun}}\xspace}
\newcommand{\hrun}{\ensuremath{\mathrm{hrun}}\xspace}
\newcommand{\stepF}[4]{\ensuremath{\fstep(#1,#2,#3) \mapsto #4}}
\newcommand{\stepFD}[4]{%
\ensuremath{#3 #1_{#2_l} \Uo #3 #1_{#2_r} \mapsto #4}}
\newcommand{\stepH}[6]{\ensuremath{\hstep(#1,#2,#3,#4) \mapsto (#5, #6)}}
\newcommand{\stepHD}[6]{\ensuremath{%
#3 #1_{#2_l} \Ue #3 #1_{#2_r} \mapsto #4 \land \progress(#6,#4) \mapsto (#6',#5)}}
\newcommand{\runF}[3]{\ensuremath{\frun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runFD}[2]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepF{#1}{p}{\rho_{p-1}}{\rho_{p}}}}
\newcommand{\runH}[3]{\ensuremath{\hrun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runHD}[3]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepH{#1}{p}{\sigma_{p-1}}{#3_{p-1}}{\sigma_{p}}{#3_p}}}
\newcommand{\deff}{\ensuremath{\stackrel{{\scriptscriptstyle def}}{=\!=\!\!\!=}}}
%
$$
\begin{array}{l}
\stepF{\foUnifPb}{p}{\rho}{\rho'}
\deff
\stepFD{\foUnifPb}{p}{\rho}{\rho'}\vspace{2pt}\\
\runF{\foUnifPb}{\mathcal{N}}{\rho}
\deff
\runFD{\foUnifPb}{\mathcal{N}}
\end{array}
$$

\noindent
\todo{say that backtracking is not important} 
In order to simulate a \Fo{} logic program in \Ho{} we compile
each \Fo{} term $s$ in \foUnifPb to a \Ho{} term $t$.
We write this translation $\C{s}{t}{m}{l}$. The implementation of the compiler
is detailed in \cref{sec:simulation,sec:eta,sec:beta}, here we just point
out that it additionally produce a variable mapping $m$ and list of links $l$.
The variable map connects unification variables in \Ho to variables
in \Fo{} and is used to ``decompile'' the assignment,
$\D{\sigma}{m}{l}{\rho}$. Links are an accessory piece of information whose
description is deferred to \cref{sec:nutshell}.
We write $\hoUnifPb_p = \{~ \hoUnifPb_{p_l}, \hoUnifPb_{p_r} ~\}$
and $s \in \foUnifPb \Leftrightarrow \exists p, s \in \foUnifPb_p$.

We simulate each run in \Fo{} with a run in \Ho as follows:

%Note that $\sigma_0$ is the empty substitution.
$$
\begin{array}{l}
\stepH{\hoUnifPb}{p}{\sigma}{\linkStore}{\sigma''}{\linkStore'} \deff\vspace{2pt}\\
  \qquad\stepHD{\hoUnifPb}{p}{\sigma}{\sigma'}{\sigma''}{\linkStore}\vspace{2pt}\\
  \runH{\foUnifPb}{\mathcal{N}}{\rho} \deff \vspace{2pt}\\
  \qquad \hoUnifPb \times \mapStore \times \linkStore_0 = \{ (t,m,l) | s \in \foUnifPb, \C{s}{t}{m}{l} \}\vspace{2pt}\\
  \qquad \runHD{\hoUnifPb}{\mathcal{N}}{\linkStore}\vspace{2pt}\\
  \qquad \D{\sigma_{\mathcal{N}}}{\mapStore}{\linkStore_{\mathcal{N}}}{\rho_{\mathcal{N}}}
\end{array}
$$

\noindent
By analogy with \foUnifPb, we write $\hoUnifPb_{p_l}$ and $\hoUnifPb_{p_r}$
for the two \Ho{} terms being unified at step $p$, and we write $\hoUnifPb_p$
for the set $\{~ \hoUnifPb_{p_l}, \hoUnifPb_{p_r} ~\}$.\\
\hstep{} is made of two sub-steps: a call to the meta language
unification and a check for \progress{} on the set of links, that intuitively
will compensate for the weaker equational theory honoured by \Ue.
\hrun{} compiles all terms in \foUnifPb{}, then executes each step and
finally decompiles the solution.
We claim:

\begin{proposition}[Simulation]\label{prop:simulation}
$\forall \foUnifPb, \forall \mathcal{N},$ if $~\foUnifPb \subseteq \llambda$
$$
  \runF{\foUnifPb}{\mathcal{N}}{\rho}
  \Leftrightarrow
  \runH{\foUnifPb}{\mathcal{N}}{\rho}
$$
\end{proposition}

\noindent
That is, the two executions give the same result if all terms in
\foUnifPb are in the pattern fragment. Moreover:

\begin{proposition}[Simulation fidelity]\label{prop:fidelity}
In the context of$\;$ \hrun, if $~\foUnifPb \subseteq \llambda$ we have that
$\forall p \in 1 \ldots \mathcal{N},$
$$
\stepF{\foUnifPb}{p}{\rho_{p-1}}{\rho_p}
\Leftrightarrow
\stepH{\hoUnifPb}{p}{\sigma_{p-1}}{\linkStore_{p-1}}{\sigma_p}{\linkStore_p}
$$
\end{proposition}
\noindent
In particular this property guarantees that a \emph{failure} in the \Fo{} run
is matched by a failure in \Ho{} \emph{at the same step}. We consider this
property very important from a practical point of view since it guarantees
that the execution traces are strongly related and in turn this enables a user
to debug a logic program in \Fo{} by looking at its execution trace in
\Ho{}.

We also claim that \hrun handles terms outside \llambda in the following sense:

\begin{proposition}[Fidelity recovery]\label{prop:fidelity-recovery} 
In the context of \hrun, if 
$\rho_{p-1} \foUnifPb_{p} \in \llambda$ 
(even if $\;\foUnifPb_{p} \not\in \llambda$)
then
$$
\stepF{\foUnifPb}{p}{\rho_{p-1}}{\rho_p} \Leftrightarrow
\stepH{\hoUnifPb}{p}{\sigma_{p-1}}{\linkStore_{p-1}}{\sigma_{p}}{\linkStore_p}
$$
\end{proposition}
  
In other words if the two terms involved in a step
re-enter \llambda, then \hstep and \fstep are again related, even if
$\foUnifPb \not\subseteq \llambda$ and hence \cref{prop:fidelity} does not apply.
Indeed, the main difference between \cref{prop:fidelity} and \cref{prop:fidelity-recovery}
is that the assumption of the former is purely static, it can be checked upfront. 
When this assumption is not satisfied one can still simulate a logic program and
have guarantees of fidelity if, at run time, decidability of higher-order
unification is restored.

This property has a practical relevance since in many logic programming
implementations, including Elpi, the order in which unification problems
are tackled does matter.
The simplest example is the sequence $F \UnifRel \lambda x.a$ and
$F \appsep a \UnifRel a$: the second problem is not in \llambda and has two
unifiers, namely $\sigma_1 = \{~ F \mapsto \lambda x.x ~\}$ and
$\sigma_2 = \{~ F \mapsto \lambda x.a ~\}$. The first problem picks $\sigma_2$
making the second problem re-enter \llambda.

\paragraph{Backtracking} We omit it from our model of a logic programs execution
since it pays a very minor role, orthogonal to higher-order unification.
We point out that each \emph{run} corresponds to a (proof search) branch in the
logic program that either fails at some point, or succeeds. A computation that
succeeds by backtracking, exploring multiple branches, could be
modeled as set of runs with (possibly non empty) common prefixes.

\subsection{The solution (in a nutshell)}
\label{sec:nutshell}
A term $s$ is compiled to a term $t$ where every
``problematic'' sub term $p$ is replaced by a fresh unification variable $h$
with an accessory \emph{link} that represents a suspended unification problem
$h \Ue p$. As a result \Ue is ``well behaved'' on $t$, in the sense that
it does not contradict \Eo as it would otherwise do on the
``problematic'' sub-terms.\\
We now define ``problematic'' and ``well behaved'' more formally
We use the $\Diamond$ symbol since it stands for ``possibly'' in modal logic
and all problematic terms are characterized by some ``uncertainty''.

\begin{definition}[\maybebeta]\label{def:maybebeta}
  \maybebeta is the set of terms of the form $X \appsep x_1 \ldots x_n$
  such that $x_1 \ldots x_n$ are distinct names (of bound variables).
\end{definition}

\noindent
An example of term \maybebeta{} is the application $F \appsep x$.
This term is problematic since the application node of
its syntax tree cannot be used to justify a
unification failure, i.e. by properly instantiating $F$ the term
head constructor may become a $\lambda$, or a constant or stay an application.

\begin{definition}[\maybeeta]\label{def:maybeeta}
  \maybeeta is the set of terms $s$ such that $\exists \rho, \rho s$
  is an eta expansion.
\end{definition}

\noindent
An example of term $s$ in \maybeeta{} is
$\lambda x.\lambda y.F \appsep y \appsep x$
since the substitution
$\rho = \{ F \mapsto \lambda a.\lambda b.f \appsep b \appsep a\}$
makes $\rho s = \lambda x.\lambda y.f \appsep x \appsep y$
that is the eta long form of $f$. This term is problematic since
its leading $\lambda$ abstraction cannot justify a
unification failure against a constant $f$.

\begin{definition}[\notllambda]\label{def:notllambda}
  \notllambda is the set of terms of the form $X \appsep t_1 \ldots t_n$
  such that $t_1 \ldots t_n$ are not distinct names.
\end{definition}

\noindent
These terms are problematic for the very same reason terms in \maybebeta are,
but cannot be handled directly by the unification of the meta language, that
is only required to handle terms in \llambda. Still, there exists a
substitution $\rho$ such that $\rho s \in \llambda$.

% An example of $t$ in \notllambda{} is $F \appsep a$ for a constant $a$.
% Note however tha
% an oracle could provide an assignment $\rho = \{ F \mapsto \lambda x.x\}$
% that makes the resulting term fall back in \llambda.
% \todo{said before}

\newcommand{\subterm}[1]{\ensuremath{\mathcal{P}(#1)}}
We write $\subterm{t}$ the set of sub-terms of $t$, and
%\begin{definition}[Subterms \subterm{t}] The set of sub terms of $t$ is the
%  largest set $\subterm{t}$ that can be obtained by the following rules.
%$$
%\begin{array}{l}
%t \in \subterm{t}\\
%t = f t_1\ldots t_n \Rightarrow \subterm{t_i} \subseteq \subterm{t} \land f \in \subterm{t}\\
%t = \lambda x.t' \Rightarrow \subterm{t'} \subseteq \subterm{t}\\
%\end{array}
%$$
%\end{definition}
%\noindent
we write $\subterm{X} = \bigcup_{t\in X} \subterm{t}$ when $X$ is a set of terms.

\newcommand{\wellb}{\ensuremath{\mathcal{W}}\xspace}
\begin{definition}[Well behaved set]
Given a set of terms $X \subseteq \Ho{}$,
$$
\wellb(X) \Leftrightarrow \forall t \in \subterm{X},
t \not\in (\maybebeta{} ~\cup~ \maybeeta{} ~\cup~ \notllambda{})
$$
\end{definition}

\noindent
We write $\wellb(t)$ as a short for $\wellb(\{t\})$.
We claim our compiler validates the following property: 

\begin{proposition}[\wellb-enforcing]\label{prop:w-enforcing}
  Given two terms $s_1$ and $s_2$, if $\exists \rho, \rho s_1 \Eo \rho s_2$,
  then 
  $$
    \C{s_i}{t_i}{m_i}{l_i} ~\mathrm{for}~ i \in \{ 1,2 \} \Rightarrow
    t_1 \Ue t_2 \mapsto \sigma \label{prop:compilation-w}
  $$
\end{proposition}

\noindent
In other words the compiler outputs terms in \wellb, even if its
input is not.
Note that the property holds for any substitution. $\rho$ could be given by an
oracle and/or not necessarily be a most general one: in \wellb \Ue{} simply
does not contradict \Eo.

\begin{proposition}[\wellb{}-preservation]\label{prop:w-preservation}
$\forall \hoUnifPb, \forall \linkStore, \forall p, \forall \sigma, \forall \sigma'$
$$
\begin{array}{l}
\wellb(\sigma\hoUnifPb) \land
  \sigma\hoUnifPb_{p_l} \Ue \sigma\hoUnifPb_{p_r} \mapsto {\sigma'}
  \Rightarrow \wellb(\sigma' \hoUnifPb)\\
\wellb(\sigma\hoUnifPb) \land
  \progress(\linkStore,\sigma) \mapsto (\_,\sigma')
  \Rightarrow \wellb(\sigma' \hoUnifPb)
\end{array}
$$
\end{proposition}

\noindent
Proposition \ref{prop:w-preservation} is key to prove \cref{prop:simulation,prop:fidelity}:
informally it says that the problematic terms moved on the side by the compiler
are not put back by \hstep, hence \Ue{} can continue to operate properly.
In \cref{sec:simulation,sec:eta,sec:beta}
we describe how the compiler recognizes terms in \maybebeta, \maybeeta and
\notllambda and how \progress takes care of them preserving \wellb
and granting \cref{prop:simulation,prop:fidelity,prop:fidelity-recovery}.

% Note that proposition \ref{prop:w-preservation} does not hold for \hrun as a whole
% since decompilation can introduce (actually restore) problematic terms.

\section{Basic compilation and simulation}
\label{sec:simulation}


\subsection{Memory map (\mapStore) and substitution (\texorpdfstring{$\rho$ and $\sigma$}{rho and sigma})}
\label{sec:grounwork}

% The predicate to test this condition is called \elpiIn{pattern-fragment}:

% \input{code/pattern_fragment}

Unification variables are identified by a (unique) memory address.
The memory and its associated operations are described below:

\input{code/mem_types}

\noindent
If a memory cell is \elpiIn{none}, then the corresponding unification variable
is not set. \elpiIn{assign} sets an unset cell to the given value, while
\elpiIn{new} finds the first unused address and sets it to \elpiIn{none}.

Since each \Ho unification variables occurs together with a scope,
its assignment needs to be abstracted over it to enable the
instantiation of the same assignment to different scopes.
This is expressed by the \elpiIn{inctx} container, and in particular
its \elpiIn{abs} binding constructor.

\input{code/ho_subst}

\noindent
A solution to a \Fo{} variable is a plain term, that is \elpiIn{fsubst}
is an abbreviation for \elpiIn{mem fm}.
%We call \elpiIn{fsubst} the memory of \Fo{}, while we call \elpiIn{subst}
%the one of \Ho.

The compiler establishes a mapping between variables of the two languages.

\input{code/comp_base_types}

\noindent
Each \elpiIn{hvariable} is stored in the mapping together with
its arity (a number) so that the code of \ref{clause:malloc} below can preserve:

\begin{invariant}[Unification-variable arity]\label{inv:uvaarity}
  Each variable \elpiIn{A}
  in \Ho has a (unique) arity \elpiIn{N} and each occurrence
  \elpiIn{(uva A L)} is such that \elpiIn{L} has length \elpiIn{N}.
\end{invariant}

\input{code/alloc_mapping}

\noindent
When a single \elpiIn{fvariable} occurs multiple times with different numbers
of arguments the compiler generates multiple mappings for it, on a first
approximation, and then makes the mapping bijective by introducing
\linketa; this detail is discussed in section \ref{sec:invariant1}.

%Applying the substitution corresponds to dereferencing a term with respect to
%the memory.
%  To ease the comparison we split \Fo{} dereferencing into a
% \elpiIn{fder} step and a \elpiIn{napp} one. The former step replaces references
% to memory cells that are set with their values, and has a corresponding
% operation in \Ho, namely \elpiIn{deref}. On the contrary \elpiIn{napp}
% has no corresponding operation in \Ho, and only ensures that
% terms of the form <<\elpiIn{fapp[fapp L1|L2]}>> are replaced by
% <<\elpiIn{fapp L3}>> where \elpiIn{L3} is the concatenation of \elpiIn{L1}
% and \elpiIn{L2}. The reasons for this asymmetry is
% that an \elpiIn{fapp} node with a flexible head is always mapped
% to a \elpiIn{uva} (as per \cref{sec:simulation,sec:beta}),
% preventing nested applications to materialize.
% \input{code/fderef}
It is worth looking at the code of \elpiIn{deref} that
applies the substitution to a \Ho{} term. Remark how assignments are moved
to the current scope, i.e. renaming the \elpiIn{abs}-bound variables
with the names in the scope of the unification variable occurrence.

\input{code/deref}

\noindent
Note that move strongly relies on invariant \ref{inv:uvaarity}: the length
of the arguments of all occurrences of a unification are the same. Hence
they have the same simple type for the meta-level and hence the number of
\elpiIn{abs} nodes in the assignment matches that length.
In turn this grants that \elpiIn{move} never fails.

\input{code/move}

We write $\sigma = \{~ A_{xy} \mapsto y ~\}$ for the assignment
<<\elpiIn{abs x\abs y\y}>> and $\sigma = \{~ A \mapsto \lambda x.\lambda y.y ~\}$
for <<\elpiIn{lam x\lam y\y}>>.

\subsection{Links (\linkStore)}

\noindent
As we mentioned in section~\ref{sec:nutshell} the compiler
replaces terms in \maybeeta, \maybebeta and \notllambda with fresh
variables linked to the problematic terms. Terms in \maybebeta do not
need a link since \Ho{} variables faithfully represent
the problematic term thanks to their scope.

\input{code/comp_links}

\noindent
The right hand side of a link, the problematic term, can occur under binders.
To accommodate this situation the compiler wraps \elpiIn{baselink} using
the \elpiIn{inctx} container (see~\ref{data:inctx} also used for \elpiIn{subst}).

\begin{invariant}[Link left hand side]\label{inv:linklhs}
  The left hand side of a suspended link
  is a variable.
\end{invariant}

\noindent
New links are suspended by construction.
If the left hand side is assigned during a step, then 
the link is considered for progress and possibly eliminated.
This is discussed in \cref{sec:eta} and \cref{sec:beta}.

When detailing examples we write links as equations between two
terms under a context.
The equality sign is subscripted with
kind of \elpiIn{baselink}. For example $\linkbetaM{x}{A_x}{F_x~a}$ corresponds to:
\begin{elpicode}
abs x\ val (link-llam (uva A [x]) (app[uva F [x],con "a"]))
\end{elpicode}

\subsection{Notational conventions}\todo{move away}

In \cref{sec:eta,sec:invariant1,sec:beta,sec:llam},
we use the following schema to represent the compilation of the list of \Fo{}
problems \foUnifPb into the \Ho problems \hoUnifPb. \mapStore and \linkStore are
respectively the mapping and the link store.
%
\printAlll
  {{{p_1,p_2},{p_3,p_4}}}
  {{{t_1,t_2},{t_3,t_4}}}
  {{{X_1,A_1,{{x}}},{X_2,A_2,{{y}}}}}
  {{{\eta,\Gamma,a,b}}}

We index each sub-problem, sub-mapping, sub-link with its position in the image
starting from $1$ and counting from left to right, top to bottom. For example,
$\hoUnifPb_2$ corresponds to the \Ho problem $t_3 \Ue t_4$.
The compiled version of each $\foUnifPb_i$ is represented by $\hoUnifPb_i$.

Moreover, to indicate the scope of a \Ho variable, we use that scope as
subscript of the considered variable. For example, $X_{xy}$ is the variable $X$ 
having in scope $x$ and $y$.

% The first three rules unify terms with same rigid heads, and
% call the unification relation on the sub-terms. If $t_1$ (resp. $t_2$) is an
% assigned variables, $t_1$ is dereferenced to $t_1'$ (resp. $t_2'$) and the
% unification is called between $t_1'$ and $t_2$ (resp. $t_1$ and $t_2'$). If both
% terms are unification variables, we test that their arguments are in the pattern
% fragment, we allocate a new variable $w$ in $\rho_1$ such that $w$ is the
% pruning of the arguments of $t_1$ and $t_2$, we assign both $t_1$ and $t_2$ to
% $w$ and return the new mapping $\rho_2$ containing all the new variable
% assignment. Finally, if only one of the two terms is an unification variable
% $v$, after having verified that $v$ does not occur in the other term $t$, we
% bind $v$ to $t$ and return the new substitution mapping.

% \old

% A key property needed in unification is being able to verify if two terms are
% equal wrt a given equational theory. This relation allow to compare terms under
% a certain substitution mapping, so that any time a variable $v$ is assigned in a
% subterm, a dereferencing of $v$ is performed. After variable dereferencing, the
% test for equality is continued on the new-created subterm.

% The base equality function over terms can be defined as follows:

% The solution we are proposing aim to overcome these unification issues by 1)
% compiling the terms $t$ and $u$ of the OL into an internal version $t'$ and $u'$
% in the ML; 2) unifying $t'$ and $u'$ at the meta level instantiating meta
% variables; 3) decompiling the meta variable into terms of the OL; 4) assigning
% the variables of the OL with the decompiled version of their corresponding meta
% variables. We claim that $t$ and $u$ unify if and only if $t'$ and $u'$ unify
% and that the substitution in the object language is the same as the one returned
% by the ML. \noteE[inline]{same or $\supseteq$ or $\subseteq$}

% In the following section we explain how we deal with term (de)compilation and
% links between unification variables.

% \section[Compilation: fo\_tm to tm]{Basic simulation of \Fo{} in \Ho{}}

% In this section we describe a basic compilation scheme that we refine
% later, in the following sections. This scheme is sufficient to implement
% a \hstep that respects $\beta$-conversion for terms in \llambda.
% The extension to $\eta\beta$-conversion is described in \cref{sec:eta} and
% the support for terms outside \llambda in \cref{sec:beta}.

\subsection{Compilation}
\label{sec:compilation}

The simple compiler described in this section serves as a base for the
extensions in \cref{sec:llam,sec:eta,sec:beta}.
Its main task is to beta normalize the term and map one syntax tree to
the other.
In order to bring back the substitution from \Ho{} to \Fo{} the compiler
builds a ``memory map'' connecting the the kind of variables using routine
\ref{clause:malloc}.

The signature of the \elpiIn{comp} predicate below allows for the generation of
links (suspended unification problems) that play no role in this section
but play a major role in \cref{sec:llam,sec:eta,sec:beta}.
With respect to \cref{sec:problem-statement} the signature also allows
for updates to the substitution.

\input{code/comp_base}
\todo{use the real code}
\begin{elpicode}
type compile fm -> tm -> mmap -> mmap -> links -> links ->
  subst -> subst -> o.
compile Fo0 Ho M0 M1 L0 M1 S0 S1 :-
  beta-normal Fo0 Fo, comp Fo Ho M0 M1 L0 M1 S0 S1.
\end{elpicode}

\noindent
The code above uses that possibility
in order to allocate space for the variables, i.e. sets their memory
address to \elpiIn{none} (a details not worth mentioning in the
previous sections).
\todo{explain fold6}

\input{code/comp_lam}

\noindent
In the code above the syntax \elpiIn{pi x y\..} is syntactic sugar for
iterated \elpiIn{pi} abstraction, as in \elpiIn{pi x\ pi y\..}.

The auxiliary function \elpiIn{close-links} tests if the bound variable
\elpiIn{v} really occurs in the link. If it is the case the link is wrapped into
an additional \elpiIn{abs} node binding \elpiIn{v}. In this way links generated
deep inside the compiled terms can be moved outside their original context
of binders.

\input{code/comp_close_links}

\noindent
Note that we could remove the first rule, whose sole purpose is to make
links more readable by pruning unused context entries.

\subsection{Execution}
\label{sec:execution}

A step in \Ho consists in unifying two terms and reconsidering all
links for progress. If any of the two tasks fails we say that the entire step
fails, and it is at this granularity that we can relate steps in the
two languages.


\input{code/hstep}

\noindent
Note tha the infix notation \elpiIn{((A ~\Ue~B) C D)} is syntactic sugar for
\elpiIn{((~\Ue\!\!\!~) A B C D)}.

Reconsidering links is a fixpoint, since the progress of a link can update the
substitution and in turn enable another link to progress.

\input{code/progress}

\subsubsection{Progress}
In the base compilation scheme \elpiIn{progress1} is the identity
on both the links and the substitution, so the fixpoint trivially terminates.
Sections \ref{sec:eta} and \ref{sec:beta} add rules to \elpiIn{progress1}
and justify why the don't hinder termination.
% For brevity we omit the code
% that applies the substitution \elpiIn{S1} to all terms in \linkStore.

\subsubsection{Occur check}\label{sec:oc}
Since compilation moves problematic terms out of the sight of \Ue{},
that procedure can only perform a partial occur check. For example the
unification problem $X \Ue f~Y$ cannot generate a cyclic substitution alone,
but should be disallowed if a $\linkStore$ contains a link like
$\linketaM{}{Y}{\lambda z.X_z}$: we don't know yet if $Y$ will feature
a lambda in head position, but we surely know it contains $X$, hence
$f~Y$ and that fails the occur check.
The procedure \elpiIn{occur-check-links} is in charge of
performing this check that is needed in order to
guarantee \fullref{prop:fidelity}.

\subsection{Substitution decompilation}

Decompiling the substitution involves three steps.

First and foremost problematic terms stored in
\linkStore have to be moved back into the game:
a suspended link must be turned into a valid assignment.
This operation is possible thanks to \fullref{inv:linklhs},
thanks to the fact that no link causes an occur-check~(\ref{sec:oc})
and the fact that \linkStore is duplicate free (\cref{TODO}).

The second step amounts at allocating new variables in the
memory of \Fo{}. This technicality is required because some
higher-order unification may need to prune a variable. For example
$F\appsep x\appsep y = F\appsep x\appsep z$ requires to allocate a 
variable $G$ in order to express the assignment $F_{ab} \mapsto G_a$.

The last step amounts at decompiling each assignment.
Decompiling a term is trivial since \mapStore is a bijection.
The only tricky part concerns the \elpiIn{abs} node. In out simple setting
the \elpiIn{flam} node carries no extra info (other then the function body),
so each \elpiIn{abs} node can be trivially converted to a \elpiIn{flam} one.
In the case of CIC, where lambdas carry the type of the bound variable, one
has to store it somewhere. Note how this piece of information is akin
to the arity of variables, that is CIC's unification variables have a
(function) type, and that type can be used to annotate the lambdas
needed in order to express their assignment.

\begin{lemma}[Compilation round trip]\label{prop:comprt} If
  \elpiIn{compile S T [] M [] _ [] _} then \elpiIn{decompile M T S}
\end{lemma}
% \begin{proof}[Proof sketch]
% Trivial since \mapStore is a bijection and 
% the terms are beta normal.
% some discussion about commit maybellam to be done later.
% \end{proof}

\subsection{Definition of \Uo{} and its properties}\label{sec:founif}

Even if the compiler, so far, makes no use 
of the higher-order nature of the meta language (all variables have
an empty scope so far) we can already show the code of \Ue{}.

\input{code/unif_fo}
\todo{Fix real code calling compile (not comp), rename decompm to decomp}

If \wellb{\foUnifPb} then we can prove that \Uo is a good
``first order'' unification algorithm. Later, when the compiler will
enforce it by \cref{prop:w-enforcing} and the proof will be adjusted.

\begin{lemma}
\Cref{prop:correct-ml,prop:complete-ml} hold for the implementation of \Uo above
\end{lemma}
\begin{proof}[Proof sketch]
 In this setting \Ee is as strong as
\Eo. What we have to show is that whenever two different \Fo{}
terms can be made equal by a substitution $\rho$ (plus the \ref{clause:beta1}
and \ref{clause:beta2} if needed) we can produce this $\rho$ by finding
a $\sigma$ via \Ue{} on the corresponding \Ho terms and by decompiling it.
If we look at the syntax of \Fo{} terms the only interesting case is
\elpiIn{fuva X ~\Uo~s}. In this case after compilation we have
$Y \Ue t$ that succeeds with $\sigma = \{ Y \mapsto t\}$ and
$\sigma$ is decompiled to $\rho = \{ Y \mapsto s\}$ by \cref{prop:comprt}.
\end{proof}

\begin{theorem}[Fidelity in \wellb] \Fullref{prop:simulation} and
\fullref{prop:fidelity} hold
\end{theorem}
\begin{proof}[Proof sketch]
Trivial since \elpiIn{progress1} is a no-op and \fstep and \hstep are the same.
Since all terms are $\beta$-normal and \wellb, \Ue is equivalent to \Uo.
\end{proof}

% \subsection{Limitations of by this basic scheme}
% \label{sec:basic-comp-limitations}
% The basic compilation scheme is not about to
% deal wit the following problem:
% \printAlll
%   {{{\lambda x y.X \appsep y \appsep x, \lambda x y.x},{\lambda x. f \appsep (X \appsep x) \appsep x,Y}}}
%   {{}}
%   {{}}
%   {{}}
% % \begin{gather}
% % \lambda x y.F \appsep y \appsep x = \lambda x y.x \label{eq:unif-eta1}\\
% % \lambda x. f \appsep (F \appsep x) \appsep x = G \label{eq:unif-eta2}
% % % \lambda x. f \appsep (F \appsep x) \appsep x = f \appsep (\lambda y.y) \label{eq:unif-eta2}
% % \end{gather}

% \noindent Note that here $X$ is used with different arities, moreover
% in the second problem the left hand side happens to be an
% eta expansion (of $f (\lambda y.y)$) only after we discover (at run time)
% that $X = \lambda x\lambda y.y$ (i.e. that $X$ discards the $x$ argument).
% Both problems are addressed in the next two sections.
  
\section{Handling of \maybebeta}\label{sec:llam}

A first problem we encounter when making unification between terms that are
well behaved is the need to treat higher-order variables. 
%
% make test ONLY=7006 TEX=tex
\printAlll
  {{{\lambda x.(f\appsep (X\appsep x)\appsep a),\lambda x.(f\appsep x\appsep a)}}}
  {{{\lambda x.(f\appsep (A\appsep x)\appsep a),\lambda x.(f\appsep x\appsep a)}}}
  {{{X,A,0}}}
  {{}}

In the example above, we can note that the very basilar compilation given in 
the previous section is not able to make the \Ho unification problem succeeds.
The unification of $T_1$ fails while trying to unifying $A \appsep x$ and $x$.
This is due to the fact that $A \appsep x$ (equivalent to \elpiIn{app[uva A [], x]})
is represented as the application of the variable $A$ to the name $x$.
In order to exploit the higher-order unification algorithm of the meta language,
we need to compile the \Fo{} term $X\appsep x$ into the \Ho term $A_x$.

\subsection{Compilation and decompilation}

In order to address this problem, we add the following rule before rule~\ref{rule:compapp}.

\input{code/comp_base_beta}

\noindent
Note that compiling \elpiIn{Ag} cannot create new mappings nor links, since \elpiIn{Ag}
is made of bound variables and the hypothetical rule loaded by \elpiIn{comp-lam}
(see below) grants this property. Also note that this rule generates no links.


\noindent
The only detail worth discussing is the fact that the procedure updates a
substitution, rather than just crafting one as presented in
section~\ref{sec:problem-statement}. The reason is that the algorithm folds
over a term, updating a substitution while it traverses it.\noteE[inline]{explain better}

\paragraph{Decompilation} Since no link is created by the compilation of 
\maybebeta terms, no modification should be done
to the \elpiIn{commit-link} predicate.

\paragraph{Progress} Similarly to decompilation, since no link is produced,
no modification to the \elpiIn{progress} predicate is needed.

\begin{lemma}
  \Cref{prop:correct-ml,prop:complete-ml} hold for the implementation of \Uo
  in \cref{sec:founif}
  \end{lemma}
  \begin{proof}[Proof sketch]
  If we look at the \Fo{} terms, the is one more case interesting cases:
  \begin{itemize}
  \item \elpiIn{fapp[fuva X|L] ~\Uo~s}. In this case
   we have $Y_{\vec{x}} \Ue t$ that succeeds with
   $\sigma = \{ Y_{\vec{y}} \mapsto t[\vec{x}/\vec{y}]\}$ that in turn
\todo{ste x escono da L}   is decompiled to $\rho = \{ Y \mapsto \lambda \vec{y}.s[\vec{x}/\vec{y}]\}$.
   Thanks to \ref{clause:beta1}
   $(\lambda \vec{y}.s[\vec{x}/\vec{y}])~\vec{x} \Eo s$.
  \end{itemize}
  \end{proof}
  
\begin{lemma}[\wellb-enforcement]\label{lem:w-enforcement-maybebeta} Even if $\foUnifPb \cap \maybebeta \ne \emptyset$,
  $\hoUnifPb \cup \maybebeta = \emptyset$
\end{lemma}\noteD{Non capisco}
\begin{proof}[Proof sketch]
  problematic terms are mapped to uva by comp, the problematic fapp node is gone.
\end{proof}

\begin{theorem}[Fidelity in \maybebeta] \Fullref{prop:simulation} and
\fullref{prop:fidelity} hold
\end{theorem}
\begin{proof}[Proof sketch] thanks to \cref{lem:w-enforcement-maybebeta}
  it is the same as in \cref{sec:simulation}, even if now
  we really need \Ue{} to deal with \llambda, while before a FO unif
  would have done.
\end{proof}
% \subsection{Example}

% OK

% \begin{elpicode}
% Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%       , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr z (s z) ] % $\lambda x.g (F x) = \lambda x.g a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% \end{elpicode}

% KO

% \begin{elpicode}
%   Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%   , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr 0 1   % $A = \lambda x.x$
%            , pr 2 3 ] % $A a = a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% lam x\ app[f, app[X, x]] = Y,
%   lam x\ x) = X.
% \end{elpicode}

% \otext{Goal: $s_1 \Uo s_2$ is compiled into $t_1 \Ue t_2$}
% \otext{What is done: uvars \elpiIn{fo_uv} of OL are replaced into uvars \elpiIn{ho_uv} of the ML}
% \otext{Each \elpiIn{fo_uv} is linked to an \elpiIn{ho_uv} of the OL}
% \otext{Example needing the compiler v0 (tra l'altro lo scope è ignorato):\\ \elpiIn{lam x\ app[con"g",app[uv 0, x]] ~\Uo~lam x\ app[con"g", c"a"]}}
% \otext{Links used to instantiate vars of elpi}
% \otext{After all links, the solution in links are compacted and given to coq}
% \otext{It is not so simple, see next sections (multi-vars, eta, beta)}


% The compilation step is meant to recover the higher-order variables of the OL,
% expressed in a first order way, by replacing them with higher-order variables in
% the ML. In particular, every time a variable of the OL is encountered in the
% original term, it is replaced with a meta variable, and if the OL variable is
% applied to a list of distinct names $L$, then this list becomes the scope of the variable.
% For all the other constructors of
% \elpiIn{tm}, the same term constructor is returned and its arguments are
% recursively compiled. The predicate in charge for term compilation is:

% \elpiIn{type comp tm -> tm -> links -> links -> subst -> subst -> o}.

% \noindent
% where, we take the term of the OL, produce the term of the ML, take a list
% of link and produce a list of new links, take a substitution and return a
% new substitution.

% In particular, due to programming constraints, we need to drag the old subst and
% return a new one extended, if needed, with the new declared meta-variables.

% The following code
% %
% \begin{elpicode}
%   kind link type.
%   type link nat -> nat -> nat -> subst.
% \end{elpicode}
% %
% \noindent
% defines a link, which is a relation between to variables indexes, the first
% being the index of a OL variable and the second being the index of a ML
% variable. The third integer\noteE[inline]{integer or nat?} is the number of term in the
% scope of the two variables, or equivalently, in a typed language, their arity.

% As an example, let's study the following unification problem (a slightly
% modified version from \cref{sec:intro}):

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Uo~
%     lam x\ app [c"decision", app[uv 0, x]]
% \end{elpicode}

% \noindent
% we have the main unification problem where the nested \elpiIn{app} nodes have
% lists of different lengths making the unification to fail. The compilation of
% these terms produces a new unification problem with the following shape:

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Ue~
%     lam x\ app [c"decision", uv 1 [x]]
% \end{elpicode}

% \noindent
% The main difference is the replacement of the subterm \elpiIn{app[uv 0, x]} of
% the OL with the subterm \elpiIn{uv 0 [x]}. Variable indexes are chosen by the
% ML, that is, the index \elpiIn{0} for that unification variable of the OL term
% has not the sam meaning of the index \elpiIn{0} in the ML. There exists two
% different substitution mapping, one for the OL and one for the ML and the indexes
% of variable point to the respective substitution.

% decomp che mappa abs verso lam
% \noindent
% \otext{An other example: \\
%   \elpiIn{lam x\ app[f, app[X, x]] = Y, (lam x\ x) = X.}}

% \section{Use of multivars}

% Se il termine initziale è della forma

% \begin{elpicode}
%   app[con"xxx", (lam x\ lam y\ Y y x), (lam x\ f)]
%   =
%   app[con"xxx",X,X]
% \end{elpicode}

% allora se non uso due X diverse non ho modo di recuperare il quoziente che mi manca.

% a sto punto consideriamo liste di problemi e così da eliminare sta xxx senza
% perdità di generalità (e facciamo problemi più corti, e modellizziamo anche la
% sequenza)

\section{Handling of \maybeeta}\label{sec:eta}
$\eta$-reduction is an equivalence relation where a term of the form
$\lambda x.t \appsep x$ can be converted to $t$ any time $x$ does not occur as a
free variable in $t$. We call $t$ the $\eta$-contraction of
$\lambda x. t \appsep x$.

Following the compilation scheme of \cref{sec:compilation} the
unification problem \foUnifPb is compiled as follows:
%
\printAlll
  {{{\lambda x. X \appsep x, f}}}
  {{{\lambda x. A_x, f}}}
  {{{X,A,1}}}
  {{}}

\noindent
While $\lambda x.X \appsep x \Uo{} f$ does admit the solution
$\rho = \{~ X \mapsto f ~\}$, the corresponding problem in
\hoUnifPb does not:
\elpiIn{lam x\ uva A [x]} and
\elpiIn{con"f"} start with different, rigid, term constructors hence
\Ue{} fails.

In order to guarantee \cref{prop:simulation} we detect
lambdas that can disappear by eta contraction (\cref{sec:etadetection}) and
we modify the compiled terms by putting fresh unification variables
in their place: the problematic term is moved 
from  \hoUnifPb to \linkStore (\cref{sec:etacomp}). The compilation
of the problem \foUnifPb above is refined to: 
%
\printAlll
  {{{\lambda x.X \appsep x,f}}}
  {{{A,f}}}
  {{{X,B,1}}}
  {{{\eta,,A,\lambda x.B_x}}}

\noindent
As per \cref{inv:linklhs} the term on the left is a variable, and its
right counterpart is the
term in \maybeeta. That term has the following property:

\begin{invariant}[\linketa \rhs]
  The \rhs of any \linketa %in \linkStore 
  has the shape $\lambda x.t$
  and $t$ is not a lambda. 
  %where $t_x$ is a \maybeeta term and $x$ is free in $t$.
  \label{inv:link-eta-right}
\end{invariant}

\linketa are kept in the link store \linkStore during execution
and activated when some conditions hold on \lhs or \rhs.
Link activation is implemented by extending the \elpiIn{progress1}
predicate (defined in \cref{sec:execution}).

\subsection{Detection of \maybeeta}\label{sec:etadetection}

When compiling a term $t$ we need to determine if any
subterm $s \in \subterm{t}$ that is of the form $\lambda x. r$,
where $x$ occurs in $r$, can be a $\eta$-expansion, i.e. if
there exists a substitution $\rho$ such that $\rho (\lambda x.r) \Eo s$.
The detection of lambda abstractions that can ``disappear''
is not as trivial as it may seems, here a few examples:
%
\begin{center}
  \begin{tabular}{lll}
    %Term & Status & Evidence \\\hline
    $\lambda x. f \appsep (A \appsep x)$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.x ~\}$ \\
    $\lambda x. f \appsep (A \appsep x) \appsep x$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.a ~\}$\\
    $\lambda x. f \appsep x \appsep (A \appsep x)$ & $\not\in\maybeeta$ &\\
    $\lambda x. \lambda y. f \appsep (A \appsep x) \appsep (B \appsep y \appsep x)$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.x,~ B \mapsto \lambda y.\lambda x.y ~\}$
  \end{tabular}
\end{center}
\vspace{4pt}

% In the examples above, the first term is a \maybeeta since $A_x$ can
% reduce to $x$ by setting $A_x = \lambda x.x$, 
% the second one is not a \maybeeta since it exists no substitution
% for $A_x$ such that $A_x$ reduces to $x$ and $x$ is not free in the subterm $f \appsep x$.
\noindent
The first two examples are easy, and show how a unification variable can expose
or erase a variable in their scope and turn the resulting term in an $\eta$-expansion or not.\\
The third example shows that when a variable occurs outside the scope of a unification
variable it cannot be erased and can hence prevent a term from being an $\eta$-expansion.\\
The last example shows the recursive nature of the check we need to implement.
The term starts with a spine of two lambdas hence the whole term
is in \maybeeta iff the inner term $\lambda y.f\appsep (A \appsep x) \appsep (B \appsep y \appsep x)$
is in \maybeeta itself. If it is, it could $\eta$-contract to
$f \appsep (A \appsep x)$ making $\lambda x.f \appsep (A \appsep x)$ a potential
$\eta$-expansion.\\
We can now define more formally how \maybeeta terms are detected together with
its auxiliary functions:

\newcommand{\reduceto}{\emph{may-contract-to}}
\begin{definition}[\reduceto]
  A $\beta$-normal term $s$ \reduceto{} a name $x$ if there exists a
  substitution $\rho$ such that $\rho s \Eo{} x$.
\end{definition}

\begin{lemma}\label{lem:reduceto}
A $\beta$-normal term $s = \lambda x_1 \ldots x_n.t$
%, where $x, x_1\ldots x_n$ can occur in $t$, 
\reduceto{} $x$ only if one of the following three conditions holds:
\begin{enumerate}
  \item $n = 0$ and $t = x$;
  \item $t$ is the application of $x$ to a list
     of terms $l$ and each $l_i$ \reduceto{} $x_i$
     (e.g. $\lambda x_1 \ldots x_n.x \appsep x_1 \ldots x_n \Eo{} x$) ;
  \item $t$ is a unification variable with scope
    $W$, and for any $v \in \{ x, x_1 \ldots x_n \}$,
    there exists a $w_i \in W$, such that $w_i$ \reduceto{} $v$
    (if $n = 0$ this is equivalent to $x \in W$).
\end{enumerate}
\end{lemma}
\begin{proof}[Proof sketch]
Since our terms are in $\beta$-normal form there is only
one rule that can play a role (namely \ref{clause:eta1}),
hence if the term $s$ is not exactly $x$ (case 1)
it can only be an $\eta$-expansion of $x$, or a unification
variable that can be assigned to $x$, or a combination of both.
If $s$ begins with a lambda, then the lambda can only disappear by $\eta$
contraction. In that case the term $t$ is under the spine of binders
$x_1\ldots x_n$, $t$ can either be $x$ applied to terms that can
\reduceto{} these variables (case 2), or a unification variable
that can be assigned to that application (case 3).
\end{proof}

% \noindent
% Note that this condition does not require the term to be in \llambda.
% \noteE[inline]{Is this relevant}

\newcommand{\occursrigid}{\emph{occurs-rigidly}\xspace}
\newcommand{\occurrigid}{\emph{occur-rigidly}\xspace}
\begin{definition}[\occursrigid]\label{def:occrigid}
  A name $x$ \occursrigid{} in a $\beta$-normal term $t$, if $\forall \rho, x \in
  \subterm{\rho t}$
\end{definition}

In other words $x$ \occursrigid in $t$ if it occurs in $t$
outside of the scope of a unification variable $X$, otherwise an instantiation
of $X$ can make $x$ disappears from $t$.
Moreover, note that $\eta$-contracting $t$ cannot make $x$ disappear, since
$x$ is not a locally bound variable inside $t$.

We can now derive the implementation for \maybeeta detection:

\newcommand{\testmaybeeta}{\emph{maybe-eta}\xspace}
\begin{definition}[\testmaybeeta]\label{def:testmaybeeta}
  Given a $\beta$-normal term
  $s = \lambda x_1 \ldots x_n.t$, \testmaybeeta{} $s$ holds if any
  of the following holds:
  \begin{enumerate}
    \item $t$ is a constant or a name applied to the arguments
      $l_1 \ldots l_m$ such that 
      $m \geq n$ and for every $i$ such that $m - n < i \leq m$
      the term  $l_i$
      \reduceto{} $x_i$, and
      no $x_i$ \occursrigid{} in $l_1 \ldots l_{m-n}$;
    \item $t$ is a
      unification variable with scope $W$ and
      for each $x_i$ there exists a $w_j \in W$ such that $w_j$
      \reduceto{} $x_i$.
  \end{enumerate}
\end{definition}
\begin{lemma}[\maybeeta detection]\label{lem:maybeeta}
  If $t$ is a $\beta$-normal term and \testmaybeeta{} $t$ holds,
  then $t \in \maybeeta$.
\end{lemma}
\begin{proof}[Proof sketch]
Follows from \cref{def:occrigid} and \cref{lem:reduceto}
\end{proof}

\noindent
Remark that the converse of \cref{lem:maybeeta} does not hold: 
there exists a term $t$ satisfying the criteria (1) of
\cref{def:testmaybeeta} that is not in $\maybeeta$, i.e.
there exists no substitution $\rho$ such that $\rho t$ is an
$\eta$-expansion. A simple counter example is
$\lambda x. f \appsep (A \appsep x) \appsep (A \appsep x)$
since $x$ does not \occurrigid{} in the first argument
of $f$,
and the second argument of $f$ \reduceto{} $x$.
In other words $A \appsep x$
may either use or discard $x$, but our analysis does not
take into account that \emph{the same
term} cannot have two contrasting behaviors.

As we will see in the rest of this section this is not a problem
since it does not break
\cref{prop:simulation} nor \cref{prop:fidelity}.
% A term in \maybeeta{} is compiled to a
% unification variable and a link (see \cref{sec:etacomp}):
% the link makes progress (see \cref{sec:etaprogress})
% in the same step in which the
% variable is instantiated, and that compensates
% for this coarse analysis.

% The implementation we propose for the \maybeeta relation is given below.

% \input{code/maybe_eta}

% Here a complex maybeeta example
% \begin{gather}
%   T = \lambda y. f \appsep A_{xy} \appsep (B \appsep a \appsep (\lambda z.y\appsep C_z)) \appsep D_x
% \end{gather}

\subsection{Compilation and decompilation}\label{sec:etacomp}

% Thanks to the \elpiIn{maybe-eta} predicate, we can detect ``$\eta$-problematic''
% terms and, consequently replace them with fresh \Ho unification variables at
% compilation time. The code below illustrate how this relation is used to for
% term compilation.

\paragraph{Compilation}
The following rule is inserted just before rule~\ref{rule:complam} from the code in
\cref{sec:compilation}.

\input{code/comp_eta}

\noindent
The rule triggers when the input term \elpiIn{flam F} is in
\maybeeta. It compiles \elpiIn{flam F} to \elpiIn{lam F1} but puts the fresh
variable \elpiIn{A} in its place. This variable sees all the names free in
\elpiIn{lam F1}. The critical part of this rule is the creation of the \linketa,
which relates the variable \elpiIn{A} with \elpiIn{lam F1}.
This link clearly validates \cref{inv:linklhs}.

\begin{corollary}
  The \rhs of any \linketa has exactly one lambda abstraction, hence
  the rule above respects \cref{inv:link-eta-right}.
  \label{cor:rhs-eta-onelamb}
\end{corollary}

\begin{proof}[Proof sketch]
  By contradiction, suppose that the rule above is triggered and that
  the \rhs of the link is $\lambda x.\lambda y.t_{xy}$.
  If $\testmaybeeta{}~\lambda y.t_{xy}$ holds the recursive call to
  \elpiIn{comp} (made by \elpiIn{comp-lam}) must have put a fresh variable
  in its place, so this case is impossible.
  Otherwise, if $\testmaybeeta{}~\lambda y.t_{xy}$ does not hold, also
  $\testmaybeeta{}~\lambda x.\lambda y.t_{xy}$ does not hold, contradicting
  the assumption that the rule triggered.
\end{proof}

\paragraph{Decompilation}
Decompilation of the remaining \linketa (i.e. the \linketa that have been
activated) is performed by iterating over them and unifying \lhs and \rhs. Note
that this unification never fails, since \lhs is a flexible term not appearing
in any other \linketa (by \cref{def:progressetadedup}).

\subsection{Progress}\label{sec:etaprogress}

\linketa are meant to delay the unification of ``problematic'' terms until
we know for sure if the term has to be $\eta$-contracted or not.

\newcommand{\progressetaleft}{\emph{$\eta$-progress-\lhs}\xspace}
\begin{definition}[\progressetaleft]\label{def:progressetaleft}
A link \linketaM{\Gamma}{X}{T} is removed from \linkStore when
$X$ becomes rigid. Let $y\in\Gamma$, there are two cases:
\begin{enumerate}
  \item if $X = a$ or $X = y$ or $X = f \appsep a_1\ldots a_n$
    we unify the $\eta$-expansion of $X$ with $T$, that is we run
    $\lambda x.X \appsep x\Ue{} T$
    \item if $X = \lambda x.t$ we run $X \Ue{} T$.
\end{enumerate}
\end{definition}

\newcommand{\progressetaright}{\emph{$\eta$-progress-\rhs}\xspace}
\begin{definition}[\progressetaright]\label{def:progressetaright} A link
\linketaM{\Gamma}{X}{T} is removed from \linkStore when either 1)
$\testmaybeeta~T$ does not hold (anymore) or 2) by $\eta$-contracting $T$ to
$T'$, $T'$ is a term not starting with the \elpiIn{lam} constructor. In the
first case, $X$ is unified with $T$ and in the second one, $X$ is unified with
$T'$ (under the context $\Gamma$).
\end{definition}

There is a third case in which a link is removed from \linkStore, namely
when the \lhs is assigned to a variable that is the \lhs of another
\linketa.

\newcommand{\progressetadedup}{\emph{$\eta$-progress-deduplicate}\xspace}
\begin{definition}[\progressetadedup]\label{def:progressetadedup}
  A link \linketaM{\Gamma}{X_{\vec{s}}}{T} is removed from \linkStore when
  another link \linketaM{\Delta}{X_{\vec{r}}}{T'} is in  \linkStore.
  By \cref{inv:uvaarity} the length of $\vec{s}$ and $\vec{r}$ is the same
  hence we can move the term $T'$ from $\Delta$ to $\Gamma$ by renaming its
  bound variables, i.e. $T'' = T'[\vec{r}/\vec{s}]$.
  We then run $T \Ue{} T''$ (under the context $\Gamma$).
\end{definition}

\begin{lemma}
  Let $\lambda x.t$ the \rhs of a \linketa, then $\wellb(t)$.
  \label{lemma:unif-eta-aux}
\end{lemma}

\begin{proof}[Proof sketch]
  By construction, every ``problematic'' term in \Fo{} is replaced with a variable
  in the corresponding \Ho term. Therefore, $t$ is \wellb.
\end{proof}

% \noteD[inline]{Below the proof of \cref{prop:w-preservation}, ho usato 3 lemmi ausiliari,
% forse si può compattare in una prova più piccola?}
\begin{lemma}
  Given a \linketa $l$, the unification done by \progressetaleft is between
  terms in $\wellb$  
  \label{lemma:unif-eta-1}
\end{lemma}

\begin{proof}[Proof sketch]
  Let $\sigma$ be the substitution, which is  $\wellb(\sigma)$ (by
  \cref{prop:w-preservation}). $\lhs \in \sigma$, therefore $\wellb(\lhs)$. By
  \progressetaleft, if 1) \lhs is a name, a constant or an
  application, then, $\lambda x.\lhs \appsep x$ is unified with \rhs. By
  \cref{inv:link-eta-right} and \cref{lemma:unif-eta-aux}, $\rhs = \lambda x. t$ and $\wellb(t)$.
  Otherwise, 2) \lhs has \elpiIn{lam} as functor. In both cases, unification is
  performed between terms in \wellb.
\end{proof}

\begin{lemma}
  Given a \linketa $l$, the unification done by \progressetaright is between
  terms in \wellb.
  \label{lemma:unif-eta-2}
\end{lemma}

\begin{proof}[Proof sketch]
  \lhs is variable, and, by \cref{def:progressetaright}, \rhs is either no more
  a \maybeeta, i.e. \rhs is not a $\eta$-expansion and, so, $\wellb(\rhs)$,
  otherwise, \rhs can reduce to a term which cannot be a $\eta$-expansion, and,
  so, $\wellb(\rhs)$. In both cases, the unification between \rhs and \lhs
  is done between terms that are in \wellb.
\end{proof}

\begin{lemma}
  Given a \linketa $l$, the unification done by \progressetadedup is between
  terms in \wellb.
  \label{lemma:unif-eta-3}
\end{lemma}

\begin{proof}
  The unification is done between the \rhs of two \linketa. Both \rhs has the
  shape $\lambda x.t$, and by \cref{lemma:unif-eta-aux}, $\wellb(t)$.
  Therefore, the unification is done between well-behaved terms.
\end{proof}

\begin{lemma}
  The introduction of \linketa guarantees \fullref{prop:w-preservation}
  \label{lemma:unif-wellb}
\end{lemma}
\todo{is this W-enforcing?}

\begin{proof}[Proof sketch]
  By \cref{lemma:unif-eta-1,lemma:unif-eta-2,lemma:unif-eta-3}, every
  unification performed by the activation of a \linketa is done between
  terms in \wellb, therefore, the substitution remains \wellb.
\end{proof}

\begin{lemma}
  \elpiIn{progress} terminates.
  \label{lemma:prog-eta-terminates}
\end{lemma}

\begin{proof}[Proof sketch]
  Rules \cref{def:progressetaleft,def:progressetaright} and
  \cref{def:progressetadedup} remove one link from \linkStore, hence they
  cannot be applied indefinitely.
  Moreover each rule only relies on terminating operations such as \Ue,
  $\eta$-contraction, $\eta$-expansion, relocation (a recursive copy of a
  finite term).
  % The addition of rules for \elpiIn{progres1} complicates the function
  % \elpiIn{progress}. We can note, however, that they do not prevent the
  % termination of \elpiIn{progress}. 1) If a link is activated it is removed from
  % \linkStore and the recursive call to \elpiIn{progress} will have a smaller
  % list of links to recurse on. Moreover, link activation only runs terminating
  % instructions (such as unification). 2) If a link is deduplicated, the
  % termination of \elpiIn{progress} is still guaranteed since again we reduce
  % \linkStore and the instructions run by link deduplications are all
  % terminating. 3) If a link is neither activated nor deduplicated, i.e. it
  % remains suspended, then \linkStore remains unchanged like the substitution;
  % therefore, \elpiIn{if (L = L1, S1 = S2)} succeeds and \elpiIn{progress}
  % terminates.
\end{proof}

\begin{theorem}[Fidelity in \maybeeta]
  % F x = z, F x y = z y
  Given a list of unification problems \foUnifPb, such that \noteD{riprendere sec 3.1}
  $\forall t, t\in\subterm{\foUnifPb} \land t \notin \notllambda$, \noteD{dire che M e biiettivo}
  the introduction 
  of \linketa guarantees \fullref{prop:fidelity}.
  \footnote{We also suppose that any higher-order variable is always applied with
  the same number of arguments. This problem is addressed in \cref{sec:invariant1}}\noteD{modificare accordingly}
  \label{lemma:fidelity-maybeeta}
\end{theorem}

\begin{proof}[Proof sketch]
  \progressetaleft and \progressetadedup activate a \linketa when, in the
  original unification problem, a \maybeeta term is unified with respectively a
  well-behaved term or another \maybeeta term. In both cases, the links trigger
  a unification which succeeds iff the same unification in \Fo{} succeeds,
  guaranteeing \cref{prop:fidelity}. \progressetaright never fails, in fact,
  this progression refines a variable to a rigid term and plays no role in 
  \cref{prop:fidelity}.
  % If 1) a \linketa is activated by \progressetaleft, then unification is done
  % between a \maybeeta term $t_1$ and a term $t_2$ (with $\wellb(t_2)$). This
  % activation performs a unification which succeeds iff the original problem in
  % \Fo{} succeeds. If 2) a \linketa is activated by \progressetadedup, then the
  % unification is done between two \maybeeta terms, and again this unification
  % succeeds iff it succeeds in \Fo{}. Finally, if 3) a \linketa is activated by
  % \progressetaright, the unification, done between a variable and a term,
  % always succeeds, this is what we expect to guarantee fidelity, since we
  % are essentially removing a hole added by the compilation in the place of a
  % \maybeeta subterm. In all the cases fidelity is respected.
\end{proof}

\paragraph{Example of \progressetaleft}

The example at the beginning of \cref{sec:eta}, once
$\sigma = \{~ A \mapsto f ~\}$, triggers \progressetaleft since the link
becomes \linketaM{}{f}{\lambda x.B_{x}} and the \lhs is a constant.
In turn the rule runs $\lambda x.f \appsep x \Ue{} \lambda x.B_{x}$,
resulting in $\sigma = \{~ A \mapsto f ~;~ B_{x} \mapsto f ~\}$.
Decompilation the generates $\rho = \{~ X \mapsto f ~\}$, since
$X$ is mapped to $B$ and
$f$ is the $\eta$-contracted version of $\lambda x.f \appsep x$.

\paragraph{Example of \progressetadedup}

A very basic example of \linketa deduplication, is given below:
% make test ONLY=7002 TEX=tex
\printAlll
  {{{\lambda x.(X\appsep x),\lambda x.(Y\appsep x)}}}
  {{{A,C}}}
  {{{X,B,1},
    {Y,D,1}}}
  {{{\eta,,A,\lambda x.B_{x}},
    {\eta,,C,\lambda x.D_{x}}}}

\noindent
The result of $A \Ue{} C$ is that the two \linketa share the same \lhs.
By unifying the two \rhs we get
$\sigma = \{ A~ \mapsto C, B \mapsto D ~\}$.
In turn, given the map \mapStore, this second assignment is decompiled to
$\rho = \{~ X \mapsto Y ~\}$ as expected.

We delay at the end of  next section an example of \linketa progression due to
\progressetaright


%\section{Enforcing inv.: \NoCaseChange{\nameref{inv:uvaarity}}}
\section{Making \mapStore a bijection}
\label{sec:invariant1}

In \cref{sec:grounwork}, we introduced the definition of ``memory map'' (\mapStore).
This memory allows to decompile the \Ho terms back to the object language.
It is the case that, while solving unification problems, a same unification
variable $X$ is used multiple times with different arities.
%
% make test ONLY=7001 TEX=tex
\printAlll
  {{{\lambda x.\lambda y.(X\appsep y\appsep x),\lambda x.\lambda y.x},
    {\lambda x.(f\appsep (X\appsep x)\appsep x),Y}}}
  {{{A,\lambda x.\lambda y.x},
    {D,F}}}
  {{{X,E,1},
    {Y,F,0},
    {X,C,2}}}
  {{{\eta,,D,\lambda x.(f\appsep E_{x}\appsep x)},
    {\eta,,A,\lambda x.B_{x}},
    {\eta,x,B_{x},\lambda y.C_{y x}}}}

In the unification problems \foUnifPb above, we see that $X$ is used with arity $2$ in
$\foUnifPb_1$ and with arity $1$ in $\foUnifPb_2$. 
By \fullref{inv:uvaarity}, we are not allowed to use a same \Ho variable to 
represent the two occurrences of $X$.
If we execute \hrun, we remark that the unification fails.
There is in fact a major problem:
\hstep is not conscious of the connection between the variables $C$ and $E$ (both corresponding to $X$),
since no link in \linkStore puts $C$ and $E$ in relation and decompilation
does not work properly if a \Fo{} variable is mapped to two distinct \Ho variables. 
The two main drawbacks connected to this situation are 
firstly the lost of \fullref{prop:fidelity} and
secondly, if we want to guarantee at least \fullref{prop:simulation}, we should
overcomplicate the decompilation phase. In order to ease the second
drawback, we pose the following property:

\begin{proposition}[\mapStore is a bijection]
  Given a list of unification problems \foUnifPb, then the memory map \mapStore
  compiled from \foUnifPb is a bijection relating the \Fo{} and the \Ho{} 
  variables.
\end{proposition}

We finally adjust the compiler's output with a \elpiIn{map-deduplication} procedure.

\newcommand{\alignarity}{\emph{align-arity}}
\begin{definition}[\alignarity] Given two mappings
  $m_1 : X \mapsto A^m$ and
  $m_2 : X \mapsto C^n$ where $m < n$ and $d = n - m$,
  $\alignarity{}~ m_1 ~ m_2$ generates the following $d$ links, one
  for each $i$ such that $0 \leq i < d$,
\[%
  \linketaM{x_0 \ldots x_{m+i}}
           {B^i_{x_0 \ldots x_{m+i}}}
           {\lambda x_{m+i+1}.B^{i+1}_{x_0 \ldots x_{m+i+1}}}
\]%
where $B^i$ is a fresh variable of arity $m+i$, and $B^0 = A$ as well as $B^d = C$.
\end{definition}

The intuition is that we $\eta$-expand the occurrence of the variable
with lower arity to match the higher arity. Since each \linketa can
add exactly one lambda, we need as many links as the difference between the
two arities.

\newcommand{\mapdeduplication}{\emph{map-deduplication}\xspace}

\begin{definition}[\mapdeduplication]
  Forall mappings $m_1, m_2\in \mapStore$ such that 
  $m_1 : X \mapsto A^m$ and
  $m_2 : X \mapsto C^n$ and $m < n$
  we remove $m_1$ from \mapStore and
  add to \linkStore the result of $\alignarity{}~m_1~m_2$.
\end{definition}

\begin{theorem}[Fidelity with \mapdeduplication]
  Given a list of unification problems \foUnifPb, such that 
  $\forall t, t\in\subterm{\foUnifPb} \Rightarrow \wellb(t) \lor t \in \maybeeta$,
  if \foUnifPb contains two same \Fo{} variables with different arities,
  then \mapdeduplication guarantees \fullref{prop:fidelity}
\end{theorem}

\begin{proof}[Proof sketch]
  By the definition of \mapdeduplication, any two occurrencies of the same \Fo{} 
  variables $X_1, X_2$
  with different arities are related with \linketa. 
  If one of the two variables is instantiated, the corresponding
  \linketa is triggered instantiating the related variable.
  This allows to make unification fail if $X_1$ and $X_2$ are unified with 
  different terms. Finally, since \foUnifPb contains only terms thar are
  either \wellb or \maybeeta, by \cref{lemma:fidelity-maybeeta},
  we can conclude the proof.
\end{proof}

If we look back the example give at the beginning of this section, we can
deduplicate $\mapping{X}{E}{1}, \mapping{X}{C}{2}$ by removing the first mapping
and adding the auxiliary \linketa: \linketaM{x}{E_{x}}{\lambda y.C_{x y}}.
After deduplication the compiler output is as follows:
% make test ONLY=7001 TEX=tex
\printAlll
  {{{\lambda x.\lambda y.(X\appsep y\appsep x),\lambda x.\lambda y.x},
    {\lambda x.(f\appsep (X\appsep x)\appsep x),Y}}}
  {{{A,\lambda x.\lambda y.x},
    {D,F}}}
  {{{Y,F,0},
    {X,C,2}}}
  {{{\eta,x,E_{x},\lambda y.C_{x y}},
    {\eta,,D,\lambda x.(f\appsep E_{x}\appsep x)},
    {\eta,,A,\lambda x.B_{x}},
    {\eta,x,B_{x},\lambda y.C_{y x}}}}

In this example, $\hoUnifPb_1$ assigns $A$ which triggers $\linkStore_3$ and
then $\linkStore_4$ by \progressetaleft. $C_{yx}$ is therefore
assigned to $x$ (the second variable of its scope). We can finally see the
\progressetaright of $\linkStore_1$: its \rhs is now $\lambda y.y$ (the term $C_{xy}$
reduces to $y$). Since it is no more in \maybeeta, $\lambda y.y$ is unified with
$E_x$. After the execution of the remaining \hstep, we obtain the 
following \Fo{} substitution $\rho = \{X := \lambda x.\lambda y.y, Y := (f\appsep \lambda x.x)\}$.

\section{Handling of \notllambda}\label{sec:beta}

In this section we suppose the unification of the object language between two
terms $t_1$ and $t_2$ to fail each time at least one of the between $t_1$ or
$t_2$ is outside $\llambda$. This means for instance that $X \nUo Y \appsep Z$ and 
$X\appsep Y \nUo X\appsep Y$.

% On
% the other hand, we also point out that the \maybeeta detection spot out
% potential $\eta$-expansion for terms that are not in \llambda. For example,
% $\lambda x.F \appsep G_x$ is considered as \maybeeta, since we have the
% application of term whose argument can reduce to $x$.

% \noteE[inline]{IIRC, second order unification, where variables can stand for functions, is semi-decidable, indeed Huet's algorith enumerates all solutions. Third order, functions that take functions, is undecidable, proved by Dowek. IMO here the problem is that there is no unique solution, (semi)decidability is a secondary point. This paragraph needs fixing.}
% \noteD[inline]{I've rewritten it, it is clearer?}
In general, unification between \notllambda terms admits more then one
solution and committing one of them in the substitution does not guarantee
\cref{prop:complete-ml}. For instance, $X \appsep a \Uo a$ 
admits two different substitutions: $\rho_1 = \{X \mapsto \lambda x.x\}$
and $\rho_2 = \{X \mapsto \lambda \_.a\}$. Prefer one over the other may break
future unifications.

Given a list of unification problems, $\foUnifPb_1\dots
\foUnifPb_n$ with $\foUnifPb_n$ in \notllambda, it is often the case that the resolution of
$\bigwedge_{i=0}^{n-1}\foUnifPb_i$ gives a partial substitution $\rho$, such
that $\rho\foUnifPb_n$ falls again in \llambda.
%
% make test ONLY=7003 TEX=TEX + deactivate beta tex
\printAlll
  {{{X,\lambda x.a},
    {(X\appsep a),a}}}
  {{{A,\lambda x.a},
    {(A\appsep a),a}}}
  {{{X,A,0}}}
  {{}}

In the example above, we see that $\foUnifPb_1$ instantiates $X$ so that
$\foUnifPb_2$ can be solved in \llambda.
On the other hand, we see that, 
\Ue can't solve the compiled problems \hoUnifPb. In
fact, the resolution of $\hoUnifPb_1$ gives the substitution $\sigma = \{ A
\mapsto \lambda x. a\}$, but the dereferencing of $\hoUnifPb_2$ gives the 
non-unifiable problem $(\lambda x. a) \appsep a \nUe a$.

To address
this unification problem, term compilation must recognize and replace
\notllambda terms with fresh variables.
This replacement produces links that we call \linkbeta.

\linkbeta respects \cref{inv:linklhs} and the term on the \rhs has the
following property:

\newcommand{\rhsBetaHead}{\ensuremath{X_{s_1\dots s_n}}}
\newcommand{\rhsBeta}{\ensuremath{\rhsBetaHead\appsep t_1\dots t_m}\xspace}
% \noteE[inline]{Io direi $X_{s_1\ldots s_n}\appsep l_1\ldots l_m$
% ... where S = [s1 .. sn] e L = [l1 .. lm]}

\begin{invariant}[\linkbeta \rhs]
  The \rhs of any \linkbeta has the shape \rhsBeta such that $X$ is a
  unification variable with scope $s_1\dots s_n$\footnote{with $s_1\dots s_n$
  that are distinct names} and $t_1\dots t_m$ is a list of terms. This is
  equivalent to \\\elpiIn{app[uva X S | L]}, where \elpiIn{S}~$= s_1\dots s_n$
  and \elpiIn{L}~$=t_1\dots t_m$.
  \label{inv:beta-rhs}
\end{invariant}

% \linkbeta are put in \linkStore and activated when \rhs falls in \llambda. 
% \noteE[inline]{un po' ridondante con 8.2, non so se serva}

% This property can be relaxed, to accept approximations: a dedicated
% section is given in a future section

% From \cref{lemma:keep-fidelity}, we can deduce the following corollary

% \begin{corollary}
%   Given a \linkbeta \linkbetaM{\Gamma}{X}{T}, if it exists a second link
%   $l\in\linkStore$, then unification fails.   
% \end{corollary}

\subsection{Compilation and decompilation}

Detection of \notllambda is quite simple to implement in the compiler, since it
is sufficient to detect applications with flexible head and argument that
are not in \llambda. The following rule for \notllambda compilation is inserted 
just before rule~\ref{rule:compapp}.


\input{code/comp_beta}

The list \elpiIn{Ag} is split into the list \elpiIn{Pf} and \elpiIn{Extra} such
that \elpiIn{append Pf Extra Ag} and \elpiIn{Pf} is the largest prefix of
\elpiIn{Ag} such that \elpiIn{Pf} is in \llambda. The \rhs of the \linkbeta is
the application of a fresh variable \elpiIn{C} having in scope all the free
variables appearing in the compiled version of \elpiIn{Pf} and \elpiIn{Extra}. The
variable \elpiIn{B}, returned has the compiled term, is a fresh variable having in
scope all the free variables occurring in \elpiIn{Pf1} and \elpiIn{Extra1}.
Note that this construction enforce \cref{inv:beta-rhs}.

% In the following, we pose $X_{s_1\dots s_n}$ to represent a variable $X$ with
% the list of distinct names $s_1\dots s_n$ as scope. Moreover, $X_{s_1\dots
% s_n}\appsep t_1\dots t_m$ is the application of that variable to the list of
% terms $t_1\dots t_m$. Note that \rhsBeta is equivalent to \elpiIn{app[uva N S |
% T]}.

\noteD{Si puo togliere se serve spazio}
\begin{corollary}
  Let \rhsBeta be the \rhs of a \linkbeta, then $m > 0$.
\end{corollary}

\begin{comment}
\begin{proof}[Proof sketch]
  Assume we have a \linkbeta, by contradiction, if $m = 0$, then the original
  \Fo{} term has the shape \elpiIn{fapp[fuva M | Ag]} where \elpiIn{Ag} is a
  list of distinct names (i.e. the list \elpiIn{Extra} is empty). This case is
  however captured by rule~\ref{rule:complam} (from \cref{sec:compilation}) and
  no \linkbeta is produced which contradicts our initial assumption.
\end{proof}
\end{comment}

\noteD{Si puo togliere se serve spazio}
\begin{corollary}
  Let \rhsBeta be the \rhs of a \linkbeta, then $t_1$ either appears in $s_1\dots s_n$ or it is 
  not a name.
\end{corollary}

\begin{comment}
\begin{proof}[Proof sketch]
  By construction, the lists $s_1\dots s_n$ and $t_1\dots t_m$ are built by splitting
  the list \elpiIn{Ag} from the original term \elpiIn{fapp [fuva A|Ag]}.
  $s_1\dots s_n$ is the longest prefix of the compiled terms in \elpiIn{Ag} which is
  in \llambda. Therefore, by definition of \llambda, $t_1$ must appear  
  in $s_1\dots s_n$, otherwise $s_1\dots s_n$ is not the longest prefix in
  \llambda, or it is a term with a constructor of \elpiIn{tm} as functor.  
\end{proof}
\end{comment}

\paragraph{Decompilation}
A failure is thrown if any \linkbeta remains in \linkStore at the
begin of decompilation, i.e. all \linkbeta should be solved before decompilation.

\subsection{Progress}

\newcommand{\progBetaLL}{\emph{\llambda-progress-refine}\xspace}
\newcommand{\progBetaRH}{\emph{\llambda-progress-\rhs}\xspace}
% \newcommand{\progBetaDedup}{\emph{progress-\llambda-dedup}\xspace}
\newcommand{\progBetaFail}{\emph{\llambda-progress-fail}\xspace}

Given a \linkbeta $l$ of the form \linkbetaM{\Gamma}{T}{\rhsBeta}, we provide
$3$ different activation rules:

\begin{definition}[\progBetaLL]
  Given a substitution $\sigma$, where $\sigma t_1$ is a name, say $t$, and
  $t\notin s_1\dots s_n$. If $m = 0$, then $l$ is removed and \lhs is
  unified with \rhsBetaHead. If $m > 0$, then $l$ is replaced by a
  refined version $\linkbetaM{\Gamma}{T}{Y_{s_1\dots s_n,t}\appsep t_2\dots
  t_m}$ with reduced list of arguments and $Y$ being a fresh variable. Moreover,
  the new link \linketaM{\Gamma}{X_{s_1\dots s_n}}{\lambda x.Y_{s_1\dots s_n,x}}
  is added to \linkStore.   

  % A link \linkbetaM{\Gamma}{T}{\rhsBeta} is removed from \linkStore, if given
  % the substitution $\sigma$, $\sigma t_1$ is a name, say $t$, such that, $t
  % \notin s_1\dots s_n$. In this case, let $Y$ a fresh variable, then
  % \linketaM{\Gamma}{X_{s_1\dots s_n}}{\lambda x.Y_{s_1\dots s_n,x}} is added to
  % \linkStore, and 1) if $m = 1$ then $Y_{s_1\dots s_n, t}$ is unified with $T$,
  % 2) otherwise, the refined \linkbeta, \linkbetaM{\Gamma}{T}{M_{s_1\dots
  % s_n,t}\appsep t_2\dots t_m}, is added to \linkStore.
  \label{def:progBetaLL}
  % % \noteE[inline]{non è chiaro. la sostituzione immagino sia la corrente, non se ne esiste una. Poi non è chiaro se otherwise si riferische a in this case. Usa un enumerate}
  % %\noteE[inline]{Is it clearer?}
  % \noteE[inline]{l1 or t1? Forse è più chiaro dire che il ilnk beta viene raffinato con link beta cone meno argomenti, Se poi il numero di argomenti extra è 0 il tutto è in llambda e quindi viene buttato via. In questo modo la terminazione è ancora più chiara perchè si vede già che prima decresce la lista di argomenti e poi il numero di beta}
  % \noteD{L'ho riformulato}
\end{definition}

\begin{definition}[\progBetaRH]
  $l$ is removed from
  \linkStore if \rhsBetaHead is instantiated to a term $t$ and the
  $\beta$-reduced term $t'$ obtained from the application of $t$ to
  $l_1\dots l_m$ is in \llambda. Moreover, $X$ is unified with $t$.
  \label{def:progBetaRH}
\end{definition}

% Example of this `X a = Y a'
% \begin{definition}[\progBetaDedup]
%   Given a \linkbeta $l_1$ and second link $l_2 \in\linkStore$, such that they
%   share the same \lhs. The two \rhs are unified and $l_2$ is
%   removed from \linkStore.
%   \label{def:progBetaDedup}
% \end{definition}

\begin{definition}[\progBetaFail]
  If it exists a link $l' \in \linkStore$ with same \lhs as $l$, or the \lhs 
  of $l$ become rigid, then unification fail.
  \label{def:progBetaFail}
\end{definition}

\begin{lemma}
  \elpiIn{progress} terminates
\end{lemma}

\begin{proof}[Proof sketch]
  Let $l$ a \linkbeta in the store \linkStore. If $l$ is activated by
  \progBetaRH{}, then it disappears from \linkStore and \elpiIn{progress}
  terminates. Otherwise, the \rhs of $l$ is made by a variable applied to $m$
  arguments. At each activation of \progBetaLL, $l$ is replaced by a new
  \linkbeta $l^1$ having $m-1$ arguments. At the $m^{th}$ iteration, the
  \linkbeta $l^m$ has no more arguments and is removed from \linkStore.
  Note that at the $m^{th}$ iteration, $m$ new \linketa have been added to
  \linkStore, however, by \cref{lemma:prog-eta-terminates}, the algorithm
  terminates. Finally \progBetaFail also guarantees termination since 
  it makes \elpiIn{progress} immediately fails.

  % \Cref{def:progBetaRH} makes \elpiIn{progress} terminates, since it makes a
  % \linkbeta disappear from \linkStore. On the other hand, \cref{def:progBetaLL},
  % creates each time a new \linketa and replace the old \linkbeta with a new one.
  % This progression can however triggered at most $m$ times, since each new
  % \linkbeta as a smaller list of applied variables. At the $m^{th}$ progression,
  % the \linkbeta is removed from \linkStore which is now filled by $m$ new
  % \linketa. By \cref{lemma:prog-eta-terminates}, we know that \elpiIn{progress}
  % terminates if \linkStore is made by only \linketa and therefore
  % \elpiIn{progress} still terminates.
  %\noteE[inline]{is it ok?}
  % \noteE[inline]{funziona. per essere più precisi io parlerei di ordine lessicografico (tipico ordine ben fondato usato per dimostrare terminazione). Nl nostro caso è la tripla (argomenti extra dei beta, numero di beta, numero di eta).}
\end{proof}

% \begin{corollary}
%   Given a \linkbeta, the variables occurring in its \rhs are in \llambda.
%   % \noteE[inline]{vuoi dire: le variabili che occorrono nel rhs sono in...?}
%   \noteD[inline]{is it clearer?}
% \end{corollary}

% \begin{proof}[Proof sketch]
%   By construction, the \rhs of \linkbeta has the shape \rhsBeta, $s_1\dots s_n$
%   is in \llambda and all the terms $t_1\dots t_n$ are in \llambda, too. If a
%   \linkbeta is triggered by \progBetaRH, then, by \cref{def:progBetaRH}, that
%   link is removed by \linkStore, and the property is satisfied. If the \linketa
%   is activated by \progBetaLL, then, by \cref{def:progBetaLL}, the new \linkbeta
%   as a variable as a scope which is still in \llambda. 
% \end{proof}

\begin{theorem}[Fidelity with \linkbeta]
  The introduction of \linkbeta guarantees \fullref{prop:fidelity-recovery}
\end{theorem}

\begin{proof}[Proof sketch]
  Let \hoUnifPb a unification problem and $\sigma$ a substitution
  such that $\hoUnifPb \in \notllambda$. 
  If $\sigma\hoUnifPb$ is in \llambda, then by
  \cref{def:progBetaLL,def:progBetaRH}, the \linkbeta associated to the subterm of
  \hoUnifPb have been solved and removed. The
  unification is done between terms in \llambda and by \cref{lemma:fidelity-maybeeta}
  fidelity is guaranteed. If $\sigma\hoUnifPb$ is in \notllambda,
  then, by \cref{def:progBetaFail}, the unification fails, as per the
  corresponding unification in \Fo{}.
\end{proof}

\paragraph{Example of \progBetaLL}
Consider the \linkbeta below:

% make test ONLY=7004 TEX=tex
\printAlll
  {{{X,\lambda x.x},
    {\lambda x.(Y\appsep (X\appsep x)),f}}}
  {{{A,\lambda x.x},
    {B,f}}}
  {{{Y,D,0},
    {X,A,0}}}
  {{{\eta,,A,\lambda x.E_{x}},
    {\eta,,B,\lambda x.C_{x}},
    {\llambda,x,C_{x},(D\appsep E_{x})}}}

\noindent
Initially the \linkbeta \rhs is a variable $D$ applied to the $E_x$.
The first unification problem results in $\sigma =
\{A \mapsto \lambda x.x\}$. In turn this instantiation
triggers $\linkStore_1$ by \progressetaleft 
and $E_x$ is assigned to $x$.
Under this substitution the \linkbeta becomes
\linkbetaM{x}{C_x}{(D \appsep x)}, and by \progBetaLL
it is replaced with the link:
\linketaM{}{E}{\lambda x.D_x}, while $C_x$ is unified with $D_x$. The second unification
problem assigns $f$ to $B$, that in turn activates
the second \linketa ($f$ is assigned to $C$), and then all the remaining links
are solved. The final \Ho substitution is $\sigma = \{A _{} \mapsto \lambda x.x, 
B _{} \mapsto f, C _{x} \mapsto (f\appsep x), 
D _{} \mapsto f, E _{x} \mapsto x, F _{x} \mapsto C_{x} \}$ and is decompiled into $\rho = \{X \mapsto \lambda x.x,
Y \mapsto f\}$.

\paragraph{Example of \progBetaRH}
We can take the example provided in \cref{sec:beta}. The problem is compiled
into:
%
% make test ONLY=7003 TEX=tex
\printAlll
  {{{X,\lambda x.Y},
    {(X\appsep a),a}}}
  {{{A,\lambda x.B},
    {C,a}}}
  {{{Y,B,0},
    {X,A,0}}}
  {{{\llambda,,C,(A\appsep a)}}}

% \todo{Rinominare i print dei problemi}

The first unification problems is solved by the substitution $\sigma = \{A
\mapsto \lambda x.B\}$. The \linkbeta becomes
\linkbetaM{}{C}{((\lambda x.B) \appsep a)} whose \rhs can be $\beta$-reduced to
$B$. $B$ is in \llambda and is unified with $C$. The resolution of the second
unification problem
gives the final substitution $\sigma = \{A \mapsto \lambda x.B, B \mapsto C, C
\mapsto a\}$ which is decompiled into $\rho = \{X \mapsto \lambda x.a, Y \mapsto
a\}$.
 
\subsection{\texorpdfstring{Relaxing \fullref{def:progBetaFail}}{Relaxing progress-llam-fail}}

\newcommand{\progBetaNoLLWait}{\emph{progress-beta-\notllambda}}

% from https://www.cs.mcgill.ca/~bpientka/papers/unif_miller60.pdf
Working with terms in \llambda is sometime too restrictive \cite{Abel2018ExtensionsTM}. 
There exists systems
such as Teyjus~\cite{Nadathur2001} and $\lambda$Prolog~\cite{lamProlog} which 
delay the resolution of \notllambda unification problems if the substitution
is not able to put them in \llambda.

In this section we want to show how we can adapt the unification of the object
language in the meta language by simply adding (or removing) rules to the
\elpiIn{progress} predicate.
%
% make test ONLY=7005 TEX=tex
\printAlll
  {{{(X\appsep a),a},
    {X,\lambda x.a}}}
  {{}}
  {{}}
  {{}}

In the example above, $\foUnifPb_1$ is in \notllambda. \emph{If} the object
language delays the first unification problem waiting $X$ to be
be instantiated in a future unification, we can relax \cref{def:progBetaFail}. 
Instead of failing because the \lhs of the considered \linkbeta $l$ becomes rigid,
we keep it in \linkStore until the head of its \rhs also become rigid.
In this case, since \lhs and \rhs have rigid heads, they can be unified
just before removing $l$ from \linkStore. We can note that this rule trivially
guarantees \fullref{prop:fidelity}. On the other hand, the occur check becomes 
partial: there exists \linkbeta with a non-flexible \lhs.

A second strategy to deal with problem that are in \notllambda is to make
approximations. This is the case for example of the unification algorithm of Coq
used in its type-class solver~\cite{sozeau08}. The approximation consists in
forcing a choice (among the others) when the unification problem is outside
\llambda. For instance, in $X \appsep a \appsep b = Y \appsep b$, the last
argument of the two terms is the same, therefore $Y$ is assigned to $X a$. Note
that this is of course an approximation, since $\sigma = \{X \mapsto \lambda x.Y, Y \mapsto
\_\}$ is another valid substitution for the original problem. We stress the 
fact that, again, our unification procedure in the meta language can be 
accommodated for this new behavior: given a \linkbeta, if \lhs is not in \llambda,
then \elpiIn{progress} can try to align the rightmost arguments and unify
the resulting heads. 

Note that delaying unification outside \llambda can leave \linkbeta during the
decompilation phase. Therefore, new rules to \elpiIn{commit-links} should
be added accordingly.

% \noteD{Paragraph for decompile in case of \maybebeta}
% \todo{cita paper su estensioni a llam via sospensione etc}
\todo[inline]{cita teyjus (1) era 2nd order HO (huet's algorithm), teyjus 2 è llam ma sospende i disagreement pairs fuori da llam}


\section{Actual implementation in Elpi}\label{sec:implementation}

In this paper we show a minimized example. The full code is there.
But we also have to code things in Coq-Elpi.

The main difference between the presentation in the previous sections and
the actual implementation for Coq is that the main loop \hrun is replaced by
the one of Prolog that chains calls to the unification procedure. In order
implement the store of links we resort to Elpi's CLP engine and
use constraints (suspended goals) to represent links, and constraint
handling rules to implement progress operations involving more than one link.

\todo{finish}
about the progress of 1 link:

\begin{elpicode}
link-eta L R :- suspend-condition L R Holes, !,
  declare_constraint (link-eta L R) Holes.
link-eta L R :-
  progress. % e.g. L = R.
\end{elpicode}

about the progress of 2 links:

\begin{elpicode}
constraint link-eta {
  rule (N1 ~$\triangleright$~ G1 ?- link-eta (uvar X LX1) T1) % match
    /  (N2 ~$\triangleright$~ G2 ?- link-eta (uvar X LX2) T2) % remove
    |  (relocate LX1 LX2 T2 T2')             % condition
   <=> (N1 ~$\triangleright$~ G1 ?- T1 = T2').                % new goal
}
\end{elpicode}

Remark how the invariant about uvar arity makes this easy, since LX1 and LX2
have the same length. Also note that N1 only contains the names of the first
link (while relocate runs in the disjoint union) and Elpi ensures that
T2' can live in N1.

\noindent
\section{Related work and conclusion}

Different strategies can be used to unify terms of the object language in the
meta langauge. One initial approach involves integrating \Uo as a procedure
within the ML, outlined as follows:

\begin{elpicode}
  decision X :- X ~\Uo~(all A x\ app [P, x]), finite A,
    pi x\ decision (app [P, x]).
\end{elpicode}

Opting for this method would result in a suboptimal utilization of the logic
programming engine provided by the meta language, as it degrades indexing by
eliminating data from rule heads. Additionally, embedding \Uo within the meta
language is likely to be significantly slower compared to a built-in
solution.

% Paper \cite{10.1145/2966268.2966272} introduces semi-shallow.
Another possibility is to avoid having the application and abstraction nodes
in the syntax tree, and use the ones of meta language, as in the following:

\begin{elpicode}
decision (all A x\ P x) :- finite A, pi x\ decision (P x).
\end{elpicode}

\noindent
However, two reasons justify rejecting this encoding. Firstly, in CIC, it is
not always feasible to adopt it due to the meta language's type system being
too limited to accommodate that of the object language. \\
Secondly, the CIC encoding provided by Elpi is primarily utilized for meta
programming, in order to extend the Coq system. Consequently, it must be able to
manipulate terms that are not known in advance
without relying on introspection primitives such as Prolog's
\texttt{functor} and \texttt{arg}. In this context, constants need to live in
an open world, akin to the \elpiIn{string} data type used in the preceding
examples.

In the literature we could find related encoding of the Calculus of
Constructions~\cite{felty93lics}. The goal of that work was to exhibit
a logic program performing proof checking in CC and hence relate the
proof system of intuitionistic higher-order logic (that animates $\lambda$Prolog
programs) with the Calculus of Constructions. The encoding is hence tailored
toward a different goal, and utilizes three relations to represent the
equational theory of CC. Section 6 contains a discussion about the use of the
unification procedure of the meta language in presence of non ground goals, but
the authors do not aim at exploiting it to the degree we want.\todo{sucks}

\todo{cite isabelle's TC, that are baked in}

Our encoding provides a third option that addresses all the considerations
mentioned earlier. It capitalizes on the benefit of not requiring the recoding
of the unification algorithm of the object language. Instead, it employs the
unification capabilities of the meta language, facilitated by the various links
we establish to manage ``problematic'' subterms. Moreover, our encoding takes
advantage of indexing algorithms and mode analysis for static clause filtering. It's noteworthy
that we only replace the minimum necessary information with variables,
specifically targeting \maybeeta and \notllambda subterms.

Our proposed approach is highly adaptable to
align closely with the behavior of the object language. It is not tightly
coupled with the Coq system but can serve as a flexible framework for meta
programming in any ML.

Furthermore, the unification process we propose is tailored for potential future
implementations of tabled search, incorporating memoization to retrieve
solutions from previous searches.

% ---

% Benefits: less work, reuse efficient ho unif (3x faster), indexing,

% Future: tabling and static analysis (reuse for ML again).

% Very little is Coq specific. Applies to all OL that are not a subsystem of 
% HOL, or for ML that are used for meta programming.

\printbibliography

\clearpage

\input{appendix.tex}

\end{document}