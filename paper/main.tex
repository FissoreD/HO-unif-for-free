\documentclass[sigconf,natbib=false,review]{acmart}
\usepackage[]{biblatex}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
\addbibresource{bib.bib}

\usepackage{myTools}
\usepackage{macros}
\usepackage{enumitem}
\usepackage{intcalc}

% TODO: set this fields
%\setcopyright{cc}
%\setcctype{by}
\copyrightyear{2024}
\acmYear{XXXX 2024}
\acmBooktitle{YYY}
\acmDOI{ZZZZZZZZZZZZ}


% \xspaceaddexceptions{]\}}

\def\elpi{\proglang{elpi}}
\def\coqelpi{\proglang{coq-elpi}}
\def\lambdaprolog{\proglang{$\lambda$-prolog}}
\def\coq{\proglang{coq}}

\newcommand{\library}[1]{\textit{#1}\xspace}
\def\stdpp{\library{stdpp}}
\def\iris{\library{iris}}

\newcommand*{\acronym}[1]{\texttt{#1}\xspace}

\newtheorem{invariant}{Invariant}
\crefname{invariant}{invariant}{invariants}


\def\ol{\acronym{ol}} % object language
\def\ml{\acronym{ml}} % meta language
\def\lf{\acronym{lf}} % logical framework
\def\ho{\acronym{ho}} % higher order
\def\Forall{$\forall$}

\newcommand{\appsep}{\ensuremath{\textcolor{lightgray}{\cdot}}}
\newcommand{\EqualRel}{\ensuremath{=}}
\newcommand{\nEqualRel}{\ensuremath{\new}}
\newcommand{\UnifRel}{\ensuremath{\simeq}}
\newcommand{\nUnifRel}{\ensuremath{\not\simeq}}

\newcommand{\Uo}{\ensuremath{\UnifRel_o}\xspace}
\newcommand{\nUo}{\ensuremath{\nUnifRel_o}\xspace}
\newcommand{\Eo}{\ensuremath{\EqualRel_o}\xspace}
\newcommand{\nEo}{\ensuremath{\nEqualRel_o}\xspace}

\newcommand{\Ue}{\ensuremath{\UnifRel_\lambda}\xspace}
\newcommand{\nUe}{\ensuremath{\nUnifRel_\lambda}\xspace}
\newcommand{\Ee}{\ensuremath{\EqualRel_\lambda}\xspace}
\newcommand{\nEe}{\ensuremath{\nEqualRel_\lambda}\xspace}
\newcommand{\llambda}{\ensuremath{\mathcal{L}_\lambda}\xspace}

\newcommand{\linkbeta}{\texttt{link-}\ensuremath{\beta}\xspace}
\newcommand{\linketa}{\texttt{link-}\ensuremath{\eta}\xspace}

\newcommand{\Fo}{\ensuremath{\mathcal{F}_{\!o}\xspace}} % space non va
\newcommand{\Ho}{\ensuremath{\mathcal{H}_o}\xspace}

\newcommand*{\eqtau}{\ensuremath{\mathrel{\overset{\mathrm{\tau}}{=}}}}

\newcommand{\linketaM}[3]{\ensuremath{#1 \vdash #2 =_\eta #3}}
\newcommand{\linkbetaM}[3]{\ensuremath{#1 \vdash #2 =_\beta #3}}
\newcommand{\substCell}[3]{\ensuremath{#1 \vdash #2 = #3}}
\newcommand{\mapping}[3]{\ensuremath{#1 \mapsto #2^#3}}

\newcommand{\lhs}{\ensuremath{\mathrm{lhs}}\xspace}
\newcommand{\rhs}{\ensuremath{\mathrm{rhs}}\xspace}

\newcommand{\linkStore}{\ensuremath{\mathbb{L}}\xspace}
\newcommand{\mapStore}{\ensuremath{\mathbb{M}}\xspace}
\newcommand{\foUnifPb}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\hoUnifPb}{\ensuremath{\mathbb{T}}\xspace}

\include{pb_printer}

\begin{document}

\title{HO unification from object language to meta language}

\author{Davide Fissore}
\email{davide.fissore@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\author{Enrico Tassi}
\email{enrico.tassi@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\begin{abstract}
  Specifying and implementing a logic from scratch requires significant effort.
  Logical Frameworks and Higher Order Logic Programming Languages provide
  dedicated, high-level Meta Languages (ML) to facilitate this task in two
  key ways: 1) variable binding and substitution are simplified when ML binders
  represent object logic ones; 2) proof construction, and even proof search, is
  greatly simplified by leveraging the unification procedure provided by the ML.
  Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
  $\lambda$Prolog~\cite{miller_nadathur_2012} and
  Isabelle~\cite{10.1007/978-3-540-71067-7_7}
  which have been utilized to implement various formal systems such as
  First Order Logic~\cite{felty88cade},
  Set Theory~\cite{10.1007/BF00881873},
  Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
  Constuctions~\cite{felty93lics}.

  The object logic we are interested in is Coq's~\cite{Coq-refman}
  Dependent Type Theory (DTT),
  for which we aim to implement a unification procedure \Uo using the ML
  Elpi~\cite{dunchev15lpar}, a dialect of $\lambda$Prolog.
  Elpi's equational theory comprises
  $\eta\beta$ equivalence and comes equipped with a
  higher order unification procedure \Ue restricted to the pattern
  fragment~\cite{miller92jsc}.
  We want \Uo to be as powerful as \Ue but on the object logic DTT.
  Elpi also comes with an encoding for DTT that works well
  for meta-programming~\cite{tassi:hal-01637063,tassi:hal-01897468,gregoire:hal-03800154,newtc}.
  Unfortunately this encoding, which we refer to as \Fo,
  ``underuses'' \Ue by restricting it to first-order unification problems only.
  To address this issue, we propose a better-behaved encoding, \Ho,
  demonstrate how to map unification problems in \Fo{}
  to related problems in \Ho, and illustrate
  how to map back the unifiers found by \Ue, effectively implementing
   \Uo on top of \Ue for the encoding \Fo.

  We apply this technique to the implementation of a type-class~\cite{wadler89}
  solver for Coq~\cite{Coq-refman}.
  Type-class solvers are proof search procedures based on
  unification that back-chain designated lemmas, providing essential
  automation to widely used
  Coq libraries such as Stdpp/Iris~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
  and TLC~\cite{10.1007/978-3-642-14052-5_15}. These two libraries
  constitute our test bed.
\end{abstract}

\keywords{Logic Programming, Meta-Programming, Higher-Order Unification, Proof Automation}

\maketitle

\section{Introduction}
\label{sec:intro}

Specifying and implementing a logic from scratch requires significant effort.
Logical Frameworks and Higher Order Logic Programming Languages provide
dedicated, high-level Meta Languages (ML) to facilitate this task in two
key ways: 1) variable binding and substitution are simplified when ML binders
represent object logic ones; 2) proof construction, and even proof search, is
greatly simplified by leveraging the unification procedure provided by the ML.
Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
$\lambda$Prolog~\cite{miller_nadathur_2012} and
Isabelle~\cite{10.1007/978-3-540-71067-7_7}
which have been utilized to implement various formal systems such as
First Order Logic~\cite{felty88cade},
Set Theory~\cite{10.1007/BF00881873},
Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
Constuctions~\cite{felty93lics}.

The object logic we are interested in is Coq's~\cite{Coq-refman}
Dependent Type Theory (DTT), and we want to code a type-class~\cite{wadler89}
solver for Coq~\cite{Coq-refman} using the Coq-Elpi~\cite{tassi:hal-01637063}
meta programming framework.
Type-class solvers are unification based proof search procedures
that combine a set of designated lemmas in order to providing essential
automation to widely used Coq libraries.

As the running example we take the \coqIn{Decide} type class,
from the Stdpp~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
library. The class identifies predicates equipped with a decision procedure.
The following three designated lemmas (called \coqIn{Instances} in the
type-class jargon) state that: 1) the type \coqIn{fin n}, of natural numbers
smaller than \coqIn{n} is finite; 2) the predicate \coqIn{nfact n nf},
linking a natural number \coqIn{n} to its prime factors \coqIn{nf}, is decidable;
3) the universal closure of a predicate has a decision procedure if the
predicate has and if its domain is finite.

\begin{coqcode}
Instance fin_fin n : Finite (fin n).              (* r1 *)
Instance nfact_dec n nf : Decision (nfact n nf).  (* r2 *)
Instance forall_dec A P : Finite A ~$\to$~             (* r3 *)
  ~$\forall$~x:A, Decision (P x) ~$\to$~ Decision (~$\forall$~x:A, P x).
\end{coqcode}

\noindent Under this context of instances a type-class solver is able to prove
the following statement automatically by back-chaining.

\begin{coqcode}
  Check _ : Decision (forall y: fin 7, nfact y 3).       ~\customlabel{goal:g}{(g)}~
\end{coqcode}

\noindent
The encoding of DTT provided by Elpi, that we will discuss at length later in
section~\ref{sec:encodings,sec:lang-spec} and ~\ref{}, is an Higher Order Abstract
Syntax (HOAS) datatype \elpiIn{tm} featuring (among others) the following
constructors:

\begin{elpicode}
type lam  tm -> (tm -> tm) -> tm.     % lambda abstraction
type app  list tm -> tm.              % n-ary application
type all  tm -> (tm -> tm) -> tm.     % forall quantifier
type con  string -> tm.               % constants
\end{elpicode}

\noindent
Following standard $\lambda$Prolog~\cite{miller_nadathur_2012}
the concrete syntax to abstract, at the meta level, an expression
\elpiIn{e} over a variable \elpiIn{x}
is <<\elpiIn{x\ e}>>, and square brackets denote a list of
terms separated by comma. As an example we show the encoding of the Coq term
<<\coqIn{~$\forall$~y:t, nfact y 3}>>:

\begin{elpicode}
all (con"t") y\ app[con"nfact", y, con"3"]
\end{elpicode}

\noindent
We now illustrate the encoding of the three instances above as higher-order
logic-programming rules: capital letters denote rule
parameters; \elpiIn{:-} separates the rule's head from the premises;
\elpiIn{pi w\ p} introduces a fresh nominal constant \elpiIn{w}
for the premise \elpiIn{p}.

\begin{elpicode}
finite (app[con"fin", N]).                            ~\customlabel{clause:r1}{(r1)}~
decision (app [con"nfact", N, NF]).                   ~\customlabel{clause:r2}{(r2)}~
decision (all A x\ app[P, x]) :- finite A,            ~\customlabel{clause:r3}{(r3)}~
  pi w\ decision (app[P, w]).
\end{elpicode}

\noindent
Unfortunately this translation of rule \ref{clause:r3} uses the
predicate \coqIn{P} as a first order term: for the meta
language its type is \elpiIn{tm}.
If we try to backchain the rule \ref{clause:r3} on the encoding of the goal
\ref{goal:g} given below

\begin{elpicode}
decision (all (app[con"fin", con"7"]) y\
  app[con"nfact", y, con"3"]).
\end{elpicode}

\noindent
we obtain an unsolvable unification problem \ref{problem:p}:
the two lists of terms have different lengths!
%The root cause is that
%\ref{problem:p} is an higher order in DTT, but becomes
%first order in the meta language due to the ``naive'' encoding.

\begin{elpicode}
app[con"nfact", y, con"3"] = app[P, y]                 ~\customlabel{problem:p}{(p)}~
\end{elpicode}

\noindent
In this paper we study a more sophisticated encoding of Coq terms allowing
us to rephrase the problematic rule \ref{clause:r3} as follows:

\begin{elpicode}
decision (all A x\ Pm x) :- decomp Pm P A, finite A,   ~\customlabel{clause:r3a}{(r3a)}~
  pi x\ decision (app[P, x]).
\end{elpicode}

\noindent
Since \elpiIn{Pm} is an higher-order unification variable
of type \elpiIn{tm -> tm},
with \elpiIn{x}
in its scope, the unification problem \ref{problem:pa}
admits one solution:

\begin{elpicode}
app[con"nfact", y, con"3"] = Pm y                     ~\customlabel{problem:pa}{(p')}~
Pm = x\ app[con"nfact", x, con"3"]     % assignment for Pm
A = app[con"fin", con"7"]              % assignment for A
\end{elpicode}

\noindent
After unifying the head of rule \ref{clause:r3a} with the goal, Elpi runs
the premise <<\elpiIn{decomp Pm A P}>> that is in charge of bringing the
assignment for \elpiIn{Pm} back to the domain \elpiIn{tm} of Coq terms:

\begin{elpicode}
P = lam A a\ app[con"nfact", a, con"3"]
\end{elpicode}

\noindent
This simple example is sufficient to show that the encoding we seek
is not trivial and does not only concern the head of rules, but the entire sequence
of unification problems that constitute the execution of a logic program.
In fact
the solution for \elpiIn{P} above generates a
(Coq) $\beta$-redex in the second premise (the predicate
under the \elpiIn{pi w\ }\hspace{-0.4em}):

\begin{elpicode}
decision (app[lam A (a\ app[con"nfact", a, con"3"]), w])
\end{elpicode}

\noindent
In turn this redex prevents the rule \ref{clause:r2} to backchain properly since
the following unification problem has no solution:

\begin{elpicode}
app[lam A (a\ app[con"nfact", a, con"3"]), x] =
app[con"nfact", N, NF]
\end{elpicode}
\noindent
~\\
The root cause of the problems we sketched in the running example
is that the unification procedure \Ue of the meta language is not aware
of the equational theory of the object logic, even if both theories
include $\eta\beta$-conversion and admit most general
unifiers for unification problems in the pattern fragment \llambda~\cite{miller92jsc}.

\paragraph{Contributions}
In this paper we discuss alternative encodings of Coq in
Elpi (Section~\ref{sec:encodings}), then we identify a minimal language \Fo{}
in which the problems sketched here can be fully described.
We then detail an encoding \elpiIn{comp} from \Fo{} to \Ho (the language of
the meta language) and a decoding \elpiIn{decomp} to relate the unifiers
bla bla.. TODO citare Teyjus.
The code discussed in the paper can be accessed at the URL:
\url{https://github.com/FissoreD/paper-ho}.

\section{Problem statement} %%%%%%%%%%%%%%%%%%%%%%
\label{sec:problem-statement}

The equational theory of Coq's Dependent Type Theory is very rich. In
addition to the usual $\eta\beta$-equivalence for functions, terms (hence types)
are compared up to proposition unfolding and fixpoint unrolling. Still,
for efficiency and predictability reasons, most form of automatic proof search
employ a unification procedure that captures a simpler one,
just $\eta\beta$, and that solves higher-order problems
restricted to the pattern fragment $\llambda$~\cite{miller92jsc}.
We call this unification procedure \Uo{}.

The equational theory of the meta language Elpi is strikingly similar,
since it it comprises $\eta\beta$ (for the meta language functions), and the
unification procedure \Ue{} solves higher-order problems in
$\llambda$.

In spite of the similarity the link between \Ue{} and \Uo{} is not trivial,
since the abstraction and application term constructors
the two unification procedures deal with are different. For example

\begin{tabular}{lcl}
\elpiIn{x\ f x} & \Ue{} & \elpiIn{f}\\
\elpiIn{lam A x\ app[con"f", x]} & \Uo{} & \elpiIn{con"f"}\\
\elpiIn{lam A x\ app[con"f", x]} & \nUe{} & \elpiIn{con"f"} \\
\elpiIn{P x} & \Ue{} & \elpiIn{x}\\
\elpiIn{app[P, x]} & \Uo{} & \elpiIn{x}\\
\elpiIn{app[P, x]} & \nUe{} & \elpiIn{x}\\
\end{tabular}

\noindent
One could ignore this similarity, and ``just'' describe the object language
unification procedure in the meta language, that is crafting a \elpiIn{unif}
predicate to be used as follows in rule \ref{clause:r3}:

\begin{elpicode}
decision X :- unif X (all A x\ app[P, x]), finite A,
  pi x\ decision (app[P, x]).
\end{elpicode}

\noindent
This choice would underuse the logic programming engine provided by
the metalanguage since by removing any datum from the head of rules
indexing degenerates. Moreover the unification procedure built in the
meta language is likely to be faster than one implemented in it,
especially if the meta language is interpreted as Elpi is.

To state precisely the problem we solve we need a \Fo{} representation
of DTT terms and a \Ho one.
We call \Eo the equality over ground terms in \Fo,
\Ee the equality over ground terms in \Ho,
\Uo the unification procedure we want to implement and
\Ue the one provided by the meta language.
TODO extend \Eo and \Ee with reflexivity on uvars.

\newcommand{\specunif}[3]{
  #3_i \in \llambda \Rightarrow %
    \exists \rho, %
      \rho #3_1 #1 \rho #3_2  %
        \Leftrightarrow #3_1 #2 #3_2 \mapsto \rho' \subseteq \rho
}


\newcommand{\unifcorrect}[3]{
  % \forall \rho #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    #3_i \in \llambda \Rightarrow
      #3_1 #2 #3_2 \mapsto \rho
        \Rightarrow
          \rho #3_1 #1 \rho #3_2  %
}

\newcommand{\unifcomplete}[3]{
  % \forall #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    #3_i \in \llambda \Rightarrow
      % \forall \rho, %
        \rho #3_1 #1 \rho #3_2  %
          \Rightarrow \exists \rho', #3_1 #2 #3_2 \mapsto \rho' \land \rho' \subseteq \rho
}

We write $t_1 \Ue t_2 \mapsto \sigma$ when $t_1$ and $t_2$ unify
with substitution $\sigma$; we write $\sigma t$ for the application of
the substitution to $t$, and $\sigma X = \{ \sigma t | t \in X\}$ when
$X$ is a set; we write $\sigma \subseteq \sigma'$ when $\sigma$ is more
general than $\sigma'$. We assume that the unification of our meta
language is correct:
%
\begin{gather}
  \unifcorrect{\Ee}{\Ue}{t} \label{prop:correct-ml}\\
  \unifcomplete{\Ee}{\Ue}{t}\label{prop:complete-ml}
\end{gather}

\newcommand{\C}[4]{\ensuremath{\langle #1 \rangle}\mapsto(#2,#3,#4)}
\newcommand{\D}[4]{\ensuremath{\langle #1,#2,#3 \rangle^{-1}\mapsto #4}}

We illustrate a compilation $\C{s}{t}{m}{l}$ that
maps a term $s$ in \Fo{} to a term $t$ in \Ho, a variable mapping $m$ and
list of links $l$.
The variable map connects unification variables in \Ho with variables
in \Fo{} and is used to ``decompile'' the assignment,
$\D{\sigma}{m}{l}{\rho}$. Links represent problematic sub-terms which
are linked to the unification variable that stands in their place in the
compiled term. These links are checked for or progress XXX improve....

We represent a logic program \emph{run} in \Fo{} as
a list \emph{steps} $p$ of length $\mathcal{N}$. Each step is a
unification problem between terms $\foUnifPb_{p_l}$ and
$\foUnifPb_{p_r}$ taken from the set of all terms \foUnifPb.
The composition of these steps starting from the
empty substitution $\rho_0$ produces the final
substitution $\rho_\mathcal{N}$.
\footnote{If the same rule is used multiple time in a run we
just consider as many copies as needed of the terms composing the
rules, with fresh unification variables each time}
The initial here $\rho_0$ is the empty substitution
%
\newcommand{\progress}{\ensuremath{\mathrm{progress}}\xspace}
\newcommand{\fstep}{\ensuremath{\mathrm{fstep}}\xspace}
\newcommand{\hstep}{\ensuremath{\mathrm{hstep}}\xspace}
\newcommand{\frun}{\ensuremath{\mathrm{frun}}\xspace}
\newcommand{\hrun}{\ensuremath{\mathrm{hrun}}\xspace}
\newcommand{\stepF}[4]{\ensuremath{\fstep(#1,#2,#3) \mapsto #4}}
\newcommand{\stepFD}[5]{%
\ensuremath{#3 #1_{#2_l} \Uo #3 #1_{#2_r} \mapsto #4 \land #5 = #3 \cup #4}}
\newcommand{\stepH}[6]{\ensuremath{\hstep(#1,#2,#3,#4) \mapsto (#5, #6)}}
\newcommand{\stepHD}[6]{\ensuremath{%
#3 #1_{#2_l} \Ue #3 #1_{#2_r} \mapsto #4 \land \progress(#6,#3 \cup #4) \mapsto (#6',#5)}}
\newcommand{\runF}[3]{\ensuremath{\frun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runFD}[2]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepF{#1}{p}{\rho_{p-1}}{\rho_{p}}}}
\newcommand{\runH}[3]{\ensuremath{\hrun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runHD}[3]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepH{#1}{p}{\sigma_{p-1}}{#3_{p-1}}{\sigma_{p}}{#3_p}}}
\newcommand{\deff}{\ensuremath{\stackrel{{\scriptscriptstyle def}}{=\!=\!\!\!=}}}
%
$$
\begin{array}{l}
\stepF{\foUnifPb}{p}{\rho}{\rho''}
\deff
\stepFD{\foUnifPb}{p}{\rho}{\rho'}{\rho''}\vspace{2pt}\\
\runF{\foUnifPb}{\mathcal{N}}{\rho}
\deff
\runFD{\foUnifPb}{\mathcal{N}}
\end{array}
$$

We simulate each run in \Fo{} with a run in \Ho as follows.
Note that $\sigma_0$ is the empty substitution.
$$
\begin{array}{l}
\stepH{\hoUnifPb}{p}{\sigma}{\linkStore}{\sigma''}{\linkStore'} \deff\vspace{2pt}\\
  \qquad\stepHD{\hoUnifPb}{p}{\sigma}{\sigma'}{\sigma''}{\linkStore}\vspace{2pt}\\
\runH{\foUnifPb}{\mathcal{N}}{\rho} \deff \vspace{2pt}\\
  \qquad \hoUnifPb \times \mapStore \times \linkStore_0 = \{ (t_j,m_j,l_j) | s_j \in \foUnifPb, \C{s_j}{t_j}{m_j}{l_j} \}\vspace{2pt}\\
  \qquad \runHD{\hoUnifPb}{\mathcal{N}}{\linkStore}\vspace{2pt}\\
  \qquad \D{\sigma_{\mathcal{N}}}{\mapStore}{\linkStore_{\mathcal{N}}}{\rho_{\mathcal{N}}}
\end{array}
$$

\noindent
Here \hstep{} is made of two sub-steps: a call to \Ue (on the compiled
terms) and a call to \progress{} on the set of links. We claim the following:

\begin{proposition}[Simulation]\label{prop:simulation}
$\forall \foUnifPb, \forall \mathcal{N},$
$$
  \runF{\foUnifPb}{\mathcal{N}}{\rho}
  \Leftrightarrow
  \runH{\foUnifPb}{\mathcal{N}}{\rho}
$$
\end{proposition}

\noindent
That is, the two executions give the same result. Moreover:

\begin{proposition}[Simulation fidelity]\label{prop:fidelity}
In the context of~ \hrun, if $~\hoUnifPb \subseteq \llambda$ we have that
$\forall p \in 1 \ldots \mathcal{N},$
$$
\stepF{\foUnifPb}{p}{\rho_{p-1}}{\rho_p}
\Leftrightarrow
\stepH{\hoUnifPb}{p}{\sigma_{p-1}}{\linkStore}{\sigma_p}{\_}
$$
\end{proposition}
\noindent
In particular this property guarantees that a \emph{failure} in the \Fo{} run
is matched by a failure in \Ho{} \emph{at the same step}. We consider this
property very important from a practical point of view since it guarantees
that the execution traces are strongly related and in turn this enables a user
to debug a logic program in \Fo{} by looking at its execution trace in
\Ho{}.

XXX permuting hrun does not change the final result if check dooes not fail eagerly

XXX if we want to apply heuristics, we can apply them in decomp to avoid committing to
a non MGU too early


We can define $s_1 \Uo{} s_2$ by specializing the code of \hrun{} to
$\foUnifPb = \{ s_1, s_2 \}$ as follows:
%
$$
\begin{array}{l}
s_1 \Uo s_2 \mapsto \rho \deff \vspace{2pt}\\
\quad\C{s_1}{t_1}{m_1}{l_1} \land \C{s_2}{t_2}{m_2}{l_2}\vspace{2pt}\\
\quad    t_1 \Ue t_2 \mapsto \sigma' \land
    \progress(\{l_1,l_2\},\sigma') \mapsto (L,\sigma'') \land\vspace{2pt}\\
\quad \D{\sigma''}{\{m_1,m_2\}}{L}{\rho}
\end{array}
$$

\begin{proposition}[Properties of \Uo{}]
\begin{gather}
  \unifcorrect{\Eo}{\Uo}{s}\customlabel{prop:correct}{(correct)}\\
\unifcomplete{\Eo}{\Uo}{s}\customlabel{prop:complete}{(complete)}\\
% \forall \rho'\rho,
  \rho s_1 \Eo \rho s_2 \Rightarrow
  \rho' \subseteq \rho \Rightarrow
  \rho's_i \in \llambda \Rightarrow
  \rho' s_1 \Uo \rho' s_2 %\label{prop:simulation}
\end{gather}
\end{proposition}

Properties \ref{prop:correct} and \ref{prop:complete} state, respectively, that
in \llambda the implementation of \Uo is correct, complete and returns the most
general unifier.

\todo[inline]{fix}Property \ref{prop:simulation} states that \Uo, hence our compilation scheme,
is resilient to unification problems outside \llambda solved by
a third party. We believe this property is of practical interest since we
want the user to be able to add heuristics via hand written rules
to the ones obtained by our compilation scheme. A Typical example
is the following problem \ref{problem:q} that is outside \llambda:

\begin{elpicode}
app [F, con"a"] = app[con"f", con"a", con"a"]          ~\customlabel{problem:q}{(q)}~
F = lam x\ app[con"f",x,x]                             ~\customlabel{heuristic:h}{(h)}~
\end{elpicode}

\noindent
Instead of rejecting it our scheme accepts it and guarantees that if
\ref{heuristic:h} is given (after the compilation part of the scheme, as
a run time hint) then ...


\subsection{The intuition in a nutshell}
\label{sec:nutshell}
A term $s$ is compiled in a term $t$ where every
``problematic'' sub term $p$ is replaced by a fresh unification variable $h$
and an accessory link that represent a suspended unification problem
$h \Ue p$. As a result \Ue is ``well behaved'' on $t$, that is it does not
contradict \Eo as it would otherwise do on ``problematic'' terms.
We now define ``problematic'' and ``well behaved'' more formally.

\newcommand{\maybeeta}{\ensuremath{\Diamond\eta}\xspace}
\newcommand{\maybebeta}{\ensuremath{\overline{\llambda}}\xspace}
%\newcommand{\maybebeta}{\ensuremath{\Diamond\beta}\xspace}
\begin{definition}[\maybeeta]\label{def:maybeeta}
  $\maybeeta = \{ t ~|~ \exists \rho, \rho t ~\mathrm{is~an~eta~expansion} \}$
\end{definition}

\noindent
An example of term $t$ in \maybeeta{} is
$\lambda x.\lambda y.F~y~x$
since the substitution
$\rho = \{ F \mapsto \lambda a.\lambda b.fba\}$
makes $\rho t = \lambda x.\lambda y.f x y$
that is the eta long form of $f$. This term is problematic since
its rigid part, the $\lambda$-abstractions, cannot justify a
unification failure against, say, a constant.

\begin{definition}[\maybebeta]\label{def:maybebeta}
  $\maybebeta = \{ X t_1 \ldots t_n ~|~ X t_1 \ldots t_n \not\in \llambda \}$.
\end{definition}

\noindent
An example of $t$ in \maybebeta{} is $F a$ for a constant $a$. Note however tha
an oracle could provide an assignment $\rho = \{ F \mapsto \lambda x.x\}$
that makes the resulting term fall back in \llambda.

\newcommand{\subterm}[1]{\ensuremath{\mathcal{P}(#1)}}
\begin{definition}[Subterms \subterm{t}] The set of sub terms of $t$ is the
  largest set $\\subterm{t}$ that can be obtained by the following rules.
$$
\begin{array}{l}
t \in \subterm{t}\\
t = f t_1\ldots t_n \Rightarrow \subterm{t_i} \subseteq \subterm{t} \land f \in \subterm{t}\\
t = \lambda x.t' \Rightarrow \subterm{t'} \subseteq \subterm{t}\\
\end{array}
$$
\end{definition}

\noindent
We write $\subterm{X} = \bigcup_{t\in X} \subterm{t}$ when $X$ is a set of terms.

\newcommand{\wellb}{\ensuremath{\mathcal{W}}\xspace}
\begin{definition}[Well behaved set]
Given a set of terms $X \subseteq \Ho{}$,
$$
\wellb(X) \Leftrightarrow \forall t \in \subterm{X}, t \not\in (\maybebeta{} ~\cup~ \maybeeta{})
$$
\end{definition}

\noindent

\begin{proposition}[\wellb{}-preservation]\label{prop:nf}
$\forall \hoUnifPb, \forall \linkStore, \forall p, \forall \sigma, \forall \sigma'$
$$
\begin{array}{l}
\wellb(\sigma\hoUnifPb) \land
  \sigma\hoUnifPb_{p_l} \Ue \sigma\hoUnifPb_{p_r} \mapsto {\sigma'}
  \Rightarrow \wellb(\sigma' \hoUnifPb)\\
\wellb(\sigma\hoUnifPb) \land
  \progress(\linkStore,\sigma) \mapsto (\_,\sigma')
  \Rightarrow \wellb(\sigma' \hoUnifPb)
\end{array}
$$
\end{proposition}

\noindent
A less formal way to state \ref{prop:nf} is that \hstep{} and \progress never
``commit'' an unneeded $\lambda$-abstraction in $\sigma$ (a $\lambda$
that could be erased by an $\eta$-contraction),
nor put in $\sigma$ a flexible application outside \llambda{}
(an application node that could be erased by a $\beta$-reduction).

Note that proposition \ref{prop:nf} does not hold for \Uo{} as a whole
since decompilation can introduce (actually restore) terms in
\maybeeta or \maybebeta that were move out of the way
(put in $\linkStore$) during compilation.

\section{Alternative encodings and related work}

Paper \cite{10.1145/2966268.2966272} introduces semi-shallow.

Our encoding of DTT may look ``semi shallow'' since we use the meta-language
lambda abstraction but not its application (for the terms of type \elpiIn{tm}).
A fully shallow encoding unfortunately does not fit our use case, although
it would make the running example work:

\begin{elpicode}
finite (fin N).
decision (nfact N NF).
decision (all A x\ P x) :- finite A, pi x\ decision (P x).
\end{elpicode}

\noindent
There are two reasons for dismissing this encoding. The first one is that
in DTT it is not always possible to adopt it since the type system
of the meta language is too weak to accommodate terms with a variable arity,
like the following example:

\begin{coqcode}
Fixpoint arr T n := if n is S m then T -> arr T m else T.
Definition sum n : arr nat n := ...
Check sum 2   7 8   : nat.
Check sum 3   7 8 9 : nat.
\end{coqcode}

\noindent
The second reason is the encoding for Coq is used for meta programming the
system, hence it must accommodate the manipulation of terms that are now
know in advance (not even defined in Coq) without using introspection
primitives such as Prologs's \texttt{functor} and \texttt{arg}.

In the literature we could find a few related encoding of DTT.
TODO In~\cite{felty93lics} is related and make the
discrepancy between the types of ML and DTT visible. In this case
one needs 4 application nodes. Moreover the objective is an encoding
of terms, proofs, not proof search. Also note the conv predicate,
akin to the unif we rule out.

TODO This other paper~\cite{10.1007/978-3-031-38499-8_25} should also be cited.

None of the encodings above provide a solution to our problem.

\section{Preliminaries: \Fo{} and \Ho}
\label{sec:lang-spec}

In order to reason about unification we provide a description of the
\Fo{} and \Ho languages where unification variables
are first class terms, i.e. they have a concrete syntax. We keep these languages
minimal, for example, we omit the \elpiIn{all} quantifier of DTT we used
in the example in Section~\ref{sec:intro} together with the type notation of
terms carried by the \elpiIn{lam} constructor.
%
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-13pt}

\begin{figure}[H]
  \begin{tabular}{ll}
  \begin{minipage}{0.21\textwidth}
   \inputrawelpicode{code/fo_tm}
  \end{minipage}
  &
  \begin{minipage}{0.24\textwidth}
   \inputrawelpicode{code/ho_tm}
  \end{minipage}
  \end{tabular}\vspace{4pt}
  \caption{The \Fo{} and \Ho languages}\vspace{0.3em}
  \label{code:common-terms}
  \Description[code:common-terms]{code:common-terms}
\end{figure}

\noindent
Unification variables (\elpiIn{fuva} term constructor)
in \Fo{} have no explicit scope:
the arguments of an higher order variable are given via the \elpiIn{fapp}
constructor. For example the term \coqIn{P x} is represented as
\elpiIn{fapp[fuva N, x]}, where \elpiIn{N} is a memory address and
\elpiIn{x} is a bound variable.\\
In \Ho the representation of \coqIn{P x} is instead \elpiIn{uva N [x]},
since unification variables come equipped with an explicit scope.
We say that the unification variable occurrence \elpiIn{uva N L} is in
\llambda if and only if \elpiIn{L} is made of distinct names. The
predicate to test this condition is called \elpiIn{pattern-fragment}:

\input{code/pattern_fragment}

\noindent
Natural numbers represent the memory addresses that
identify unification variables in both languages.
The memory and its associated operations are described below:

\input{code/mem_types}

\noindent
If a memory cell is \elpiIn{none}, then the corresponding unification variable
is not set. \elpiIn{assign} sets an unset cell to the given value, while
\elpiIn{new} finds the first unused address and sets it to \elpiIn{none}.\todo[inline]{is new used?}

Since in \Ho unification variables have a scope, their solution needs to be
abstracted over it to enable the instantiation of a single
solution to different scopes. This is obtained via the \elpiIn{inctx}
container, and in particular via its \elpiIn{abs} binding constructor.
On the contrary a solution to a \Fo variable is a plain term.

\input{code/fo_subst}
\input{code/ho_subst}

\noindent
We call \elpiIn{fsubst} the memory of \Fo{}, while we call \elpiIn{subst}
the one of \Ho.
Both have the invariant that they are not cyclic, TODO: explain.

\input{code/comp_base_types}

\begin{invariant}[Unification variable arity]
  Each variable \elpiIn{A}
  in \Ho has a (unique) arity \elpiIn{N} and each occurrence~
  \elpiIn{(uva A L)} is such that \elpiIn{(len L N)} holds
  \label{inv:uvaarity}
\end{invariant}

\noindent
The compiler establishes a mapping between variables of the two languages.
In order to preserve invariant \ref{inv:uvaarity} we store the
arity of each \elpiIn{hvariable} in the mapping and we reuse an existing
mapping only if the arity matches.

TODO: add ref to \cref{sec:invariant1}

\input{code/alloc_mapping}

\noindent
When a single \elpiIn{fvariable} occurs multiple times with different numbers
of arguments the compiler generates multiple mappings for it, on a first
approximation, and then makes the mapping bijective by introducing
\linketa; this detail is discussed in section \ref{sec:eta}.

As we mentioned in section~\ref{sec:nutshell} the compiler
replaces terms in \maybeeta and \maybebeta with fresh variables
linked to the problematic terms. Each class of problematic terms
has a dedicated link.

\input{code/comp_links}

\noindent
The right hand side of a link, the problematic term, can occur under binders.
To accommodate this situation the compiler wraps \elpiIn{baselink} using
the \elpiIn{inctx} container (see, \ref{data:inctx}).

\begin{invariant}[Link left hand side]\label{inv:linklhs}
  The left hand side of a suspended link
  is a variable.
\end{invariant}

\noindent
New links are suspended by construction.
If the left hand side variable is assigned during a step, then 
the link is considered for progress and possibly eliminated.
This is discussed in \cref{sec:eta} and \cref{sc:beta}.

\subsection{Notational conventions}

When we write \Ho terms outside code blocks we follow the
usual $\lambda$-calculus notation, reserving $f, g, a, b$ for constants,
$x, y, z$ for bound variables and $X, Y, Z, F, G, H$ for unification variables.
However we need to
distinguish between the ``application'' of a unification variable
to its scope and the application of a term to a list of arguments.
We write the scope of unification variables in subscript
while we use juxtaposition for regular application.
Here a few examples:
\vspace{4pt}

\begin{tabular}{ll}
  $f\appsep a$ &  \elpiIn{app[con "f", con "a"]}\\
  $\lambda x.\lambda y.F_{x y}$ & \elpiIn{lam x\ lam y\ uva F [x, y]} \\
  $\lambda x.F_{x} \appsep a$ & \elpiIn{lam x\ app[uva F [x], con "a"]} \\
  $\lambda x.F_{x} \appsep x$ & \elpiIn{lam x\ app[uva F [x], x]} \\
\end{tabular}
\vspace{4pt}

\noindent
When variables $x$ and $y$ can occur in term $t$ we shall write
$t_{xy}$ to stress this fact. 

We write $\sigma = \{~ A_{xy} \mapsto y ~\}$ for the assignment
\elpiIn{abs x\abs y\y} and $\sigma = \{~ A \mapsto \lambda x.\lambda y.y ~\}$
for \elpiIn{lam x\lam y\y}.

When detailing examples we write links as equations between two
terms under a context.
The equality sign is subscripted with
kind of \elpiIn{baselink}. For example $\linkbetaM{x}{A_x}{F_x~a}$ corresponds to:
\begin{elpicode}
abs x\ val (link-beta (uva A [x]) (app[uva F [x],con "a"]))
\end{elpicode}

\noindent
When it is clear from the context we shall use the same syntax for \Fo{} terms
(although we never subscripts unification variables).

\subsection{Equational theory and Unification}

In order to express properties \ref{prop:correct, prop:complete, prop:simulation}
we need to equip \Fo{} and \Ho with term equality,
substitution application and unification.

\paragraph{Term equality: \Eo vs. \Ee} We extend the equational theory
over ground terms to the full languages by adding the reflexivity of
unification variables (a variable is equal to itself).

The first four rules are common to both equalities
and just define the usual congruence over terms, and since
we use an HOAS encoding they also capture $\alpha$-equivalence.
In addition to that \Eo has rules for $\eta$ and $\beta$-equivalence.

\input{code/feq}

\begin{elpicode}
  ~\PYG{k+kd}{type} \PYG{n+nf}{(\Ee)} \PYG{k+kt}{tm -> tm -> o}~.
  con C ~\Ee~fcon C.
  app A ~\Ee~fapp B :- forall2 ~(\Ee)~ A B.
  lam F ~\Ee~flam G :- pi x\ x ~\Ee~x => F x ~\Ee~G x.
  uva N A ~\Ee~fuva N B :- forall2 ~(\Ee)~ A B.
\end{elpicode}

\noindent
The main point in showing these equality tests is to remark how weaker \Ee is,
and to identify the four rules that need special treatment in
the implementation of \Uo.

For reference, \elpiIn{(beta T A R)} reduces away \elpiIn{lam} nodes in head
position in \elpiIn{T} whenever the list \elpiIn{A} provides a corresponding
argument.

\input{code/beta_fo}

\noindent
The \elpiIn{name} predicate holds only on nominal constants (i.e. bound
variables).\footnote{Elpi provides it as a builtin, but one could implement it by
systematically loading the hypothetical rule \elpiIn{name x} every time
a nominal constant is postulated via \elpiInFN{pi x\ }}
The choice of using n-ary application, rather than binary, is to make it
easy to access the application's head. The price we pay is that substituting
an application in the head of an application should be amended by
``flattening'' \elpiIn{fapp} nodes, that is the job of \elpiIn{napp}.
\footnote{Note that \elpiIn{napp} is an artefact of formalization of \Fo{}
we do in this presentation and, as we explain later,
no equivalent of \elpiIn{napp} is needed in \Ho.}
Finally note that the cut operator is inessential, it could be
removed at the cost of a verbose test on the head of \elpiIn{L}
in the second rule about \elpiIn{fapp}: \elpiIn{L}'s head
can be \elpiIn{fcon}, \elpiIn{flam} or a name.


\paragraph{Substitution application: $\rho s$ and $\sigma t$}

Applying the substitution corresponds to dereferencing a term with respect to
the memory. To ease the comparison we split \Fo dereferencing into a
\elpiIn{fder} step and a \elpiIn{napp} one. The former step replaces references
to memory cells that are set with their values, and has a corresponding
operation in \Ho, namely \elpiIn{deref}. On the contrary \elpiIn{napp}
has no corresponding operation in \Ho. The reasons for this asymmetry is
that an \elpiIn{fapp} node with a flexible head is always mapped
to a \elpiIn{uva} (as per \cref{sec:compilation} and \cref{sec:beta}),
preventing nested applications to materialize.

\input{code/fderef}

\noindent
Applying the substitution in \Ho{} is very similar, with
the caveat that assignments have to be moved to the
current scope, i.e. renaming the \elpiIn{abs}-bound variables
with the names in the scope of the unification variable occurrence.

\input{code/deref}

\noindent
Note that move strongly relies on invariant \ref{inv:uvaarity}: the length
of the arguments of all occurrences of a unification variable and the
number of abstractions in its assignment have to match. In turn
this grants that \elpiIn{move} never fails.

\input{code/move}

\paragraph{Term unification: \Uo vs. \Ue}

In this paper we assume to have an implementation of \Ue that satisfies
properties~\ref{prop:correct-ml} and~\ref{prop:complete-ml}. Although we provide an
implementation in the appendix (that we used for testing purposes) we only
describe its signature here. Elpi is expected to provide this brick, as well as
any other implementation of $\lambda$Prolog.

\input{code/ue_type}

\noindent
The only detail worth discussing is the fact that the procedure updates a
substitution, rather than just crafting one as presented in
section~\ref{sec:problem-statement}. The reason is that the algorithm folds
over a term, updating a substitution while it traverses it.\todo[inline]{explain better}

% The first three rules unify terms with same rigid heads, and
% call the unification relation on the sub-terms. If $t_1$ (resp. $t_2$) is an
% assigned variables, $t_1$ is dereferenced to $t_1'$ (resp. $t_2'$) and the
% unification is called between $t_1'$ and $t_2$ (resp. $t_1$ and $t_2'$). If both
% terms are unification variables, we test that their arguments are in the pattern
% fragment, we allocate a new variable $w$ in $\rho_1$ such that $w$ is the
% pruning of the arguments of $t_1$ and $t_2$, we assign both $t_1$ and $t_2$ to
% $w$ and return the new mapping $\rho_2$ containing all the new variable
% assignment. Finally, if only one of the two terms is an unification variable
% $v$, after having verified that $v$ does not occur in the other term $t$, we
% bind $v$ to $t$ and return the new substitution mapping.

% \old

% A key property needed in unification is being able to verify if two terms are
% equal wrt a given equational theory. This relation allow to compare terms under
% a certain substitution mapping, so that any time a variable $v$ is assigned in a
% subterm, a dereferencing of $v$ is performed. After variable dereferencing, the
% test for equality is continued on the new-created subterm.

% The base equality function over terms can be defined as follows:

% The solution we are proposing aim to overcome these unification issues by 1)
% compiling the terms $t$ and $u$ of the OL into an internal version $t'$ and $u'$
% in the ML; 2) unifying $t'$ and $u'$ at the meta level instantiating meta
% variables; 3) decompiling the meta variable into terms of the OL; 4) assigning
% the variables of the OL with the decompiled version of their corresponding meta
% variables. We claim that $t$ and $u$ unify if and only if $t'$ and $u'$ unify
% and that the substitution in the object language is the same as the one returned
% by the ML. \todo[inline]{same or $\supseteq$ or $\subseteq$}

% In the following section we explain how we deal with term (de)compilation and
% links between unification variables.

\section[Compilation: fo\_tm to tm]{Basic simulation of \Fo{} in \Ho{}}
\label{sec:compilation}

In this section we describe a basic compilation scheme that we refine
later, in the following sections. This scheme is sufficient to implement
an \Uo{} that respects $\beta$-conversion for terms in \llambda. The extension to
$\eta\beta$-conversion is described in Section \ref{sec:eta} and the support
for terms outside \llambda in Section \ref{sec:beta}.

\subsection{Compilation}
\label{sec:compilation}
\todo[inline]{manca beta normal in entrata}

The main task of the compiler is to recognize \Fo{} variables standing
for functions and map them to higher order variables in \Ho.
In order to bring back the substitution from \Ho{} to \Fo{} the compiler
builds a ``memory map'' connecting the the kind of variables using routine
\ref{clause:malloc}.

The signature of the \elpiIn{comp} predicate below allows for the generation of
links (suspended unification problems) that play no role in this section
but play a major role in \cref{sec:eta} and \cref{sec:beta}.
With respect to \cref{sec:problem-statement} the signature also allows
for updates to the substitution.  The code below uses that possibility
in order to allocate space for the variables, i.e. sets their memory
address to \elpiIn{none} (a details not worth mentioning in the
previous discussion).

\input{code/comp_base}

\noindent
This preliminary version of \elpiIn{comp} recognizes \Fo{} variables
applied to a (possibly empty) duplicate free list of names.
Note that compiling \elpiIn{Ag} cannot create new mappings nor links, since \elpiIn{Ag}
is made of bound variables and the hypothetical rule loaded by \elpiIn{comp-lam}
(see below) grants this property.

\input{code/comp_lam}

\noindent
In the code above the syntax \elpiIn{pi x y\..} is syntactic sugar for
iterated \elpiIn{pi} abstraction, as in \elpiIn{pi x\ pi y\..}.

The auxiliary function \elpiIn{close-links} tests if the bound variable
\elpiIn{v} really occurs in the link. If it is the case the link is wrapped into
an additional \elpiIn{abs} node binding \elpiIn{v}. In this way links generated
deep inside the compiled terms can be moved outside their original context
of binders.

\input{code/comp_close_links}

\noindent
Note that we could remove the first rule, whose solve purpose is to make
links more readable by pruning unused context entries.

\subsection{Execution}
\label{sec:execution}

A step in \Ho consists in unifying two terms and reconsidering all
links for progress. If any of the two tasks fail we say that the entire step
fails, and it is at this granularity that we can relate steps in the
two languages.


\input{code/hstep}

\noindent
Note tha the infix notation \elpiIn{((A ~\Ue~B) C D)} is syntactic sugar for
\elpiIn{((~\Ue\!\!\!~) A B C D)}.

Reconsidering links is a fixpoint, since the progress of a link can update the
substitution and in turn enable another link to progress.

\input{code/progress}

\noindent
In the base compilation scheme \elpiIn{progress1} is the identity
on both the links and the substitution, so the fixpoint trivially terminates.
Sections \ref{sec:eta} and \ref{sec:beta} add rules to \elpiIn{progress1}
and justify why the don't hinder termination. For brevity we omit the code
that applies the substitution \elpiIn{S1} to all terms in \linkStore.

Since compilation moves problematic terms out of the sigh of \Ue{},
that procedure can only perform a partial occur check. For example the
unification problem $X \Ue f~Y$ cannot generate a cyclic substitution alone,
but should be disallowed if a $\linkStore$ contains a link like
$\linketaM{}{Y}{\lambda z.X_z}$: We don't know yet if $Y$ will feature
a lambda in head position, but we surely know it contains $X$, hence
$f~Y$ and that fails the occur check.
The procedure \elpiIn{occur-check-links} is in charge of ensuring that
each link does not represent a (suspended) unification problem doomed
to fail because of occur check. This check is needed in order to
guarantee \cref{prop:fidelity} (simulation fidelity).

\subsection{Substitution decompilation}

Decompiling the substitution requires to first force the
progress of links and then allocating new unassigned variables
in the substitution for \Fo{} and finally decompiling all
assignments. Note that \cref{inv:linklhs} and the
occur check allows us to update the subst.


\input{code/decompile}

TODO: What is commit-links and complete-mapping?, maybe complete-mapping can be
hidden in the code rendering?

\noindent
Decompiling an assignment requires to turn abstractions into
lambdas. For aestetic purposes we also eta-contract the result
(not needed since \Fo{} equality can do that)

\input{code/decompm}

\noindent
Finally decompiling a term is trivial, now that we have an extended
mapping containing all unassigned variables \Ue may have introduced.

\input{code/decomp}

\noindent
Note that we use beta to build fapp nodes when needed (if Ag is empty
no \elpiIn{fapp} node should appear).


\begin{invariant}

  TODO: dire che il mapping è bijective
  \label{inv:map-bijective}
\end{invariant}

\subsection{Definition of \Uo and its properties}

\input{code/unif_fo}

The code given so far applies to terms in $\beta\eta$-normal form where
unification variables in \Fo{} can occur non linearly but always with
the same number of arguments, and where their arguments are distinct names
(as per \llambda).

\begin{lemma}[Compilation round trip] If
  \elpiIn{comp S T [] M [] _ [] _} then \elpiIn{decomp M T S}
\end{lemma}
\begin{proof}[Proof sketch]
trivial, since the terms are beta normal beta just builds an app.
\end{proof}


\begin{lemma}
Properties \ref{prop:correct} and
\ref{prop:complete} hold for the implementation of \Uo above
\end{lemma}
\begin{proof}[Proof sketch]
 In this setting \Ee is as strong as
\Eo on ground terms. What we have to show is that whenever two different \Fo
terms can be made equal by a substitution $\rho$ (plus the \ref{clause:beta1}
and \ref{clause:beta2} if needed) we can find this $\rho$ by finding
a $\sigma$ via \Ue{} on the corresponding \Ho terms and by decompiling it.
If we look at the \Fo{} terms, the are two interesting cases:
\begin{itemize}
\item \elpiIn{fuva X ~\Uo~s}. In this case after \elpiIn{comp} we have
  $Y \Ue t$ that succeeds with $\sigma = \{ Y \mapsto t\}$ and
  $\sigma$ is decompiled to $\rho = \{ Y \mapsto s\}$.
\item \elpiIn{fapp[fuva X|L] ~\Uo~s}. In this case
 we have $Y_{\vec{x}} \Ue t$ that succeeds with
 $\sigma = \{ \vec{y} \vdash Y \mapsto t[\vec{x}/\vec{y}]\}$ that in turn
 is decompiled to $\rho = \{ Y \mapsto \lambda \vec{y}.s[\vec{x}/\vec{y}]\}$.
 Thanks to \ref{clause:beta1}
 $(\lambda \vec{y}.s[\vec{x}/\vec{y}])~\vec{x} \Eo s$.
\end{itemize}
Since the mapping is a bijection occur check in \Ho{} corresponds to occur
check in \Fo{}.
\end{proof}

\begin{lemma} Properties simulation (\ref{prop:simulation}) and
fidelity (\ref{prop:fidelity}) hold
\end{lemma}
\begin{proof}[Proof sketch]
Since \elpiIn{progress1} is trivial \fstep and \hstep are the same, that is
in this
context where input terms are $\beta\eta$-normal and we disregard $\eta$-equivalence
\Ue is equivalent to \Uo.
\end{proof}

\subsection{Limitations of by this basic scheme}
\label{sec:basic-comp-limitations}
The basic compilation scheme is not about to
deal wit the following problem:
\printAlll
  {{{\lambda x y.X \appsep y \appsep x, \lambda x y.x},{\lambda x. f \appsep (X \appsep x) \appsep x,Y}}}
  {{}}
  {{}}
  {{}}
% \begin{gather}
% \lambda x y.F \appsep y \appsep x = \lambda x y.x \label{eq:unif-eta1}\\
% \lambda x. f \appsep (F \appsep x) \appsep x = G \label{eq:unif-eta2}
% % \lambda x. f \appsep (F \appsep x) \appsep x = f \appsep (\lambda y.y) \label{eq:unif-eta2}
% \end{gather}

\noindent Note that here $X$ is used with different arities, moreover
in the second problem the left hand side happens to be an
eta expansion (of $f (\lambda y.y)$) only after we discover (at run time)
that $X = \lambda x\lambda y.y$ (i.e. that $X$ discards the $x$ argument).
Both problems are addressed in the next two sections.
  
% \subsection{Example}

% OK

% \begin{elpicode}
% Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%       , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr z (s z) ] % $\lambda x.g (F x) = \lambda x.g a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% \end{elpicode}

% KO

% \begin{elpicode}
%   Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%   , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr 0 1   % $A = \lambda x.x$
%            , pr 2 3 ] % $A a = a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% lam x\ app[f, app[X, x]] = Y,
%   lam x\ x) = X.
% \end{elpicode}

% \otext{Goal: $s_1 \Uo s_2$ is compiled into $t_1 \Ue t_2$}
% \otext{What is done: uvars \elpiIn{fo_uv} of OL are replaced into uvars \elpiIn{ho_uv} of the ML}
% \otext{Each \elpiIn{fo_uv} is linked to an \elpiIn{ho_uv} of the OL}
% \otext{Example needing the compiler v0 (tra l'altro lo scope è ignorato):\\ \elpiIn{lam x\ app[con"g",app[uv 0, x]] ~\Uo~lam x\ app[con"g", c"a"]}}
% \otext{Links used to instantiate vars of elpi}
% \otext{After all links, the solution in links are compacted and given to coq}
% \otext{It is not so simple, see next sections (multi-vars, eta, beta)}


% The compilation step is meant to recover the higher-order variables of the OL,
% expressed in a first order way, by replacing them with higher-order variables in
% the ML. In particular, every time a variable of the OL is encountered in the
% original term, it is replaced with a meta variable, and if the OL variable is
% applied to a list of distinct names $L$, then this list becomes the scope of the variable.
% For all the other constructors of
% \elpiIn{tm}, the same term constructor is returned and its arguments are
% recursively compiled. The predicate in charge for term compilation is:

% \elpiIn{type comp tm -> tm -> links -> links -> subst -> subst -> o}.

% \noindent
% where, we take the term of the OL, produce the term of the ML, take a list
% of link and produce a list of new links, take a substitution and return a
% new substitution.

% In particular, due to programming constraints, we need to drag the old subst and
% return a new one extended, if needed, with the new declared meta-variables.

% The following code
% %
% \begin{elpicode}
%   kind link type.
%   type link nat -> nat -> nat -> subst.
% \end{elpicode}
% %
% \noindent
% defines a link, which is a relation between to variables indexes, the first
% being the index of a OL variable and the second being the index of a ML
% variable. The third integer\todo[inline]{integer or nat?} is the number of term in the
% scope of the two variables, or equivalently, in a typed language, their arity.

% As an example, let's study the following unification problem (a slightly
% modified version from \cref{sec:intro}):

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Uo~
%     lam x\ app [c"decision", app[uv 0, x]]
% \end{elpicode}

% \noindent
% we have the main unification problem where the nested \elpiIn{app} nodes have
% lists of different lengths making the unification to fail. The compilation of
% these terms produces a new unification problem with the following shape:

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Ue~
%     lam x\ app [c"decision", uv 1 [x]]
% \end{elpicode}

% \noindent
% The main difference is the replacement of the subterm \elpiIn{app[uv 0, x]} of
% the OL with the subterm \elpiIn{uv 0 [x]}. Variable indexes are chosen by the
% ML, that is, the index \elpiIn{0} for that unification variable of the OL term
% has not the sam meaning of the index \elpiIn{0} in the ML. There exists two
% different substitution mapping, one for the OL and one for the ML and the indexes
% of variable point to the respective substitution.

% decomp che mappa abs verso lam
% \noindent
% \otext{An other example: \\
%   \elpiIn{lam x\ app[f, app[X, x]] = Y, (lam x\ x) = X.}}

% \section{Use of multivars}

% Se il termine initziale è della forma

% \begin{elpicode}
%   app[con"xxx", (lam x\ lam y\ Y y x), (lam x\ f)]
%   =
%   app[con"xxx",X,X]
% \end{elpicode}

% allora se non uso due X diverse non ho modo di recuperare il quoziente che mi manca.

% a sto punto consideriamo liste di problemi e così da eliminare sta xxx senza
% perdità di generalità (e facciamo problemi più corti, e modellizziamo anche la
% sequenza)

\section{Handling of \maybeeta}\label{sec:eta}
$\eta$-reduction is an equivalence relation where a term of the form
$\lambda x.t \appsep x$ can be converted to $t$ any time $x$ does not occur as a
free variable in $t$. We call $t$ the $\eta$-contraction of
$\lambda x. t \appsep x$.

Following the compilation scheme of \cref{sec:compilation} the
unification problem \foUnifPb is compiled as follows:
%
\printAlll
  {{{\lambda x. X \appsep x, f}}}
  {{{\lambda x. A_x, f}}}
  {{{X,A,1}}}
  {{}}

\noindent
While $\lambda x.X \appsep x \Uo{} f$ does admit the solution
$\rho = \{~ X \mapsto f ~\}$, the corresponding problem in
\hoUnifPb does not:
\elpiIn{lam x\ uva A [x]} and
\elpiIn{con"f"} start with different, rigid, term constructors hence
\Ue{} fails.

In order to guarantee \cref{prop:simulation} we detect
lambdas that can disappear by eta contraction (\cref{sec:etadetection}) and
we modify the compiled terms by putting fresh unification variables
in their place: the problematic term is moved 
from  \hoUnifPb to \linkStore (\cref{sec:etacomp}). The compilation
of the problem \foUnifPb above is refined to: 
%
\printAlll
  {{{\lambda x.X \appsep x,f}}}
  {{{A,f}}}
  {{{X,B,1}}}
  {{{\eta,,A,\lambda x.B_x}}}

\noindent
As per \cref{inv:linklhs} the term on the left is a variable, and its
right counterpart is the
term in \maybeeta, and that term has the following property:

\begin{invariant}[\linketa \rhs]
  The \rhs of any \linketa %in \linkStore 
  has the shape $\lambda x.t$
  and $t$ is not a lambda. 
  %where $t_x$ is a \maybeeta term and $x$ is free in $t$.
  \label{inv:link-eta-right}
\end{invariant}

\linketa are kept in the link store \linkStore during execution
and activated when some conditions hold on \lhs or \rhs.
Link activation is implemented by extending the \elpiIn{progress1}
predicate (defined in \cref{sec:execution}).

\subsection{Detection of \maybeeta}\label{sec:etadetection}

When compiling a term $t$ we need to determine if any
subterm $s \in \subterm{t}$ that is of the form $\lambda x. r$,
where $x$ occurs in $r$, can be a $\eta$-expansion, i.e. if
there exists a substitution $\rho$ such that $\rho (\lambda x.r) \Eo s$.
The detection of lambda abstractions that can ``disappear''
is not as trivial as it may seems, here a few examples:
%
\begin{center}
  \begin{tabular}{lll}
    %Term & Status & Evidence \\\hline
    $\lambda x. f \appsep (A \appsep x)$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.x ~\}$ \\
    $\lambda x. f \appsep (A \appsep x) \appsep x$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.a ~\}$\\
    $\lambda x. f \appsep x \appsep (A \appsep x)$ & $\not\in\maybeeta$ &\\
    $\lambda x. \lambda y. f \appsep (A \appsep x) \appsep (B \appsep y \appsep x)$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.x,~ B \mapsto \lambda y.\lambda x.y ~\}$
  \end{tabular}
\end{center}
\vspace{4pt}

% In the examples above, the first term is a \maybeeta since $A_x$ can
% reduce to $x$ by setting $A_x = \lambda x.x$, 
% the second one is not a \maybeeta since it exists no substitution
% for $A_x$ such that $A_x$ reduces to $x$ and $x$ is not free in the subterm $f \appsep x$.
\noindent
The first two examples are easy, and show how a unification variable can expose
or erase a variable and turn the resulting term in an $\eta$-expansion or not.\\
The third example shows that when a variable occurs outside the scope of a unification
variable it cannot be erased and can hence prevent a term from being an $\eta$-expansion.\\
The last example shows the recursive nature of the check we need to implement.
The term starts with a spine of two lambdas hence the whole term
is in \maybeeta iff the inner term $\lambda y.f\appsep (A \appsep x) \appsep (B \appsep y \appsep x)$
is in \maybeeta itself. If it is, it could $\eta$-contract to
$f \appsep (A \appsep x)$ making $\lambda x.f \appsep (A \appsep x)$ a potential
$\eta$-expansion.\\

We can now define more formally how \maybeeta terms are detected together with
its auxiliary functions:

\todo[inline]{the compiler must do beta normal!!!!}
\newcommand{\reduceto}{\emph{may-contract-to}}
\begin{definition}[\reduceto]
  A term $s$ \reduceto{} a name $x$ if there exists a
  substitution $\rho$ such that $\rho s \Eo{} x$.
\end{definition}

\begin{lemma}\label{lem:reduceto}
A $\beta$-normal term $s = \lambda x_1 \ldots x_n.t$
%, where $x, x_1\ldots x_n$ can occur in $t$, 
\reduceto{} $x$ only if one of the following three conditions holds:
\begin{enumerate}
  \item $n = 0$ and $t = x$;
  \item $t$ is the application of $x$ to a list
     of terms $l$ and each $l_i$ \reduceto{} $x_i$
     (e.g. $\lambda x_1 \ldots x_n.x \appsep x_1 \ldots x_n \Eo{} x$) ;
  \item $t$ is a unification variable with scope
    $W$, and for any $v \in \{ x, x_1 \ldots x_n \}$,
    there exists a $w_i \in W$, such that $w_i$ \reduceto{} $v$
    (if $n = 0$ this is equivalent to $x \in W$).
\end{enumerate}
\end{lemma}
\begin{proof}[Proof sketch]
Since our terms are in $\beta$-normal form there is only
one rule that can play a role (namely \ref{clause:eta1}),
hence if the term $s$ is not exactly $x$ (case 1)
it can only be an $\eta$-expansion of $x$, or a unification
variable that can be assigned to $x$, or a combination of both.
If $s$ begins with a lambda, then the lambda can only disappear by $\eta$
contraction. In that case the term $t$ under the spine of binders for
$x_1\ldots x_n$ can either be $x$ itself applied to terms that can
\reduceto{} these variables (case 2), or a unification variable
that can be assigned to that application (case 3).
\end{proof}

\noindent
Note that this condition does not require the term to be in \llambda.
\todo[inline]{Is this relevant}

\newcommand{\occursrigid}{\emph{occurs-rigidly}}
\newcommand{\occurrigid}{\emph{occur-rigidly}}
\begin{definition}[\occursrigid]\label{def:occrigid}
  A name $x$ \occursrigid{} in a $\beta$-normal term $t$, if $\forall \rho, x \in
  \subterm{\rho t}$
\end{definition}
In other words $x$ \emph{\occursrigid} in $t$ if it occurs in $t$
outside of the scope of unification variables since an instantiation
is allowed to discard $x$ from the scope of the unification variable.
Note that $\eta$-contraction cannot make $x$ disappear, since the
variables being erased by $\eta$-contraction are locally bound inside $t$.

We can now derive the implementation for \maybeeta detection:

\newcommand{\testmaybeeta}{\emph{maybe-eta}\xspace}
\begin{definition}[\testmaybeeta]\label{def:testmaybeeta}
  Given a $\beta$-normal term
  $s = \lambda x_1 \ldots x_n.t$, \testmaybeeta{} $s$ holds if any
  of the following holds:
  \begin{enumerate}
    \item $t$ is a constant or a variable applied to the arguments
      $l_1 \ldots l_m$ such that 
      $m \geq n$ and for every $i$ such that $1 \leq i \leq m-n$
      the term  $l_i$
      \reduceto{} $x_i$, and
      no $x_i$ \occursrigid{} in $l_1 \ldots l_{m-n-1}$;
    \item $t$ is a
      unification variable with scope $W$ and
      for each $x_i$ there exists a $w_j \in W$ such that $w_j$
      \reduceto{} $x_i$.
  \end{enumerate}
\end{definition}
\begin{lemma}[\maybeeta detection]\label{lem:maybeeta}
  If $t$ is a $\beta$-normal term and \testmaybeeta{} $t$ holds,
  then $t \in \maybeeta$.
\end{lemma}
\begin{proof}[Proof sketch]
Follows from \cref{def:occrigid} and \cref{lem:reduceto}
\end{proof}

\noindent
Remark that the converse of \cref{lem:maybeeta} does not hold: 
there exists a term $t$ satisfying the criteria (1) of
\cref{def:testmaybeeta} that is not in $\maybeeta$, i.e.
there exists no substitution $\rho$ such that $\rho t$ is an
$\eta$-expansion. A simple counter example is
$\lambda x. f \appsep (A \appsep x) \appsep (A \appsep x)$
since $x$ does not \occurrigid{} in the first argument
of $f$,
and the second argument of $f$ \reduceto{} $x$.
In other words $A \appsep x$
may either use or discard $x$, but our analysis does not
take into account that \emph{the same
term} cannot have two contrasting behaviors.

As we will see in the rest of this section this is not a problem
since it does not break
\cref{prop:simulation} nor \cref{prop:fidelity}.
% A term in \maybeeta{} is compiled to a
% unification variable and a link (see \cref{sec:etacomp}):
% the link makes progress (see \cref{sec:etaprogress})
% in the same step in which the
% variable is instantiated, and that compensates
% for this coarse analysis.

% The implementation we propose for the \maybeeta relation is given below.

% \input{code/maybe_eta}

% Here a complex maybeeta example
% \begin{gather}
%   T = \lambda y. f \appsep A_{xy} \appsep (B \appsep a \appsep (\lambda z.y\appsep C_z)) \appsep D_x
% \end{gather}

\subsection{Compilation}\label{sec:etacomp}

% Thanks to the \elpiIn{maybe-eta} predicate, we can detect ``$\eta$-problematic''
% terms and, consequently replace them with fresh \Ho unification variables at
% compilation time. The code below illustrate how this relation is used to for
% term compilation.
The following rule is inserted just before rule~\ref{rule:complam} from the code in
\cref{sec:compilation}.

\input{code/comp_eta}

\noindent
The rule triggers when the input term \elpiIn{flam F} is in
\maybeeta. It compiles it to \elpiIn{lam F1} but puts the fresh
variable \elpiIn{A} in its place. The variable sees all the names free in
\elpiIn{lam F1}. The critical part of this rule is the creation of the \linketa,
which relates the variable \elpiIn{A} with \elpiIn{lam F1}.
This link clearly validates \cref{inv:linklhs}.

\begin{corollary}
  The \rhs of any \linketa has exactly one lambda abstraction, hence
  the rule above respects \cref{inv:link-eta-right}.
\end{corollary}

\begin{proof}[Proof sketch]
  By contradiction, suppose that the rule above triggered and that
  the \rhs of the link is $\lambda x.\lambda y.t_{xy}$.
  If $\testmaybeeta{}~\lambda y.t_{xy}$ holds the recursive call to
  \elpiIn{comp} (made by \elpiIn{comp-lam}) must have put a fresh variable
  in its place, so this case is impossible.
  Otherwise, if $\testmaybeeta{}~\lambda y.t_{xy}$ does not hold, also
  $\testmaybeeta{}~\lambda x.\lambda y.t_{xy}$ does not hold, contradicting
  the assumption that the rule triggered.
\end{proof}

TODO: W preservation \cref{prop:nf}

\subsection{Progress}\label{sec:etaprogress}

\linketa are meant to delay the unification of ``problematic'' terms until
we know for sure if the head lambda has to be $\eta$-contracted or not.

\newcommand{\progressetaleft}{\emph{progress-$\eta$-left}}
\begin{definition}[\progressetaleft]\label{def:progressetaleft}
A link \linketaM{\Gamma}{X}{T} is removed from \linkStore when
$X$ becomes rigid. There are two cases:
\begin{enumerate}
  \item if $X = a$ or $X = y$ or $X = f \appsep a_1\ldots a_n$
    we unify the $\eta$-expansion of the $X$ with $T$, that is we run
    $\lambda x.X \appsep x\Ue{} T$  (under
    the context $\Gamma$)
  \item if $X = \lambda x.t$ we run $X \Ue{} T$.
  \todo[inline]{do we have the name case in the code?}
\end{enumerate}
\end{definition}

\newcommand{\progressetaright}{\emph{progress-$\eta$-right}}
\begin{definition}[\progressetaright]\label{def:progressetaright}
A link \linketaM{\Gamma}{X}{T} is removed from \linkStore when
$\testmaybeeta~T$ does not hold (anymore) and by $\eta$-contracting
$T$ to $T'$ (if possible, else $T' = T$) and executing $X \Ue{} T'$ (under
the context $\Gamma$).
\todo[inline]{there was a note about T' having a rigid head, TO BE FIXED}
\end{definition}

There is a third case in which a link is removed from \linkStore, namely
when the \lhs is assigned to another variable that is the \lhs of another
\linketa.

\newcommand{\progressetadedup}{\emph{progress-$\eta$-deduplicate}}
\begin{definition}[\progressetadedup]\label{def:progressetadedup}
  A link \linketaM{\Gamma}{X_{\vec{s}}}{T} is removed from \linkStore when
  another link \linketaM{\Delta}{X_{\vec{r}}}{T'} is in  \linkStore.
  By \cref{inv:uvaarity} the length of $\vec{s}$ and $\vec{r}$ is the same
  hence we can move the term $T'$ from $\Delta$ to $\Gamma$ by renaming its
  bound variables, i.e. $T'' = T'[\vec{r}/\vec{s}]$.
  We then run $T \Ue{} T''$ (under the context $\Gamma$).
\end{definition}
  
TODO: prove \cref{prop:nf}: we never commit a \maybeeta{} term in
$\sigma$ since we run \Ue{} only when we know that the 
terms are no more \maybeeta, and when \lhs is no more a variable or \rhs is 
no more a \maybeeta, the link is removed from \linkStore.

\begin{lemma}
  \elpiIn{progress} terminates.
  \label{lemma:prog-eta-terminates}
\end{lemma}

\begin{proof}[Proof sketch]
  Rules \cref{def:progressetaleft,def:progressetaright} and
  \cref{def:progressetadedup} remove one link from \linkStore, hence they
  cannot be applied indefinitely.
  Moreover each rule only relies on terminating operations such as \Ue,
  $\eta$-contraction, $\eta$-expansion, relocation (a recursive copy of a
  finite term).
  % The addition of rules for \elpiIn{progres1} complicates the function
  % \elpiIn{progress}. We can note, however, that they do not prevent the
  % termination of \elpiIn{progress}. 1) If a link is activated it is removed from
  % \linkStore and the recursive call to \elpiIn{progress} will have a smaller
  % list of links to recurse on. Moreover, link activation only runs terminating
  % instructions (such as unification). 2) If a link is deduplicated, the
  % termination of \elpiIn{progress} is still guaranteed since again we reduce
  % \linkStore and the instructions run by link deduplications are all
  % terminating. 3) If a link is neither activated nor deduplicated, i.e. it
  % remains suspended, then \linkStore remains unchanged like the substitution;
  % therefore, \elpiIn{if (L = L1, S1 = S2)} succeeds and \elpiIn{progress}
  % terminates.
\end{proof}

\paragraph{Example of \progressetaleft}

The example at the beginning of \cref{sec:eta}, once
$\sigma = \{~ A \mapsto f ~\}$, triggers this rule since the link
becomes \linketaM{}{f}{\lambda x.B_{x}} and the \lhs is a constant.
In turn the rule runs $\lambda x.f \appsep x \Ue{} \lambda x.B_{x}$,
resulting in $\sigma = \{~ A \mapsto f ~;~ B_{x} \mapsto f ~\}$.
Decompilation the generates $\rho = \{~ X \mapsto f ~\}$, since
$X$ is mapped to $B$ and
$f$ is the $\eta$-contracted version of $\lambda x.f \appsep x$.

\paragraph{Example of \progressetaright}\todo[inline]{TODO}



A second example, showing the activation of a link when the \rhs is no more a
\maybeeta, is given in \cref{sec:invariant1}, since we need to work with
variables used with different arities. This example represent the run of the
unification problems proposed at \cref{sec:basic-comp-limitations}

\paragraph{Example of \progressetadedup}

A very basic example of \linketa deduplication, is given below:
% make test ONLY=7002 TEX=tex
\printAlll
  {{{\lambda x.(X\appsep x),\lambda x.(Y\appsep x)}}}
  {{{A,C}}}
  {{{X,B,1},
    {Y,D,1}}}
  {{{\eta,,A,\lambda x.B_{x}},
    {\eta,,C,\lambda x.D_{x}}}}

\noindent
The result of $A \Ue{} C$ is that the two \linketa share the same \lhs.
By unifying the two \rhs we get
$\sigma = \{ A~ \mapsto C, B \mapsto D ~\}$.
In turn, given the map \mapStore, this second assignment is decompiled to
$\rho = \{~ X \mapsto Y ~\}$ as expected.

\todo[inline]{I don't get this TODO}
TODO: we can have $\lambda x. F_x$ in the substitution if we know that $F$ does
not reduce to $T x$ where x is not free in $T$.

\section{Enforcing Invariant~\ref{inv:uvaarity}}
\label{sec:invariant1}

We report here the problem given in \cref{sec:basic-comp-limitations} where
$X$ is used with two different arities and the output of the compilation does
not respect \cref{inv:map-bijective} (merging the two mappings
for $s$ would break \cref{inv:uvaarity}).
In this section we explain how to replace the duplicate mapping with some
\linketa{} in order to restore the invariants.
% make test ONLY=7001 TEX=tex
\printAlll
  {{{\lambda x.\lambda y.(X\appsep y\appsep x),\lambda x.\lambda y.x},
    {\lambda x.(f\appsep (X\appsep x)\appsep x),Y}}}
  {{{A,\lambda x.\lambda y.x},
    {D,F}}}
  {{{X,E,1},
    {Y,F,0},
    {X,C,2}}}
  {{{\eta,,D,\lambda x.(f\appsep E_{x}\appsep x)},
    {\eta,,A,\lambda x.B_{x}},
    {\eta,x,B_{x},\lambda y.C_{y x}}}}

We see that the \elpiIn{maybe-eta} as identified $\lambda xy.X \appsep y \appsep
x$ and $\lambda x.f\appsep (X \appsep x) \appsep x$ and the compiler has
replaced them with $A$ and $D$ respectively.
% $A$ is linked with $\lambda x.B_x$, $B$
% has arity $1$ and is $\eta$-linked with $\lambda y.C\appsep y \appsep x$ and $D$
% is linked to the term $\lambda x.f \appsep E_{x}~x$. 
However, the mapping \mapStore breaks \cref{inv:map-bijective}: the \Fo{}
variable $X$ is mapped to two different \Ho variables. To address this problem
we adjust the compiler's output with a \elpiIn{map-deduplication} procedure.

\newcommand{\alignarity}{\emph{align-arity}}
\begin{definition}[\alignarity] Given two mappings
  $m_1 : X \mapsto A^m$ and
  $m_2 : X \mapsto C^n$ where $m < n$ and $d = n - m$,
  $\alignarity{}~ m_1 ~ m_2$ generates the following $d$ links, one
  for each $i$ such that $0 \leq i < d$,
\[%
  \linketaM{x_0 \ldots x_{m+i}}
           {B^i_{x_0 \ldots x_{m+i}}}
           {\lambda x_{m+i+1}.B^{i+1}_{x_0 \ldots x_{m+i+1}}}
\]%
where $B^i$ is a fresh variable of arity $m+i$, and $B^0 = A$ as well as $B^d = C$.
\end{definition}

The intuition is that we $\eta$-expand the occurrence of the variable
with lower arity to match the higher arity. Since each \linketa can
add exactly one lambda, we need as many links as the difference between the
two arities.

\newcommand{\mapdeduplication}{\emph{map-deduplication}}

\begin{definition}[\mapdeduplication]
  Forall mappings $m_1, m_2\in \mapStore$ such that 
  $m_1 : X \mapsto A^m$ and
  $m_2 : X \mapsto C^n$ and $m < n$
  we remove $m_1$ from \mapStore and
  add to \linkStore the result of $\alignarity{}~m_1~m_2$.
\end{definition}

If we look back the example give at the beginning of this section, we can
deduplicate $\mapping{X}{E}{1}, \mapping{X}{C}{2}$ by removing the first mapping
and adding the auxiliary \linketa: \linketaM{x}{E_{x}}{\lambda y.C_{x y}}.
After deduplication the compiler output is as follows:
% make test ONLY=7001 TEX=tex
\printAlll
  {{{\lambda x.\lambda y.(X\appsep y\appsep x),\lambda x.\lambda y.x},
    {\lambda x.(f\appsep (X\appsep x)\appsep x),Y}}}
  {{{A,\lambda x.\lambda y.x},
    {D,F}}}
  {{{Y,F,0},
    {X,C,2}}}
  {{{\eta,x,E_{x},\lambda y.C_{x y}},
    {\eta,,D,\lambda x.(f\appsep E_{x}\appsep x)},
    {\eta,,A,\lambda x.B_{x}},
    {\eta,x,B_{x},\lambda y.C_{y x}}}}
\todo[inline]{TODO: non so se serva spiegare l'esecuzione (in commento)}
% After unification of the two terms, $X$ is assigned to $\lambda x.\lambda y.x$.
% This assignment makes $l_2$ to progress since the \lhs is materialized and by
% unification, between $X$ and $\lambda x.Y_{x}$, $Y_x$ is instantiate to $\lambda
% y.x$. Once $Y_x$ is instantiated, $l_1$ can progress, and set $H_{xy}$ to $x$.
% After all these progresses, $l_1$ and $l_2$ are remove from \linkStore and the
% \elpiIn{progress} fixpoint terminates. Next, the second unification problem is
% run, and $Z$ is set to $f\appsep(\lambda x.x)$. This unification wakes up $l_3$
% and since $Z$ starts with the \elpiIn{app} node, the $\eta$-expanded version of
% $Z$ is unified with $\lambda x.f \appsep G_{x}~x$ and $G_x$ is set to $x$.
% As last step, the last link is progressed and the final \Ho substitution is
% $\{X _{} \mapsto \lambda x.\lambda y.x, Y _{x} \mapsto \lambda y.x, 
% G _{yx} \mapsto y, Z _{} \mapsto f~\lambda x.x, 
% H _{x} \mapsto \lambda y.y\}$.
% The decompilation phase is only charged, in this example to solve the mappings,
% since no suspended links remain. The only mapping in the list is
% \mapping{F}{H}{2}, which will assign the $F$ variable in \Fo{} to $\lambda xy.y$

\todo[inline]{dire che preserviamo l'invariante che tutte le variable sono fully-applied
}
\section{Handling of \maybebeta}\label{sec:beta}

% On
% the other hand, we also point out that the \maybeeta detection spot out
% potential $\eta$-expansion for terms that are not in \llambda. For example,
% $\lambda x.F \appsep G_x$ is considered as \maybeeta, since we have the
% application of term whose argument can reduce to $x$.

\todo[inline]{IIRC, second order unification, where variables can stand for functions, is semi-decidable, indeed Huet's algorith enumerates all solutions. Third order, functions that take functions, is undecidable, proved by Dowek. IMO here the problem is that there is no unique solution, (semi)decidability is a secondary point. This paragraph needs fixing.}
Until now, we have only dealt we unification of terms in \llambda. However, we
want the unification relation to be more robust so that it can work with terms
in \maybebeta. In general, unification in \maybebeta admits more then one
solution and commiting one of them in the substitution does not guarantee
prop.~\ref{prop:complete}. For instance, $X \appsep a \Uo a$ is a unification
problem admits two different substitutions: $\rho_1 = \{X \mapsto \lambda x.x\}$
and $\rho_2 = \{X \mapsto \lambda \_.a\}$. Prefer one over the other may break
future unifications.

It is the case that, given a list of unification problems, $\foUnifPb_1\dots
\foUnifPb_n$ with $\foUnifPb_n$ in \maybebeta, the resolution of
$\bigwedge_{i=0}^{n-1}\foUnifPb_i$ gives a partial substitution $\rho$, such
that $\rho\foUnifPb_n$ falls again in \llambda.
%
% make test ONLY=7003 TEX=TEX + deactivate beta tex
\printAlll
  {{{X,\lambda x.Y},
    {(X\appsep a),a}}}
  {{{A,\lambda x.B},
    {(A\appsep a),a}}}
  {{{Y,B,0},
    {X,A,0}}}
  {{}}

In the example above, we see that $\foUnifPb_1$ instantiates $X$ so that
$\foUnifPb_2$, can be solved in \llambda.
\todo[inline]{it is even a ground term, there is no unification left to perform actually}
On the other hand, we see that, 
\Ue can't solve the compiled problems \hoUnifPb. In
fact, the resolution of $\hoUnifPb_1$ gives the substitution $\sigma = \{ A
\mapsto \lambda x. B\}$, but the dereferencing of $\hoUnifPb_2$ gives the 
non-unifable problem $(\lambda x. B) \appsep a \Ue a$.

In order to
encompass\todo[inline]{not sure has the right meaning}
this unification, term compilation should capture the
terms $t$ in \maybebeta and replace them with fresh varaibles $v$.
\todo[inline]{we use capitals for unif variables}
As per
\maybebeta, the variables $v$ and the terms $t$ are linked through a \linkbeta.

\linkbeta guarantees \cref{inv:linklhs} and the term on the \rhs has the
following property:

\begin{invariant}[\linkbeta \rhs]
  The \rhs of any \linkbeta has the shape $X~t_1\dots t_n$ such that $X$ is a
  flexible term and $t_1\dots t_n$ is not in \llambda.
\end{invariant}

\linkbeta are put in \linkStore and activated when \rhs falls in \llambda. 
\todo[inline]{un po' ridondante con 8.2, non so se serva}

% This property can be relaxed, to accept approximations: a dedicated
% section is given in a future section
\begin{corollary}
  If the \lhs of a \linkbeta is instantiated to a rigid term and its \rhs
  counterpart is still in \maybebeta,
  the original unification problem is not in \llambda
  % \todo[inline]{non capisco cosa vuoi dire con "the current...". Data la prova sotto vuoi dire che il problem originale sarebbe stato fuori... e quindi falliamo}
  \todo[inline]{Is it clearer?}
  and the unification fails.
\end{corollary}

\begin{proof}[Proof sketch]
  Given $X \appsep t_1\dots t_n \Ue t$ where $t$ is a rigid term and
  $t_1\dots t_n$ is not in \llambda. By construction, $X \appsep t_1\dots t_n$
  is replaced with a variable $V$, and the \linkbeta \linkbetaM{\Gamma}{V}{X
  \appsep t_1\dots t_n} is created. The unification instantiates $V$ to $t$,
  making the \lhs of the link a rigid term, while \rhs is still in \maybebeta.
  The original problem is in fact outside \llambda and unification fails.
\end{proof}

\subsection{Compilation}

Detection of \maybebeta is quite simple to implement in the compiler, since it
is sufficient to capture applications with flexible head and argument that
are not in \llambda.

\input{code/comp_beta}

The list \elpiIn{Ag} is split into the list \elpiIn{Pf} and \elpiIn{Extra} such
that \elpiIn{append Pf Extra Ag} and \elpiIn{Pf} is the largest prefix of
\elpiIn{Ag} such that \elpiIn{Pf} is in \llambda. The \rhs of the \linkbeta is
the application of a fresh variable \elpiIn{C} having in scope all the free
variables appearing in the compiled version of \elpiIn{Pf} and \elpiIn{Extra}. The
variable \elpiIn{B}, returned has the compiled term, is a fresh variable having in
scope all the free variables occurring in \elpiIn{Pf1} and \elpiIn{Extra1}

\newcommand{\rhsBetaHead}{\ensuremath{X_{s_1\dots s_n}}}
\newcommand{\rhsBeta}{\ensuremath{\rhsBetaHead\appsep t_1\dots t_m}\xspace}
% \todo[inline]{Io direi $X_{s_1\ldots s_n}\appsep l_1\ldots l_m$
% ... where S = [s1 .. sn] e L = [l1 .. lm]}
\todo[inline]{Is it clearer?}

In the following, we pose $X_{s_1\dots s_n}$ to represent a variable $X$ with
the list of distinct names $s_1\dots s_n$ as scope. Moreover, $X_{s_1\dots
s_n}\appsep t_1\dots t_m$ is the application of that variable to the list of
terms $t_1\dots t_m$. Note that \rhsBeta is equivalent to \elpiIn{app[uva N S |
T]}.

\begin{invariant}
  The \rhs of a \linkbeta has the shape \rhsBeta.
\end{invariant}

\begin{corollary}
  Let \rhsBeta be the \rhs of a \linkbeta, then $m > 0$.
\end{corollary}

\begin{proof}[Proof sketch]
  By contradiction, if $m = 0$, then the original \Fo{} term
  has the shape \elpiIn{fapp[fuva M | Ag]} where \elpiIn{Ag} is a list of
  distinct names (i.e. the list \elpiIn{Extra} is empty). This case is however
  captured by rule~\ref{rule:complam} (from \cref{sec:compilation}) and no
  \linkbeta is produced: a contradiction.
\end{proof}

\begin{corollary}
  Let \rhsBeta be the \rhs of a \linkbeta, then $t_1$ either appears in $s_1\dots s_n$ or it is 
  not a name.
\end{corollary}

\begin{proof}[Proof sketch]
  By construction, the lists $s_1\dots s_n$ and $t_1\dots t_m$ are built by splitting
  the list \elpiIn{Ag} from the original term \elpiIn{fapp [fuva A|Ag]}.
  $s_1\dots s_n$ is the longest prefix of the compiled terms in \elpiIn{Ag} which is
  in \llambda. Therefore, by definition of \llambda, $t_1$ must appear  
  in $s_1\dots s_n$, otherwise $s_1\dots s_n$ is not the longest prefix in
  \llambda, or it is a term with a constructor of \elpiIn{tm} as functor.  
\end{proof}

\todo[inline]{Dire che maybe eta fa il detect anche su 
termini che non sono il llambda, oppure dirlo in section of maybeeta + dare un
esempio?}

\subsection{Progress}

\newcommand{\progBetaLL}{\emph{progress-beta-\llambda}}
\newcommand{\progBetaRH}{\emph{progress-beta-rigid-head}}

The activation of a \linkbeta is performed when its \rhs falls under \llambda
under a given substitution.

\begin{definition}[\progBetaLL]
  A link \linkbetaM{\Gamma}{T}{\rhsBeta} is removed from \linkStore, if given
  the substitution $\sigma$, $\sigma l_1$ is a name, say $t$, such that, $t
  \notin s_1\dots s_n$. In this case, let $Y$ a fresh variable, then
  \linketaM{\Gamma}{X_{s_1\dots s_n}}{\lambda x.Y_{s_1\dots s_n,x}} is added to
  \linkStore, and 1) if $m = 1$ then $Y_{s_1\dots s_n, t}$ is unified with $T$,
  2) otherwise, the refined \linkbeta, \linkbetaM{\Gamma}{T}{M_{s_1\dots
  s_n,t}\appsep t_2\dots t_m}, is added to \linkStore.
  \label{def:progBetaLL}
  % \todo[inline]{non è chiaro. la sostituzione immagino sia la corrente, non se ne esiste una. Poi non è chiaro se otherwise si riferische a in this case. Usa un enumerate}
  \todo[inline]{Is it clearer?}
\end{definition}

\begin{definition}[\progBetaRH]
  A link \linkbetaM{\Gamma}{X}{\rhsBeta} is removed from
  \linkStore if \rhsBetaHead is instantiated to a term $t$ and the
  $\beta$-reduced term $t'$ obtained from the application of $t$ to
  $l_1\dots l_m$ is in \llambda. Moreover, $X$ is unified to $t$.
  \label{def:progBetaRH}
\end{definition}

\begin{lemma}
  \elpiIn{progress} terminates
\end{lemma}

\begin{proof}[Proof sketch]
  \Cref{def:progBetaRH} makes \elpiIn{progress} terminates, since it makes a
  \linkbeta desappear from \linkStore. On the other hand, \cref{def:progBetaLL},
  creates each time a new \linketa and replace the old \linkbeta with a new one.
  This progression can however triggered at most $m$ times, since each new
  \linkbeta as a smaller list of applied variables. At the $m^{th}$ progression,
  the \linkbeta is removed from \linkStore which is now filled by $m$ new
  \linketa. By \cref{lemma:prog-eta-terminates}, we know that \elpiIn{progress}
  terminates if \linkStore is made by only \linketa and therefore
  \elpiIn{progress} still terminates.
  \todo[inline]{is it ok?}
\end{proof}

\begin{corollary}
  Given a \linkbeta, the variables occurring in its \rhs is in \llambda.
  % \todo[inline]{vuoi dire: le variabili che occorrono nel rhs sono in...?}
  \todo[inline]{is it clearer?}
\end{corollary}

\begin{proof}[Proof sketch]
  By construction, the \rhs of \linkbeta is of the form \rhsBeta, $s_1\dots s_n$
  is in \llambda and all the terms $t_1\dots t_n$ are in \llambda, too. If a
  \linkbeta is triggered by \progBetaRH, then, by \cref{def:progBetaRH}, that
  link is removed by \linkStore, and the property is satisfied. If the \linketa
  is activated by \progBetaLL, then, by \cref{def:progBetaLL}, the new \linkbeta
  as a variable as a scope which is still in \llambda. 
\end{proof}

\paragraph{Example of \progBetaLL} 
A simple example of \linkbeta progression due to \progBetaLL is given below:

% make test ONLY=7004 TEX=tex
\printAlll
  {{{X,\lambda x.x},
    {\lambda x.(Y\appsep (X\appsep x)),a}}}
  {{{A,\lambda x.x},
    {B,a}}}
  {{{Y,D,0},
    {X,A,0}}}
  {{{\eta,,A,\lambda x.E_{x}},
    {\eta,,B,\lambda x.C_{x}},
    {\beta,x,C_{x},(D\appsep E_{x})}}}

The \linkbeta in \linkStore has a variable $D$ applied to the variable $E_x$.
The first unification problem, $\hoUnifPb_1$ produces the substitution $\sigma =
\{A \mapsto \lambda x.x\}$. This instantiation triggers $\linkStore_1$ which
before its removal, assignes $E$ to $\lambda x.x$. Now, the \linkbeta is
\linkbetaM{x}{C_x}{(D \appsep x)}. This link is replaced with the couple of
links: \linkbetaM{x}{C_x}{F_x}, \linketaM{}{E}{\lambda x.D_x}. $\hoUnifPb_2$
assignes $B$ which activates $\linkStore_2$, and then all the remaining links
are solved. The final \Ho substitution is $\sigma = \{A = \lambda x.x, B = a,
C_x = a, D = \lambda \}$ and is decompiled into $\rho = \{X \mapsto \lambda x.x,
Y \mapsto a\}$.

\paragraph{Example of \progBetaRH}
We can take the example provided in \cref{sec:beta}. The problem is compiled
into:
%
% make test ONLY=7003 TEX=tex
\printAlll
  {{{X,\lambda x.Y},
    {(X\appsep a),a}}}
  {{{A,\lambda x.B},
    {C,a}}}
  {{{Y,B,0},
    {X,A,0}}}
  {{{\beta,,C,(A\appsep a)}}}

The first unification, $\hoUnifPb_1$, gives the substitution $\sigma = \{A
\mapsto \lambda x.B\}$. The \linkbeta, $\linkStore_1$, becomes
\linkbetaM{}{C}{((\lambda x.B) \appsep a)} whose \rhs can be $\beta$-reduced to
$B$. $B$ is in \llambda and is unified with $C$. The resolution of $\hoUnifPb_2$
gives the final substitution $\sigma = \{A \mapsto \lambda x.B, B \mapsto C, C
\mapsto a\}$ which is decompiled into $\rho = \{X \mapsto \lambda x.a, Y \mapsto
a\}$.
 
\subsection{Tricky examples}

\begin{elpicode}
  triple ok (@lam x\ @app[@f, @app[@X, x]]) @Y,
  triple ok @X (@lam x\ x),
  triple ok @Y @f
\end{elpicode}

\begin{elpicode}
% @okl 22 [
%   triple ok (@lam x\ @lam y\ @app[@Y, y, x]) @X,
%   triple ok (@lam x\ @f) @X,
% ].
\end{elpicode}

\section{First order approximation}

\otext{Coq can solve this: \coqIn{f 1 2 = X 2}, by setting X to f 1}
\otext{We can re-use part of the algo for $\beta$ given before}


\section{Unif encoding in real life}
\otext{Il ML presentato qui è esattamente elpi}
\otext{Il OL presentato qui è esattamente coq}
\otext{Come implementatiamo tutto ciò nel solver}

\section{Results: stdpp and tlc}
\otext{How may rule are we solving?}
\otext{Can we do some perf test}

\section{Conclusion}

\printbibliography

\clearpage

\input{appendix.tex}

\end{document}