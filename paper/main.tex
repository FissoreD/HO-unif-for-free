\documentclass[sigconf,natbib=false,review]{acmart}
\usepackage[]{biblatex}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
\addbibresource{bib.bib}

\usepackage{myTools}
\usepackage{macros}
\usepackage{enumitem}

% TODO: set this fields
%\setcopyright{cc}
%\setcctype{by}
\copyrightyear{2024}
\acmYear{XXXX 2024}
\acmBooktitle{YYY}
\acmDOI{ZZZZZZZZZZZZ}


% \xspaceaddexceptions{]\}}

\def\elpi{\proglang{elpi}}
\def\coqelpi{\proglang{coq-elpi}}
\def\lambdaprolog{\proglang{$\lambda$-prolog}}
\def\coq{\proglang{coq}}

\newcommand{\library}[1]{\textit{#1}\xspace}
\def\stdpp{\library{stdpp}}
\def\iris{\library{iris}}

\newcommand*{\acronym}[1]{\texttt{#1}\xspace}

\newtheorem{invariant}{Invariant}
\crefname{invariant}{invariant}{invariants}


\def\ol{\acronym{ol}} % object language
\def\ml{\acronym{ml}} % meta language
\def\lf{\acronym{lf}} % logical framework
\def\ho{\acronym{ho}} % higher order
\def\Forall{$\forall$}

\newcommand{\appsep}{\ensuremath{\textcolor{lightgray}{\cdot}}}
\newcommand{\EqualRel}{\ensuremath{=}}
\newcommand{\nEqualRel}{\ensuremath{\new}}
\newcommand{\UnifRel}{\ensuremath{\simeq}}
\newcommand{\nUnifRel}{\ensuremath{\not\simeq}}

\newcommand{\Uo}{\ensuremath{\UnifRel_o}\xspace}
\newcommand{\nUo}{\ensuremath{\nUnifRel_o}\xspace}
\newcommand{\Eo}{\ensuremath{\EqualRel_o}\xspace}
\newcommand{\nEo}{\ensuremath{\nEqualRel_o}\xspace}

\newcommand{\Ue}{\ensuremath{\UnifRel_\lambda}\xspace}
\newcommand{\nUe}{\ensuremath{\nUnifRel_\lambda}\xspace}
\newcommand{\Ee}{\ensuremath{\EqualRel_\lambda}\xspace}
\newcommand{\nEe}{\ensuremath{\nEqualRel_\lambda}\xspace}
\newcommand{\llambda}{\ensuremath{\mathcal{L}_\lambda}\xspace}

\newcommand{\linkbeta}{\texttt{link-}\ensuremath{\beta}\xspace}
\newcommand{\linketa}{\texttt{link-}\ensuremath{\eta}\xspace}

\newcommand{\Fo}{\ensuremath{\mathcal{F}_{\!o}\xspace}} % space non va
\newcommand{\Ho}{\ensuremath{\mathcal{H}_o}\xspace}

\newcommand*{\eqtau}{\ensuremath{\mathrel{\overset{\mathrm{\tau}}{=}}}}

\newcommand{\linketaM}[3]{\ensuremath{#1 \vdash #2 =_\eta #3}}
\newcommand{\linkbetaM}[3]{\ensuremath{#1 \vdash #2 =_\beta #3}}
\newcommand{\substCell}[3]{\ensuremath{#1 \vdash #2 = #3}}
\newcommand{\mapping}[3]{\ensuremath{#1 \mapsto #2^#3}}

\newcommand{\lhs}{\ensuremath{\mathrm{lhs}}\xspace}
\newcommand{\rhs}{\ensuremath{\mathrm{rhs}}\xspace}
\def\phantx{\phantom{x}}

\newcommand{\printMinipage}[2]{
  \listlength{#2}
  \foreach \x [count=\i] in #2
    {
      \begin{minipage}{3cm}
        $#1_\i : \x$ %
      \end{minipage}
      \ifthenelse{\equal{\i}{\thellength}}{}{
        \ifthenelse{\isodd{\i}}{|}{\\}
      }
    }
}

\newcommand{\printEntry}[1]{
  \listlength{#1}%
  \ifthenelse{\equal{0}{\thellength}}{}{
    \item[Entry pb:] 
    \foreach \x [count=\i] in #1
      {%
        \begin{minipage}{8cm}%
          $\mathcal{P}_\i : \x$ %
        \end{minipage}%
        \ifthenelse{\equal{\i}{\thellength}}{}{\\}%
      }%
  }%
}
\newcommand{\printItemComp}[3]{
  \listlength{#3}%
  \ifthenelse{\equal{0}{\thellength}}{}{
    \item[#1] \printMinipage{#2}{#3}
  }%
}

\newcommand{\printAll}[4]{
  \noindent%
  \begin{description}[leftmargin=!,labelwidth=\widthof{\bfseries Mapping:}]
    \printEntry{#1}%
    \printItemComp{Compil:}{\mathcal{T}}{#2}%
    \printItemComp{Mapping:}{m}{#3}%
    \printItemComp{Links:}{l}{#4}
  \end{description}
}

\begin{document}

\title{HO unification from object language to meta language}

\author{Davide Fissore}
\email{davide.fissore@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\author{Enrico Tassi}
\email{enrico.tassi@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\begin{abstract}
  Specifying and implementing a logic from scratch requires significant effort.
  Logical Frameworks and Higher Order Logic Programming Languages provide
  dedicated, high-level Meta Languages (ML) to facilitate this task in two
  key ways: 1) variable binding and substitution are simplified when ML binders
  represent object logic ones; 2) proof construction, and even proof search, is
  greatly simplified by leveraging the unification procedure provided by the ML.
  Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
  $\lambda$Prolog~\cite{miller_nadathur_2012} and
  Isabelle~\cite{10.1007/978-3-540-71067-7_7}
  which have been utilized to implement various formal systems such as
  First Order Logic~\cite{felty88cade},
  Set Theory~\cite{10.1007/BF00881873},
  Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
  Constuctions~\cite{felty93lics}.

  The object logic we are interested in is Coq's~\cite{Coq-refman}
  Dependent Type Theory (DTT),
  for which we aim to implement a unification procedure \Uo using the ML
  Elpi~\cite{dunchev15lpar}, a dialect of $\lambda$Prolog.
  Elpi's equational theory comprises
  $\eta\beta$ equivalence and comes equipped with a
  higher order unification procedure \Ue restricted to the pattern
  fragment~\cite{miller92jsc}.
  We want \Uo to be as powerful as \Ue but on the object logic DTT.
  Elpi also comes with an encoding for DTT that works well
  for meta-programming~\cite{tassi:hal-01637063,tassi:hal-01897468,gregoire:hal-03800154,newtc}.
  Unfortunately this encoding, which we refer to as \Fo,
  ``underuses'' \Ue by restricting it to first-order unification problems only.
  To address this issue, we propose a better-behaved encoding, \Ho,
  demonstrate how to map unification problems in \Fo{}
  to related problems in \Ho, and illustrate
  how to map back the unifiers found by \Ue, effectively implementing
   \Uo on top of \Ue for the encoding \Fo.

  We apply this technique to the implementation of a type-class~\cite{wadler89}
  solver for Coq~\cite{Coq-refman}.
  Type-class solvers are proof search procedures based on
  unification that back-chain designated lemmas, providing essential
  automation to widely used
  Coq libraries such as Stdpp/Iris~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
  and TLC~\cite{10.1007/978-3-642-14052-5_15}. These two libraries
  constitute our test bed.
\end{abstract}

\keywords{Logic Programming, Meta-Programming, Higher-Order Unification, Proof Automation}

\maketitle

\section{Introduction}
\label{sec:intro}

Specifying and implementing a logic from scratch requires significant effort.
Logical Frameworks and Higher Order Logic Programming Languages provide
dedicated, high-level Meta Languages (ML) to facilitate this task in two
key ways: 1) variable binding and substitution are simplified when ML binders
represent object logic ones; 2) proof construction, and even proof search, is
greatly simplified by leveraging the unification procedure provided by the ML.
Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
$\lambda$Prolog~\cite{miller_nadathur_2012} and
Isabelle~\cite{10.1007/978-3-540-71067-7_7}
which have been utilized to implement various formal systems such as
First Order Logic~\cite{felty88cade},
Set Theory~\cite{10.1007/BF00881873},
Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
Constuctions~\cite{felty93lics}.

The object logic we are interested in is Coq's~\cite{Coq-refman}
Dependent Type Theory (DTT), and we want to code a type-class~\cite{wadler89}
solver for Coq~\cite{Coq-refman} using the Coq-Elpi~\cite{tassi:hal-01637063}
meta programming framework.
Type-class solvers are unification based proof search procedures
that combine a set of designated lemmas in order to providing essential
automation to widely used Coq libraries.

As the running example we take the \coqIn{Decide} type class,
from the Stdpp~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
library. The class identifies predicates equipped with a decision procedure.
The following three designated lemmas (called \coqIn{Instances} in the
type-class jargon) state that: 1) the type \coqIn{fin n}, of natural numbers
smaller than \coqIn{n} is finite; 2) the predicate \coqIn{nfact n nf},
linking a natural number \coqIn{n} to its prime factors \coqIn{nf}, is decidable;
3) the universal closure of a predicate has a decision procedure if the
predicate has and if its domain is finite.

\begin{coqcode}
Instance fin_fin n : Finite (fin n).              (* r1 *)
Instance nfact_dec n nf : Decision (nfact n nf).  (* r2 *)
Instance forall_dec A P : Finite A ~$\to$~             (* r3 *)
  ~$\forall$~x:A, Decision (P x) ~$\to$~ Decision (~$\forall$~x:A, P x).
\end{coqcode}

\noindent Under this context of instances a type-class solver is able to prove
the following statement automatically by back-chaining.

\begin{coqcode}
  Check _ : Decision (forall y: fin 7, nfact y 3).       ~\customlabel{goal:g}{(g)}~
\end{coqcode}

\noindent
The encoding of DTT provided by Elpi, that we will discuss at length later in
section~\ref{sec:encodings,sec:lang-spec} and ~\ref{}, is an Higher Order Abstract
Syntax (HOAS) datatype \elpiIn{tm} featuring (among others) the following
constructors:

\begin{elpicode}
type lam  tm -> (tm -> tm) -> tm.     % lambda abstraction
type app  list tm -> tm.              % n-ary application
type all  tm -> (tm -> tm) -> tm.     % forall quantifier
type con  string -> tm.               % constants
\end{elpicode}

\noindent
Following standard $\lambda$Prolog~\cite{miller_nadathur_2012}
the concrete syntax to abstract, at the meta level, an expression
\elpiIn{e} over a variable \elpiIn{x}
is <<\elpiIn{x\ e}>>, and square brackets denote a list of
terms separated by comma. As an example we show the encoding of the Coq term
<<\coqIn{~$\forall$~y:t, nfact y 3}>>:

\begin{elpicode}
all (con"t") y\ app[con"nfact", y, con"3"]
\end{elpicode}

\noindent
We now illustrate the encoding of the three instances above as higher-order
logic-programming rules: capital letters denote rule
parameters; \elpiIn{:-} separates the rule's head from the premises;
\elpiIn{pi w\ p} introduces a fresh nominal constant \elpiIn{w}
for the premise \elpiIn{p}.

\begin{elpicode}
finite (app[con"fin", N]).                            ~\customlabel{clause:r1}{(r1)}~
decision (app [con"nfact", N, NF]).                   ~\customlabel{clause:r2}{(r2)}~
decision (all A x\ app[P, x]) :- finite A,            ~\customlabel{clause:r3}{(r3)}~
  pi w\ decision (app[P, w]).
\end{elpicode}

\noindent
Unfortunately this translation of rule \ref{clause:r3} uses the
predicate \coqIn{P} as a first order term: for the meta
language its type is \elpiIn{tm}.
If we try to backchain the rule \ref{clause:r3} on the encoding of the goal
\ref{goal:g} given below

\begin{elpicode}
decision (all (app[con"fin", con"7"]) y\
  app[con"nfact", y, con"3"]).
\end{elpicode}

\noindent
we obtain an unsolvable unification problem \ref{problem:p}:
the two lists of terms have different lengths!
%The root cause is that
%\ref{problem:p} is an higher order in DTT, but becomes
%first order in the meta language due to the ``naive'' encoding.

\begin{elpicode}
app[con"nfact", y, con"3"] = app[P, y]                 ~\customlabel{problem:p}{(p)}~
\end{elpicode}

\noindent
In this paper we study a more sophisticated encoding of Coq terms allowing
us to rephrase the problematic rule \ref{clause:r3} as follows:

\begin{elpicode}
decision (all A x\ Pm x) :- decomp Pm P A, finite A,   ~\customlabel{clause:r3a}{(r3a)}~
  pi x\ decision (app[P, x]).
\end{elpicode}

\noindent
Since \elpiIn{Pm} is an higher-order unification variable
of type \elpiIn{tm -> tm},
with \elpiIn{x}
in its scope, the unification problem \ref{problem:pa}
admits one solution:

\begin{elpicode}
app[con"nfact", y, con"3"] = Pm y                     ~\customlabel{problem:pa}{(p')}~
Pm = x\ app[con"nfact", x, con"3"]     % assignment for Pm
A = app[con"fin", con"7"]              % assignment for A
\end{elpicode}

\noindent
After unifying the head of rule \ref{clause:r3a} with the goal, Elpi runs
the premise <<\elpiIn{decomp Pm A P}>> that is in charge of bringing the
assignment for \elpiIn{Pm} back to the domain \elpiIn{tm} of Coq terms:

\begin{elpicode}
P = lam A a\ app[con"nfact", a, con"3"]
\end{elpicode}

\noindent
This simple example is sufficient to show that the encoding we seek
is not trivial and does not only concern the head of rules, but the entire sequence
of unification problems that constitute the execution of a logic program.
In fact
the solution for \elpiIn{P} above generates a
(Coq) $\beta$-redex in the second premise (the predicate
under the \elpiIn{pi w\ }\hspace{-0.4em}):

\begin{elpicode}
decision (app[lam A (a\ app[con"nfact", a, con"3"]), w])
\end{elpicode}

\noindent
In turn this redex prevents the rule \ref{clause:r2} to backchain properly since
the following unification problem has no solution:

\begin{elpicode}
app[lam A (a\ app[con"nfact", a, con"3"]), x] =
app[con"nfact", N, NF]
\end{elpicode}
\noindent
~\\
The root cause of the problems we sketched in the running example
is that the unification procedure \Ue of the meta language is not aware
of the equational theory of the object logic, even if both theories
include $\eta\beta$-conversion and admit most general
unifiers for unification problems in the pattern fragment \llambda~\cite{miller92jsc}.

\paragraph{Contributions}
In this paper we discuss alternative encodings of Coq in
Elpi (Section~\ref{sec:encodings}), then we identify a minimal language \Fo{}
in which the problems sketched here can be fully described.
We then detail an encoding \elpiIn{comp} from \Fo{} to \Ho (the language of
the meta language) and a decoding \elpiIn{decomp} to relate the unifiers
bla bla.. TODO citare Teyjus.
The code discussed in the paper can be accessed at the URL:
\url{https://github.com/FissoreD/paper-ho}.

\section{Problem statement} %%%%%%%%%%%%%%%%%%%%%%
\label{sec:problem-statement}

The equational theory of Coq's Dependent Type Theory is very rich. In
addition to the usual $\eta\beta$-equivalence for functions, terms (hence types)
are compared up to proposition unfolding and fixpoint unrolling. Still,
for efficiency and predictability reasons, most form of automatic proof search
employ a unification procedure that captures a simpler one,
just $\eta\beta$, and that solves higher-order problems
restricted to the pattern fragment $\llambda$~\cite{miller92jsc}.
We call this unification procedure \Uo{}.

The equational theory of the meta language Elpi is strikingly similar,
since it it comprises $\eta\beta$ (for the meta language functions), and the
unification procedure \Ue{} solves higher-order problems in
$\llambda$.

In spite of the similarity the link between \Ue{} and \Uo{} is not trivial,
since the abstraction and application term constructors
the two unification procedures deal with are different. For example

\begin{tabular}{lcl}
\elpiIn{x\ f x} & \Ue{} & \elpiIn{f}\\
\elpiIn{lam A x\ app[con"f", x]} & \Uo{} & \elpiIn{con"f"}\\
\elpiIn{lam A x\ app[con"f", x]} & \nUe{} & \elpiIn{con"f"} \\
\elpiIn{P x} & \Ue{} & \elpiIn{x}\\
\elpiIn{app[P, x]} & \Uo{} & \elpiIn{x}\\
\elpiIn{app[P, x]} & \nUe{} & \elpiIn{x}\\
\end{tabular}

\noindent
One could ignore this similarity, and ``just'' describe the object language
unification procedure in the meta language, that is crafting a \elpiIn{unif}
predicate to be used as follows in rule \ref{clause:r3}:

\begin{elpicode}
decision X :- unif X (all A x\ app[P, x]), finite A,
  pi x\ decision (app[P, x]).
\end{elpicode}

\noindent
This choice would underuse the logic programming engine provided by
the metalanguage since by removing any datum from the head of rules
indexing degenerates. Moreover the unification procedure built in the
meta language is likely to be faster than one implemented in it,
especially if the meta language is interpreted as Elpi is.

To state precisely the problem we solve we need a \Fo{} representation
of DTT terms and a \Ho one.
We call \Eo the equality over ground terms in \Fo,
\Ee the equality over ground terms in \Ho,
\Uo the unification procedure we want to implement and
\Ue the one provided by the meta language.
TODO extend \Eo and \Ee with reflexivity on uvars.

\newcommand{\specunif}[3]{
  #3_i \in \llambda \Rightarrow %
    \exists \rho, %
      \rho #3_1 #1 \rho #3_2  %
        \Leftrightarrow #3_1 #2 #3_2 \mapsto \rho' \subseteq \rho
}


\newcommand{\unifcorrect}[3]{
  % \forall \rho #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    #3_i \in \llambda \Rightarrow
      #3_1 #2 #3_2 \mapsto \rho
        \Rightarrow
          \rho #3_1 #1 \rho #3_2  %
}

\newcommand{\unifcomplete}[3]{
  % \forall #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    #3_i \in \llambda \Rightarrow
      % \forall \rho, %
        \rho #3_1 #1 \rho #3_2  %
          \Rightarrow \exists \rho', #3_1 #2 #3_2 \mapsto \rho' \land \rho' \subseteq \rho
}

We write $t_1 \Ue t_2 \mapsto \sigma$ when $t_1$ and $t_2$ unify
with substitution $\sigma$; we write $\sigma t$ for the application of
the substitution to $t$, and $\sigma X = \{ \sigma t | t \in X\}$ when
$X$ is a set; we write $\sigma \subseteq \sigma'$ when $\sigma$ is more
general than $\sigma'$. We assume that the unification of our meta
language is correct:
%
\begin{gather}
  \unifcorrect{\Ee}{\Ue}{t} \label{prop:correct-ml}\\
  \unifcomplete{\Ee}{\Ue}{t}\label{prop:complete-ml}
\end{gather}

\newcommand{\C}[4]{\ensuremath{\langle #1 \rangle}\mapsto(#2,#3,#4)}
\newcommand{\D}[4]{\ensuremath{\langle #1,#2,#3 \rangle^{-1}\mapsto #4}}

We illustrate a compilation $\C{s}{t}{m}{l}$ that
maps a term $s$ in \Fo{} to a term $t$ in \Ho, a variable mapping $m$ and
list of links $l$.
The variable map connects unification variables in \Ho with variables
in \Fo{} and is used to ``decompile'' the assignment,
$\D{\sigma}{m}{l}{\rho}$. Links represent problematic sub-terms which
are linked to the unification variable that stands in their place in the
compiled term. These links are checked for or progress XXX improve....

We represent a logic program \emph{run} in \Fo as
a list \emph{steps} $p$ of length $\mathcal{N}$. Each made of a
unification problem between terms $\mathcal{S}_{p_l}$ and
$\mathcal{S}_{p_r}$ taken from the set of all terms $\mathcal{S}$.
The composition of these steps starting from the
empty substitution $\rho_0$ produces the final
substitution $\rho_\mathcal{N}$.
\footnote{If the same rule is used multiple time in a run we
just consider as many copies as needed of the terms composing the
rules, with fresh unification variables each time}
The initial here $\rho_0$ is the empty substitution
%
\newcommand{\progress}{\ensuremath{\mathrm{progress}}\xspace}
\newcommand{\fstep}{\ensuremath{\mathrm{fstep}}\xspace}
\newcommand{\hstep}{\ensuremath{\mathrm{hstep}}\xspace}
\newcommand{\frun}{\ensuremath{\mathrm{frun}}\xspace}
\newcommand{\hrun}{\ensuremath{\mathrm{hrun}}\xspace}
\newcommand{\stepF}[4]{\ensuremath{\fstep(#1,#2,#3) \mapsto #4}}
\newcommand{\stepFD}[5]{%
\ensuremath{#3 #1_{#2_l} \Uo #3 #1_{#2_r} \mapsto #4 \land #5 = #3 \cup #4}}
\newcommand{\stepH}[6]{\ensuremath{\hstep(#1,#2,#3,#4) \mapsto (#5, #6)}}
\newcommand{\stepHD}[6]{\ensuremath{%
#3 #1_{#2_l} \Ue #3 #1_{#2_r} \mapsto #4 \land \progress(#6,#3 \cup #4) \mapsto (#6',#5)}}
\newcommand{\runF}[3]{\ensuremath{\frun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runFD}[2]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepF{#1}{p}{\rho_{p-1}}{\rho_{p}}}}
\newcommand{\runH}[3]{\ensuremath{\hrun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runHD}[3]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepH{#1}{p}{\sigma_{p-1}}{#3_{p-1}}{\sigma_{p}}{#3_p}}}
\newcommand{\deff}{\ensuremath{\stackrel{{\scriptscriptstyle def}}{=\!=\!\!\!=}}}
\newcommand{\linkStore}{\ensuremath{\mathbb{L}}\xspace}
\newcommand{\mapStore}{\ensuremath{\mathbb{M}}\xspace}
%
$$
\begin{array}{l}
\stepF{\mathcal{S}}{p}{\rho}{\rho''}
\deff
\stepFD{\mathcal{S}}{p}{\rho}{\rho'}{\rho''}\vspace{2pt}\\
\runF{\mathcal{S}}{\mathcal{N}}{\rho}
\deff
\runFD{\mathcal{S}}{\mathcal{N}}
\end{array}
$$

We simulate each run in \Fo{} with a run in \Ho as follows.
Note that $\sigma_0$ is the empty substitution.
$$
\begin{array}{l}
\stepH{\mathcal{T}}{p}{\sigma}{\linkStore}{\sigma''}{\linkStore'} \deff\vspace{2pt}\\
  \qquad\stepHD{\mathcal{T}}{p}{\sigma}{\sigma'}{\sigma''}{\linkStore}\vspace{2pt}\\
\runH{\mathcal{S}}{\mathcal{N}}{\rho} \deff \vspace{2pt}\\
  \qquad \mathcal{T} \times \mapStore \times \linkStore_0 = \{ (t_j,m_j,l_j) | s_j \in \mathcal{S}, \C{s_j}{t_j}{m_j}{l_j} \}\vspace{2pt}\\
  \qquad \runHD{\mathcal{T}}{\mathcal{N}}{\linkStore}\vspace{2pt}\\
  \qquad \D{\sigma_{\mathcal{N}}}{\mapStore}{\linkStore_{\mathcal{N}}}{\rho_{\mathcal{N}}}
\end{array}
$$

\noindent
Here \hstep{} is made of two sub-steps: a call to \Ue (on the compiled
terms) and a call to \progress{} on the set of links. We claim the following:

\begin{proposition}[Simulation]\label{prop:simulation}
$\forall \mathcal{S}, \forall \mathcal{N},$
$$
  \runF{\mathcal{S}}{\mathcal{N}}{\rho}
  \Leftrightarrow
  \runH{\mathcal{S}}{\mathcal{N}}{\rho}
$$
\end{proposition}

\noindent
That is, the two executions give the same result. Moreover:

\begin{proposition}[Simulation fidelity]\label{prop:fidelity}
In the context of~ \hrun, if $~\mathcal{T} \subseteq \llambda$ we have that
$\forall p \in 1 \ldots \mathcal{N},$
$$
\stepF{\mathcal{S}}{p}{\rho_{p-1}}{\rho_p}
\Leftrightarrow
\stepH{\mathcal{T}}{p}{\sigma_{p-1}}{\linkStore}{\sigma_p}{\_}
$$
\end{proposition}
\noindent
In particular this property guarantees that a \emph{failure} in the \Fo{} run
is matched by a failure in \Ho{} \emph{at the same step}. We consider this
property very important from a practical point of view since it guarantees
that the execution traces are strongly related and in turn this enables a user
to debug a logic program in \Fo{} by looking at its execution trace in
\Ho{}.

XXX permuting hrun does not change the final result if check dooes not fail eagerly

XXX if we want to apply heuristics, we can apply them in decomp to avoid committing to
a non MGU too early


We can define $s_1 \Uo{} s_2$ by specializing the code of \hrun{} to
$\mathcal{S} = \{ s_1, s_2 \}$ as follows:
%
$$
\begin{array}{l}
s_1 \Uo s_2 \mapsto \rho \deff \vspace{2pt}\\
\quad\C{s_1}{t_1}{m_1}{l_1} \land \C{s_2}{t_2}{m_2}{l_2}\vspace{2pt}\\
\quad    t_1 \Ue t_2 \mapsto \sigma' \land
    \progress(\{l_1,l_2\},\sigma') \mapsto (L,\sigma'') \land\vspace{2pt}\\
\quad \D{\sigma''}{\{m_1,m_2\}}{L}{\rho}
\end{array}
$$

\begin{proposition}[Properties of \Uo{}]
\begin{gather}
  \unifcorrect{\Eo}{\Uo}{s}\customlabel{prop:correct}{(correct)}\\
\unifcomplete{\Eo}{\Uo}{s}\customlabel{prop:complete}{(complete)}\\
% \forall \rho'\rho,
  \rho s_1 \Eo \rho s_2 \Rightarrow
  \rho' \subseteq \rho \Rightarrow
  \rho's_i \in \llambda \Rightarrow
  \rho' s_1 \Uo \rho' s_2 %\label{prop:simulation}
\end{gather}
\end{proposition}

Properties \ref{prop:correct} and \ref{prop:complete} state, respectively, that
in \llambda the implementation of \Uo is correct, complete and returns the most
general unifier.

\marginpar{fix}Property \ref{prop:simulation} states that \Uo, hence our compilation scheme,
is resilient to unification problems outside \llambda solved by
a third party. We believe this property is of practical interest since we
want the user to be able to add heuristics via hand written rules
to the ones obtained by our compilation scheme. A Typical example
is the following problem \ref{problem:q} that is outside \llambda:

\begin{elpicode}
app [F, con"a"] = app[con"f", con"a", con"a"]          ~\customlabel{problem:q}{(q)}~
F = lam x\ app[con"f",x,x]                             ~\customlabel{heuristic:h}{(h)}~
\end{elpicode}

\noindent
Instead of rejecting it our scheme accepts it and guarantees that if
\ref{heuristic:h} is given (after the compilation part of the scheme, as
a run time hint) then ...


\subsection{The intuition in a nutshell}
\label{sec:nutshell}
A term $s$ is compiled in a term $t$ where every
``problematic'' sub term $p$ is replaced by a fresh unification variable $h$
and an accessory link that represent a suspended unification problem
$h \Ue p$. As a result \Ue is ``well behaved'' on $t$, that is it does not
contradict \Eo as it would otherwise do on ``problematic'' terms.
We now define ``problematic'' and ``well behaved'' more formally.

\newcommand{\maybeeta}{\ensuremath{\Diamond\eta}\xspace}
\newcommand{\maybebeta}{\ensuremath{\overline{\llambda}}\xspace}
%\newcommand{\maybebeta}{\ensuremath{\Diamond\beta}\xspace}
\begin{definition}[\maybeeta]
  $\maybeeta = \{ t ~|~ \exists \rho, \rho t ~\mathrm{is~an~eta~expansion} \}$
\end{definition}

\noindent
An example of term $t$ in \maybeeta{} is
$\lambda x.\lambda y.F~y~x$
since the substitution
$\rho = \{ F \mapsto \lambda a.\lambda b.fba\}$
makes $\rho t = \lambda x.\lambda y.f x y$
that is the eta long form of $f$. This term is problematic since
its rigid part, the $\lambda$-abstractions, cannot justify a
unification failure against, say, a constant.

\begin{definition}[\maybebeta]
  $\maybebeta = \{ X t_1 \ldots t_n ~|~ X t_1 \ldots t_n \not\in \llambda \}$.
\end{definition}

\noindent
An example of $t$ in \maybebeta{} is $F a$ for a constant $a$. Note however tha
an oracle could provide an assignment $\rho = \{ F \mapsto \lambda x.x\}$
that makes the resulting term fall back in \llambda.

\newcommand{\subterm}[1]{\ensuremath{\mathcal{P}(#1)}}
\begin{definition}[Subterms \subterm{t}] The set of sub terms of $t$ is the
  largest set $\mathcal{P(t)}$ that can be obtained by the following rules.
$$
\begin{array}{l}
t \in \subterm{t}\\
t = f t_1\ldots t_n \Rightarrow \subterm{t_i} \subseteq \subterm{t} \land f \in \subterm{t}\\
t = \lambda x.t' \Rightarrow \subterm{t'} \subseteq \subterm{t}\\
\end{array}
$$
\end{definition}

\noindent
We write $\subterm{X} = \bigcup_{t\in X} \subterm{t}$ when $X$ is a set of terms.

\newcommand{\wellb}{\ensuremath{\mathcal{W}}\xspace}
\begin{definition}[Well behaved set]
Given a set of terms $X \subseteq \Ho{}$,
$$
\wellb(X) \Leftrightarrow \forall t \in \subterm{X}, t \not\in (\maybebeta{} ~\cup~ \maybeeta{})
$$
\end{definition}

\noindent

\begin{proposition}[\wellb{}-preservation]\label{prop:nf}
$\forall \mathcal{T}, \forall \linkStore, \forall p, \forall \sigma, \forall \sigma'$
$$
\begin{array}{l}
\wellb(\sigma\mathcal{T}) \land
  \sigma\mathcal{T}_{p_l} \Ue \sigma\mathcal{T}_{p_r} \mapsto {\sigma'}
  \Rightarrow \wellb(\sigma' \mathcal{T})\\
\wellb(\sigma\mathcal{T}) \land
  \progress(\linkStore,\sigma) \mapsto (\_,\sigma')
  \Rightarrow \wellb(\sigma' \mathcal{T})
\end{array}
$$
\end{proposition}

\noindent
A less formal way to state \ref{prop:nf} is that \hstep{} and \progress never
``commit'' an unneeded $\lambda$-abstraction in $\sigma$ (a $\lambda$
that could be erased by an $\eta$-contraction),
nor put in $\sigma$ a flexible application outside \llambda{}
(an application node that could be erased by a $\beta$-reduction).

Note that proposition \ref{prop:nf} does not hold for \Uo{} as a whole
since decompilation can introduce (actually restore) terms in
\maybeeta or \maybebeta that were move out of the way
(put in $\linkStore$) during compilation.

\section{Alternative encodings and related work}

Paper \cite{10.1145/2966268.2966272} introduces semi-shallow.

Our encoding of DTT may look ``semi shallow'' since we use the meta-language
lambda abstraction but not its application (for the terms of type \elpiIn{tm}).
A fully shallow encoding unfortunately does not fit our use case, although
it would make the running example work:

\begin{elpicode}
finite (fin N).
decision (nfact N NF).
decision (all A x\ P x) :- finite A, pi x\ decision (P x).
\end{elpicode}

\noindent
There are two reasons for dismissing this encoding. The first one is that
in DTT it is not always possible to adopt it since the type system
of the meta language is too weak to accommodate terms with a variable arity,
like the following example:

\begin{coqcode}
Fixpoint arr T n := if n is S m then T -> arr T m else T.
Definition sum n : arr nat n := ...
Check sum 2   7 8   : nat.
Check sum 3   7 8 9 : nat.
\end{coqcode}

\noindent
The second reason is the encoding for Coq is used for meta programming the
system, hence it must accommodate the manipulation of terms that are now
know in advance (not even defined in Coq) without using introspection
primitives such as Prologs's \texttt{functor} and \texttt{arg}.

In the literature we could find a few related encoding of DTT.
TODO In~\cite{felty93lics} is related and make the
discrepancy between the types of ML and DTT visible. In this case
one needs 4 application nodes. Moreover the objective is an encoding
of terms, proofs, not proof search. Also note the conv predicate,
akin to the unif we rule out.

TODO This other paper~\cite{10.1007/978-3-031-38499-8_25} should also be cited.

None of the encodings above provide a solution to our problem.

\section{Preliminaries: \Fo{} and \Ho}
\label{sec:lang-spec}

In order to reason about unification we provide a description of the
\Fo{} and \Ho languages where unification variables
are first class terms, i.e. they have a concrete syntax. We keep these languages
minimal, for example, we omit the \elpiIn{all} quantifier of DTT we used
in the example in Section~\ref{sec:intro} together with the type notation of
terms carried by the \elpiIn{lam} constructor.
%
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-13pt}

\begin{figure}[H]
  \begin{tabular}{ll}
  \begin{minipage}{0.21\textwidth}
   \inputrawelpicode{code/fo_tm}
  \end{minipage}
  &
  \begin{minipage}{0.24\textwidth}
   \inputrawelpicode{code/ho_tm}
  \end{minipage}
  \end{tabular}\vspace{4pt}
  \caption{The \Fo{} and \Ho languages}\vspace{0.3em}
  \label{code:common-terms}
  \Description[code:common-terms]{code:common-terms}
\end{figure}

\noindent
Unification variables (\elpiIn{fuva} term constructor)
in \Fo{} have no explicit scope:
the arguments of an higher order variable are given via the \elpiIn{fapp}
constructor. For example the term \coqIn{P x} is represented as
\elpiIn{fapp[fuva N, x]}, where \elpiIn{N} is a memory address and
\elpiIn{x} is a bound variable.\\
In \Ho the representation of \coqIn{P x} is instead \elpiIn{uva N [x]},
since unification variables come equipped with an explicit scope.
We say that the unification variable occurrence \elpiIn{uva N L} is in
\llambda if and only if \elpiIn{L} is made of distinct names. The
predicate to test this condition is called \elpiIn{pattern-fragment}:

\input{code/pattern_fragment}

\noindent
Natural numbers represent the memory addresses that
identify unification variables in both languages.
The memory and its associated operations are described below:

\input{code/mem_types}

\noindent
If a memory cell is \elpiIn{none}, then the corresponding unification variable
is not set. \elpiIn{assign} sets an unset cell to the given value, while
\elpiIn{new} finds the first unused address and sets it to \elpiIn{none}.\marginpar{is new used?}

Since in \Ho unification variables have a scope, their solution needs to be
abstracted over it to enable the instantiation of a single
solution to different scopes. This is obtained via the \elpiIn{inctx}
container, and in particular via its \elpiIn{abs} binding constructor.
On the contrary a solution to a \Fo variable is a plain term.

\input{code/fo_subst}
\input{code/ho_subst}

\noindent
We call \elpiIn{fsubst} the memory of \Fo{}, while we call \elpiIn{subst}
the one of \Ho.
Both have the invariant that they are not cyclic, TODO: explain.

\input{code/comp_base_types}

\begin{invariant}[Unification variable arity]
  Each variable \elpiIn{A}
  in \Ho has a (unique) arity \elpiIn{N} and each occurrence~
  \elpiIn{(uva A L)} is such that \elpiIn{(len L N)} holds
  \label{inv:uvaarity}
\end{invariant}

\noindent
The compiler establishes a mapping between variables of the two languages.
In order to preserve invariant \ref{inv:uvaarity} we store the
arity of each \elpiIn{hvariable} in the mapping and we reuse an existing
mapping only if the arity matches.

TODO: add ref to \cref{sec:invariant1}

\input{code/alloc_mapping}

\noindent
When a single \elpiIn{fvariable} occurs multiple times with different numbers
of arguments the compiler generates multiple mappings for it, on a first
approximation, and then makes the mapping bijective by introducing
\linketa; this detail is discussed in section \ref{sec:eta}.

As we mentioned in section~\ref{sec:nutshell} the compiler
replaces terms in \maybeeta and \maybebeta with fresh variables
linked to the problematic terms. Each class of problematic terms
has a dedicated link.

\input{code/comp_links}

\noindent
The right hand side of a link, the problematic term, can occur under binders.
To accommodate this situation the compiler wraps \elpiIn{baselink} using
the \elpiIn{inctx} container (see, \ref{data:inctx}).

\begin{invariant}[Link left hand side]\label{inv:linklhs}
  The left hand side of a suspended link
  is a variable.
\end{invariant}

\noindent
New links are suspended by construction.
If the left hand side variable is assigned during a step, then 
the link is considered for progress and possibly eliminated.
This is discussed in \cref{sec:eta} and \cref{sc:beta}.

\subsection{Notational conventions}

When we write \Ho terms outside code blocks we follow the
usual $\lambda$-calculus notation, reserving $f, g, a, b$ for constants,
$x, y, z$ for bound variables and $X, Y, Z, F, G, H$ for unification variables.
However we need to
distinguish between the ``application'' of a unification variable
to its scope and the application of a term to a list of arguments.
We write the scope of unification variables in subscript
while we use juxtaposition for regular application.
Here a few examples:
\vspace{5pt}

\begin{tabular}{ll}
  $f~ a$ &  \elpiIn{app[con "f", con "a"]}\\
  $\lambda x.\lambda y.F_{x y}$ & \elpiIn{lam x\ lam y\ uva F [x, y]} \\
  $\lambda x.F_{x} ~ a$ & \elpiIn{lam x\ app[uva F [x], con "a"]} \\
  $\lambda x.F_{x} ~ x$ & \elpiIn{lam x\ app[uva F [x], x]} \\
\end{tabular}
\vspace{5pt}

\noindent
When detailing examples we write links as equations between two
terms under a context.
The equality sign is subscripted with
kind of \elpiIn{baselink}. For example $\linkbetaM{x}{A_x}{F_x~a}$ corresponds to:
\begin{elpicode}
abs x\ val (link-beta (uva A [x]) (app[uva F [x],con "a"]))
\end{elpicode}

\noindent
When it is clear from the context we shall use the same syntax for \Fo{} terms
(although we never subscripts unification variables).

\subsection{Equational theory and Unification}

In order to express properties \ref{prop:correct, prop:complete, prop:simulation}
we need to equip \Fo{} and \Ho with term equality,
substitution application and unification.

\paragraph{Term equality: \Eo vs. \Ee} We extend the equational theory
over ground terms to the full languages by adding the reflexivity of
unification variables (a variable is equal to itself).

The first four rules are common to both equalities
and just define the usual congruence over terms, and since
we use an HOAS encoding they also capture $\alpha$-equivalence.
In addition to that \Eo has rules for $\eta$ and $\beta$-equivalence.

\input{code/feq}

\begin{elpicode}
  ~\PYG{k+kd}{type} \PYG{n+nf}{(\Ee)} \PYG{k+kt}{tm -> tm -> o}~.
  con C ~\Ee~fcon C.
  app A ~\Ee~fapp B :- forall2 ~(\Ee)~ A B.
  lam F ~\Ee~flam G :- pi x\ x ~\Ee~x => F x ~\Ee~G x.
  uva N A ~\Ee~fuva N B :- forall2 ~(\Ee)~ A B.
\end{elpicode}

\noindent
The main point in showing these equality tests is to remark how weaker \Ee is,
and to identify the four rules that need special treatment in
the implementation of \Uo.

For reference, \elpiIn{(beta T A R)} reduces away \elpiIn{lam} nodes in head
position in \elpiIn{T} whenever the list \elpiIn{A} provides a corresponding
argument.

\input{code/beta_fo}

\noindent
The \elpiIn{name} predicate holds only on nominal constants (i.e. bound
variables).\footnote{Elpi provides it as a builtin, but one could implement it by
systematically loading the hypothetical rule \elpiIn{name x} every time
a nominal constant is postulated via \elpiInFN{pi x\ }}
The choice of using n-ary application, rather than binary, is to make it
easy to access the application's head. The price we pay is that substituting
an application in the head of an application should be amended by
``flattening'' \elpiIn{fapp} nodes, that is the job of \elpiIn{napp}.
\footnote{Note that \elpiIn{napp} is an artefact of formalization of \Fo{}
we do in this presentation and, as we explain later,
no equivalent of \elpiIn{napp} is needed in \Ho.}
Finally note that the cut operator is inessential, it could be
removed at the cost of a verbose test on the head of \elpiIn{L}
in the second rule about \elpiIn{fapp}: \elpiIn{L}'s head
can be \elpiIn{fcon}, \elpiIn{flam} or a name.


\paragraph{Substitution application: $\rho s$ and $\sigma t$}

Applying the substitution corresponds to dereferencing a term with respect to
the memory. To ease the comparison we split \Fo dereferencing into a
\elpiIn{fder} step and a \elpiIn{napp} one. The former step replaces references
to memory cells that are set with their values, and has a corresponding
operation in \Ho, namely \elpiIn{deref}. On the contrary \elpiIn{napp}
has no corresponding operation in \Ho. The reasons for this asymmetry is
that an \elpiIn{fapp} node with a flexible head is always mapped
to a \elpiIn{uva} (as per \cref{sec:compilation} and \cref{sec:beta}),
preventing nested applications to materialize.

\input{code/fderef}

\noindent
Applying the substitution in \Ho{} is very similar, with
the caveat that assignments have to be moved to the
current scope, i.e. renaming the \elpiIn{abs}-bound variables
with the names in the scope of the unification variable occurrence.

\input{code/deref}

\noindent
Note that move strongly relies on invariant \ref{inv:uvaarity}: the length
of the arguments of all occurrences of a unification variable and the
number of abstractions in its assignment have to match. In turn
this grants that \elpiIn{move} never fails.

\input{code/move}

\paragraph{Term unification: \Uo vs. \Ue}

In this paper we assume to have an implementation of \Ue that satisfies
properties~\ref{prop:correct-ml} and~\ref{prop:complete-ml}. Although we provide an
implementation in the appendix (that we used for testing purposes) we only
describe its signature here. Elpi is expected to provide this brick, as well as
any other implementation of $\lambda$Prolog.

\input{code/ue_type}

\noindent
The only detail worth discussing is the fact that the procedure updates a
substitution, rather than just crafting one as presented in
section~\ref{sec:problem-statement}. The reason is that the algorithm folds
over a term, updating a substitution while it traverses it.\marginpar{explain better}

% The first three rules unify terms with same rigid heads, and
% call the unification relation on the sub-terms. If $t_1$ (resp. $t_2$) is an
% assigned variables, $t_1$ is dereferenced to $t_1'$ (resp. $t_2'$) and the
% unification is called between $t_1'$ and $t_2$ (resp. $t_1$ and $t_2'$). If both
% terms are unification variables, we test that their arguments are in the pattern
% fragment, we allocate a new variable $w$ in $\rho_1$ such that $w$ is the
% pruning of the arguments of $t_1$ and $t_2$, we assign both $t_1$ and $t_2$ to
% $w$ and return the new mapping $\rho_2$ containing all the new variable
% assignment. Finally, if only one of the two terms is an unification variable
% $v$, after having verified that $v$ does not occur in the other term $t$, we
% bind $v$ to $t$ and return the new substitution mapping.

% \old

% A key property needed in unification is being able to verify if two terms are
% equal wrt a given equational theory. This relation allow to compare terms under
% a certain substitution mapping, so that any time a variable $v$ is assigned in a
% subterm, a dereferencing of $v$ is performed. After variable dereferencing, the
% test for equality is continued on the new-created subterm.

% The base equality function over terms can be defined as follows:

% The solution we are proposing aim to overcome these unification issues by 1)
% compiling the terms $t$ and $u$ of the OL into an internal version $t'$ and $u'$
% in the ML; 2) unifying $t'$ and $u'$ at the meta level instantiating meta
% variables; 3) decompiling the meta variable into terms of the OL; 4) assigning
% the variables of the OL with the decompiled version of their corresponding meta
% variables. We claim that $t$ and $u$ unify if and only if $t'$ and $u'$ unify
% and that the substitution in the object language is the same as the one returned
% by the ML. \todo{same or $\supseteq$ or $\subseteq$}

% In the following section we explain how we deal with term (de)compilation and
% links between unification variables.

\section[Compilation: fo\_tm to tm]{Basic simulation of \Fo{} in \Ho{}}
\label{sec:compilation}

In this section we describe a basic compilation scheme that we refine
later, in the following sections. This scheme is sufficient to implement
an \Uo{} that respects $\beta$-conversion for terms in \llambda. The extension to
$\eta\beta$-conversion is described in Section \ref{sec:eta} and the support
for terms outside \llambda in Section \ref{sec:beta}.

\subsection{Compilation}
\marginpar{manca beta normal in entrata}

The main task of the compiler is to recognize \Fo{} variables standing
for functions and map them to higher order variables in \Ho.
In order to bring back the substitution from \Ho{} to \Fo{} the compiler
builds a ``memory map'' connecting the the kind of variables using routine
\ref{clause:malloc}.

The signature of the \elpiIn{comp} predicate below allows for the generation of
links (suspended unification problems) that play no role in this section
but play a major role in \cref{sec:eta} and \cref{sec:beta}.
With respect to \cref{sec:problem-statement} the signature also allows
for updates to the substitution.  The code below uses that possibility
in order to allocate space for the variables, i.e. sets their memory
address to \elpiIn{none} (a details not worth mentioning in the
previous discussion).

\input{code/comp_base}

\noindent
This preliminary version of \elpiIn{comp} recognizes \Fo{} variables
applied to a (possibly empty) duplicate free list of names.
Note that compiling \elpiIn{Ag} cannot create new mappings nor links, since \elpiIn{Ag}
is made of bound variables and the hypothetical rule loaded by \elpiIn{comp-lam}
(see below) grants this property.

\input{code/comp_lam}

\noindent
In the code above the syntax \elpiIn{pi x y\..} is syntactic sugar for
iterated \elpiIn{pi} abstraction, as in \elpiIn{pi x\ pi y\..}.

The auxiliary function \elpiIn{close-links} tests if the bound variable
\elpiIn{v} really occurs in the link. If it is the case the link is wrapped into
an additional \elpiIn{abs} node binding \elpiIn{v}. In this way links generated
deep inside the compiled terms can be moved outside their original context
of binders.

\input{code/comp_close_links}

\noindent
Note that we could remove the first rule, whose solve purpose is to make
links more readable by pruning unused context entries.

\subsection{Execution}
\label{sec:execution}

A step in \Ho consists in unifying two terms and reconsidering all
links for progress. If any of the two tasks fail we say that the entire step
fails, and it is at this granularity that we can relate steps in the
two languages.


\input{code/hstep}

\noindent
Note tha the infix notation \elpiIn{((A ~\Ue~B) C D)} is syntactic sugar for
\elpiIn{((~\Ue\!\!\!~) A B C D)}.

Reconsidering links is a fixpoint, since the progress of a link can update the
substitution and in turn enable another link to progress.

\input{code/progress}

\noindent
In the base compilation scheme \elpiIn{progress1} is the identity
on both the links and the substitution, so the fixpoint trivially terminates.
Sections \ref{sec:eta} and \ref{sec:beta} add rules to \elpiIn{progress1}
and justify why the don't hinder termination.

Since compilation moves problematic terms out of the sigh of \Ue{},
that procedure can only perform a partial occur check. For example the
unification problem $X \Ue f~Y$ cannot generate a cyclic substitution alone,
but should be disallowed if a $\linkStore$ contains a link like
$\linketaM{}{Y}{\lambda z.X_z}$: We don't know yet if $Y$ will feature
a lambda in head position, but we surely know it contains $X$, hence
$f~Y$ and that fails the occur check.
The procedure \elpiIn{occur-check-links} is in charge of ensuring that
each link does not represent a (suspended) unification problem doomed
to fail because of occur check. This check is needed in order to
guarantee \cref{prop:fidelity} (simulation fidelity).

\subsection{Substitution decompilation}

Decompiling the substitution requires to first force the
progress of links and then allocating new unassigned variables
in the substitution for \Fo{} and finally decompiling all
assignments. Note that \cref{inv:linklhs} and the
occur check allows us to update the subst.


\input{code/decompile}

TODO: What is commit-links and complete-mapping?, maybe complete-mapping can be
hidden in the code rendering?

\noindent
Decompiling an assignment requires to turn abstractions into
lambdas. For aestetic purposes we also eta-contract the result
(not needed since \Fo{} equality can do that)

\input{code/decompm}

\noindent
Finally decompiling a term is trivial, now that we have an extended
mapping containing all unassigned variables \Ue may have introduced.

\input{code/decomp}

\noindent
Note that we use beta to build fapp nodes when needed (if Ag is empty
no \elpiIn{fapp} node should appear).


\begin{invariant}

  TODO: dire che il mapping è bijective
  \label{inv:map-bijective}
\end{invariant}

\subsection{Definition of \Uo and its properties}

\input{code/unif_fo}

The code given so far applies to terms in $\beta\eta$-normal form where
unification variables in \Fo{} can occur non linearly but always with
the same number of arguments, and where their arguments are distinct names
(as per \llambda).

\begin{lemma}[Compilation round trip] If
  \elpiIn{comp S T [] M [] _ [] _} then \elpiIn{decomp M T S}
\end{lemma}
\begin{proof}[Proof sketch]
trivial, since the terms are beta normal beta just builds an app.
\end{proof}


\begin{lemma}
Properties \ref{prop:correct} and
\ref{prop:complete} hold for the implementation of \Uo above
\end{lemma}
\begin{proof}[Proof sketch]
 In this setting \Ee is as strong as
\Eo on ground terms. What we have to show is that whenever two different \Fo
terms can be made equal by a substitution $\rho$ (plus the \ref{clause:beta1}
and \ref{clause:beta2} if needed) we can find this $\rho$ by finding
a $\sigma$ via \Ue{} on the corresponding \Ho terms and by decompiling it.
If we look at the \Fo{} terms, the are two interesting cases:
\begin{itemize}
\item \elpiIn{fuva X ~\Uo~s}. In this case after \elpiIn{comp} we have
  $Y \Ue t$ that succeeds with $\sigma = \{ Y \mapsto t\}$ and
  $\sigma$ is decompiled to $\rho = \{ Y \mapsto s\}$.
\item \elpiIn{fapp[fuva X|L] ~\Uo~s}. In this case
 we have $Y_{\vec{x}} \Ue t$ that succeeds with
 $\sigma = \{ \vec{y} \vdash Y \mapsto t[\vec{x}/\vec{y}]\}$ that in turn
 is decompiled to $\rho = \{ Y \mapsto \lambda \vec{y}.s[\vec{x}/\vec{y}]\}$.
 Thanks to \ref{clause:beta1}
 $(\lambda \vec{y}.s[\vec{x}/\vec{y}])~\vec{x} \Eo s$.
\end{itemize}
Since the mapping is a bijection occur check in \Ho{} corresponds to occur
check in \Fo{}.
\end{proof}

\begin{lemma} Properties simulation (\ref{prop:simulation}) and
fidelity (\ref{prop:fidelity}) hold
\end{lemma}
\begin{proof}[Proof sketch]
Since \elpiIn{progress1} is trivial \fstep and \hstep are the same, that is
in this
context where input terms are $\beta\eta$-normal and we disregard $\eta$-equivalence
\Ue is equivalent to \Uo.
\end{proof}

\subsection{Limitations of by this basic scheme}
\label{sec:basic-comp-limitations}

\begin{gather}
\lambda x y.F \appsep y \appsep x = \lambda x y.x \label{eq:unif-eta1}\\
\lambda x. f \appsep (F \appsep x) \appsep x = G \label{eq:unif-eta2}
% \lambda x. f \appsep (F \appsep x) \appsep x = f \appsep (\lambda y.y) \label{eq:unif-eta2}
\end{gather}
Note that here $F$ is used with different arities, moreover
in the second problem the left hand side happens to be an
eta expansion (of $f (\lambda y.y)$) only after we discover (at run time)
that $F = \lambda x\lambda y.y$ (i.e. that $F$ discards the $x$ argument).
Both problems are addressed in the next section.
  
% \subsection{Example}

% OK

% \begin{elpicode}
% Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%       , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr z (s z) ] % $\lambda x.g (F x) = \lambda x.g a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% \end{elpicode}

% KO

% \begin{elpicode}
%   Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%   , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr 0 1   % $A = \lambda x.x$
%            , pr 2 3 ] % $A a = a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% lam x\ app[f, app[X, x]] = Y,
%   lam x\ x) = X.
% \end{elpicode}

% \otext{Goal: $s_1 \Uo s_2$ is compiled into $t_1 \Ue t_2$}
% \otext{What is done: uvars \elpiIn{fo_uv} of OL are replaced into uvars \elpiIn{ho_uv} of the ML}
% \otext{Each \elpiIn{fo_uv} is linked to an \elpiIn{ho_uv} of the OL}
% \otext{Example needing the compiler v0 (tra l'altro lo scope è ignorato):\\ \elpiIn{lam x\ app[con"g",app[uv 0, x]] ~\Uo~lam x\ app[con"g", c"a"]}}
% \otext{Links used to instantiate vars of elpi}
% \otext{After all links, the solution in links are compacted and given to coq}
% \otext{It is not so simple, see next sections (multi-vars, eta, beta)}


% The compilation step is meant to recover the higher-order variables of the OL,
% expressed in a first order way, by replacing them with higher-order variables in
% the ML. In particular, every time a variable of the OL is encountered in the
% original term, it is replaced with a meta variable, and if the OL variable is
% applied to a list of distinct names $L$, then this list becomes the scope of the variable.
% For all the other constructors of
% \elpiIn{tm}, the same term constructor is returned and its arguments are
% recursively compiled. The predicate in charge for term compilation is:

% \elpiIn{type comp tm -> tm -> links -> links -> subst -> subst -> o}.

% \noindent
% where, we take the term of the OL, produce the term of the ML, take a list
% of link and produce a list of new links, take a substitution and return a
% new substitution.

% In particular, due to programming constraints, we need to drag the old subst and
% return a new one extended, if needed, with the new declared meta-variables.

% The following code
% %
% \begin{elpicode}
%   kind link type.
%   type link nat -> nat -> nat -> subst.
% \end{elpicode}
% %
% \noindent
% defines a link, which is a relation between to variables indexes, the first
% being the index of a OL variable and the second being the index of a ML
% variable. The third integer\todo{integer or nat?} is the number of term in the
% scope of the two variables, or equivalently, in a typed language, their arity.

% As an example, let's study the following unification problem (a slightly
% modified version from \cref{sec:intro}):

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Uo~
%     lam x\ app [c"decision", app[uv 0, x]]
% \end{elpicode}

% \noindent
% we have the main unification problem where the nested \elpiIn{app} nodes have
% lists of different lengths making the unification to fail. The compilation of
% these terms produces a new unification problem with the following shape:

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Ue~
%     lam x\ app [c"decision", uv 1 [x]]
% \end{elpicode}

% \noindent
% The main difference is the replacement of the subterm \elpiIn{app[uv 0, x]} of
% the OL with the subterm \elpiIn{uv 0 [x]}. Variable indexes are chosen by the
% ML, that is, the index \elpiIn{0} for that unification variable of the OL term
% has not the sam meaning of the index \elpiIn{0} in the ML. There exists two
% different substitution mapping, one for the OL and one for the ML and the indexes
% of variable point to the respective substitution.

% decomp che mappa abs verso lam
% \noindent
% \otext{An other example: \\
%   \elpiIn{lam x\ app[f, app[X, x]] = Y, (lam x\ x) = X.}}

% \section{Use of multivars}

% Se il termine initziale è della forma

% \begin{elpicode}
%   app[con"xxx", (lam x\ lam y\ Y y x), (lam x\ f)]
%   =
%   app[con"xxx",X,X]
% \end{elpicode}

% allora se non uso due X diverse non ho modo di recuperare il quoziente che mi manca.

% a sto punto consideriamo liste di problemi e così da eliminare sta xxx senza
% perdità di generalità (e facciamo problemi più corti, e modellizziamo anche la
% sequenza)

\section{Handling of \maybeeta}\label{sec:eta}

$\eta$-reduction is an equivalence relation where a term of the form
$\lambda x.t \appsep x$ can be converted to $t$ any time $x$ does not occur as a
free variable in $t$. We call $\lambda x. t \appsep x$ the $\eta$-expansion of $t$. 
\printAll
  {{\elpiIn{flam x\ fapp [fuva X, x]} \Uo \elpiIn{fcon"f"}}}
  {{\lambda x. X'_x \Ue f}}
  {{\mapping{\elpiIn{X}}{X'}{1}}}
  {{}}
Following the implementation of \elpiIn{comp} given in
\cref{sec:compilation}, the unification problem $\mathcal{P}_1$ given 
above, is compiled into the unification problem $\mathcal{T}_1$. 
We can note that all the terms appearing in $\mathcal{P}_1$ are
unifiable by \Uo, but, despite this, \Ue, is not able to solve $\mathcal{T}_1$:
its left and right hand sides have both different rigid head:
$\lambda x.A'_x$ corresponds to the \Ho term \elpiIn{lam x\ app[con "f", x]} 
and $f$ corresponds to \elpiIn{con"f"}. 
This failure is motivated by the fact that \elpiIn{flam x\ fapp [fuva A, x]}
is a term belonging to \maybeeta. 

In order to guarantee \cref{prop:simulation}, we need to modify the way terms are
compiled. The goal is to recognize
every \maybeeta subterm $t$ and replace it with fresh \Ho variables $v$. 
This connection between the variable $v$ and the subterm $t$ is stored in what we
call \linketa which is an object with the following type

\elpiIn{type link-eta tm -> tm -> baselink}

\noindent
where, as sketched in \cref{sec:lang-spec}, the term on the left hand side
(\lhs) is linked with its left counterpart (\rhs).

\linketa are added in the link store (\linkStore) and activated when special
conditions are satisfied on \lhs or \rhs. These link activations are managed by
extending the \elpiIn{progress1} predicate (see \cref{sec:execution}).
We claim that \linketa progression does not contradict \cref{inv:linklhs} and we
add the following invariant:

\begin{invariant}[\linketa \rhs]
  The \rhs of any \linketa in \linkStore has the shape $\lambda x.t_x$
  where $t_x$ is a \maybeeta term and $x$ is free in $t$.
  \label{inv:link-eta-right}
\end{invariant}

In the next three subsections we explain how we detect \maybeeta terms, how we
compile them and how the generated \linketa are activated during the \elpiIn{progress}.
Moreover, we provide justification for why \cref{inv:linklhs,inv:link-eta-right} remain true.

\subsection{Detection of \maybeeta}

Compiling a term $t$ forces us to determine if there exists a $t' \in \subterm{t}$,
such that $t' = \lambda x. t''_x$,
for any term $t''$, can be a $\eta$-expansion, i.e. under a
given substitution $\sigma$, we have $\sigma (\lambda x.t''_x) = t'$. This
\maybeeta detection is not a trivial operation as it may seems.
\\
\noindent
\begin{minipage}{.5\linewidth}%
  \begin{gather}
    \lambda x. f \appsep A_x\\
    \lambda x. f \appsep x \appsep A_x
  \end{gather}
\end{minipage}% This must go next to `\end{minipage}`
\begin{minipage}{.5\linewidth}
  \begin{gather}
    \lambda x. \lambda y. f \appsep A_x \appsep B_{y x} \label{eq:lamlam}\\
    \lambda x. f \appsep A_x \appsep x \label{eq:lamdisc}
  \end{gather}
\end{minipage}

In the examples above, the first term is a \maybeeta since $A_x$ can
reduce to $x$ by setting $A_x = \lambda x.x$, 
the second one is not a \maybeeta since it exists no substitution
for $A_x$ such that $A_x$ reduces to $x$ and $x$ is not free in the subterm $f \appsep x$.
It is a bit more complicated to determine if eq.~\ref{eq:lamlam} a \maybeeta since,
we have a spine of lambdas, this means that the whole term
is a \maybeeta, if the inner $\lambda$-term $\lambda y.f\appsep A_x\appsep B_yx$,
is an $\eta$-expansion and, if so, we need to verify if the $\eta$-reduced 
subterm, i.e. $f \appsep A_x$, can make $\lambda x.f \appsep A_x$ an $\eta$-expansion.
Indeed, eq.~\ref{eq:lamlam} is a \maybeeta under the substitution 
$\sigma = \{A \mapsto \lambda x.x, B \mapsto \lambda x. \lambda y. x\}$.
Lastly, eq.~\ref{eq:lamdisc} is a \maybeeta even if $x$
occurs in the subterm $t' = f \appsep A_x$, since it exists a substitution
$\sigma = \{A \mapsto \lambda x.a\}$, for any constant $a$, such that $\sigma t'
= f \appsep a$ is a term where $x$ does not appears as a free variable. 

We can now define more formally how \maybeeta terms are detected together with
its auxiliary functions:

\begin{definition}[reduce-to]
  A term $t$ reduce to a name $x$, if $\exists \sigma, \sigma t = x$. In
  particular, for any term $t$, $\lambda x_1 \ldots x_n.t_{x_1\ldots x_n}$
  reduces to a bound variable $x$ if one of the three following cases is
  satisfied: 1) $n = 0$ and $t = x$; 2) $t$ is the application of $x$ to a list
  of terms $l$ and each $l_i$ reduces to $x_i$
  (e.g. $\lambda x_1 \ldots x_n.x_{x_1\ldots x_n} = x$) ; 3) $t$ is a unification
  variable in \llambda with scope
  $s$, and for any $v \in \{ x, x_1 \ldots x_n \}$,
  there exists a $s_i \in s$, such that $s_i$ reduces to $v$
\end{definition}

\begin{definition}[occurs-rigidly]
  A name $x$ occurs rigidly in a term $t$, if $\forall \sigma, x \in
  \subterm{\sigma t}$
\end{definition}
In other words $x$ \emph{occurs-rigidly} in $t$ if it occurs in $t$
outside of the scope of unification variables since theirs instantiations
are allowed to discard their scope.

We can now derive the implementation for \maybeeta detection:

\begin{definition}[\maybeeta detection]
  A term $\lambda x_1 \ldots x_n.t$ where each $x_i$ occurs in $t$ is a
  \maybeeta if
  either: 1) $t$ is a constant applied to arguments
  $l_1 \ldots l_m$ such that 
  $m \geq n$ and every $l_{m-n+i}$ reduces-to $x_i$ and
  no $x_i$ occurs-rigidly in $l_{1\ldots m-n-1}$; or 2) $t$ is a
  unification variable with scope $s$ and
  for each $x_i$ there exists a $s_j \in s$ such that $s_j$ reduces-to $x_i$.
\end{definition}

As a final remark, the \maybeeta detection defined just before is an
over-approximation, in the sense that there exists some terms $t$ considered as
\maybeeta, such that forall substitution $\sigma$, $\sigma t$ is not an
$\eta$-expansion. A small example is $\lambda x. f \appsep A_x \appsep A_x$
which is considered a \maybeeta. Thi is because, we suppose at the same time
that the second $A_x$ can reduce to $x$, to the first $A_x$ is not reducible to
$A_x$. This is however not considered as a problem, since, adding holes to 
the compiled term does not break \cref{prop:simulation}, since each hole is
connected to a \linketa which is activated exactly when the hole is instantiated
the \linketa, as explain below is activated.

% The implementation we propose for the \maybeeta relation is given below.

% \input{code/maybe_eta}

% Here a complex maybeeta example
% \begin{gather}
%   T = \lambda y. f \appsep A_{xy} \appsep (B \appsep a \appsep (\lambda z.y\appsep C_z)) \appsep D_x
% \end{gather}

\subsection{Compilation}

Thanks to the \elpiIn{maybe-eta} predicate, we can detect ``$\eta$-problematic''
terms and, consequently replace them with fresh \Ho unification variables at
compilation time. The code below illustrate how this relation is used to for
term compilation.

\input{code/comp_eta}

This rule, to be inserted just before rule~\ref{rule:complam} from the code in
\cref{sec:compilation}, verifies if the \Fo{} term $t$ received in entry is a
\maybeeta. Let $\lambda t'$ be the compiled version of $t$, then the fresh
variable \elpiIn{A} returned as the new \Ho term as in scope all the free names
in $t'$. The critical part of this compilation is the creation of the \linketa,
which links the variable \elpiIn{A} with $t$. This link creation enforce
\cref{inv:linklhs} and \cref{inv:link-eta-right}, since \lhs is a trivially a
variable and the \rhs is a term $t$ starting with the \elpiIn{lam} constructor where
$x$ is free in $t$ otherwise $t$ would not have been detected as a \maybeeta. 

\begin{corollary}
  The \rhs of any \linketa has exactly one lambda abstraction.
\end{corollary}

\begin{proof}[Proof sketch]
  By contradiction, suppose that a \linketa $l$ has $t$ as \rhs and $t = \lambda
  x.\lambda y.t'_{xy}$. Two cases are to be analyses: 1) $\lambda y.t'_{xy}$ is
  a $\maybeeta$, then, by construction, \rhs would have been replaced with a the
  $\eta$-expansion of fresh variable $v$, which is a contradiction, since
  $\lambda y.t'_{xy} \neq \lambda x.v_{x}$; 2) $\lambda y.t'_{xy}$ is not an a
  \maybeeta, then neither $t$ is, which is a contradiction since \rhs is always
  a \maybeeta by construction.
\end{proof}

\subsection{Progress}

\linketa are meant to delay the unification of ``problematic'' terms. In the
following, we call \linkStore the list of suspended links.

In order to activate a \linketa $l$, we need to extend the \elpiIn{progress1} predicate
by adding new rules. After passing under all the \elpiIn{abs}
constructors of $l$, there are two cases making a \linketa to progress, 1) \lhs
is instantiated to a rigid term 2) \rhs is no more a \maybeeta or it is a term
which can be reduced to a term with rigid head. 
If \lhs is instantiated to a rigid term $t$, by \cref{prop:nf},
we know that $t$ does not contain any \maybeeta. Let $t'$ the right hand side,
if $t$ is a constant or a function application, then, $t'$, which by
construction has \elpiIn{lam} as head, should be an $\eta$-expansion. We are
therefore allowed to unify $\lambda x. t \appsep x$ (the $\eta$-expanded version
of $t$) with $t'$. Finally, if $t$ is a term with \elpiIn{lam} as head, then
it is not an $\eta$-expansion and therefore, $t$ can be unified with $t'$. 

The second way to activate a \linketa is when the \rhs is no more a \maybeeta or
\rhs can be $\eta$-reduced to a term $t$ with rigid head. In both cases, \lhs is
unified with $t'$.

Once a \linketa is activated, it can be removed from \linkStore,
otherwise, the link is kept for a further iteration of \elpiIn{progress}. Note
that this link progression enforce
\cref{prop:nf,inv:linklhs,inv:link-eta-right}: we never commit a term in
the \Ho substitution, since we make unification only when we know that the 
terms are no more \maybeeta, and when \lhs is no more a variable or \rhs is 
no more a \maybeeta, the link is removed from \linkStore.

\printAll
  {{\elpiIn{flam x\ fapp [fuva X, x] ~\Uo~fcon"f"}}}
  {{A \Ue f}}
  {{\mapping{X}{X'}{1}}}
  {{\linketaM{}{A}{\lambda x.X'_{x}}}}

The example above shows the new compilation of the unification problem given at
the beginning of \cref{sec:eta}. This time, we see that the the left hand side
$t$ of $\mathcal{P}_1$ has been detected as a \maybeeta and replaced with the
fresh variable $A$. Moreover, \linkStore contains the link $l_1$ connecting $A$
with $\lambda x.X'_{x}$, the compiled version of $t$. After the resolution of
$\mathcal{T}_1$, $A$ is assigned to $f$. Therefore \lhs of $l_1$ is a term with
\elpiIn{con} as constructor. This means that \rhs of $l_1$ is a $\eta$-expansion
and therefore we can unify $\lambda x.f x$ with \rhs, which instantiate $X'_x$
to $f \appsep x$. $l_1$ is removed from \linkStore which is now empty,
\elpiIn{progress} terminate, and the decompilation, will instantiate the $X$
variable to $f$ (which is the $\eta$-contracted version of $\lambda x.f \appsep
x$). 

A second example, showing the activation of a link when the \rhs is no more a
\maybeeta, is given in \cref{sec:invariant1}, since we need to work with
variables used with different arities.

TODO: example for case 2: $\lambda x. \lambda y. F \appsep y \appsep x = G, F = \lambda x. \lambda y. a$

A second way to progress \linketa, that we call \linketa deduplication, is when
\linkStore contains two \linketa $l_1$ and $l_2$ with a \lhs having the same
variable address. Let the \lhs of $l_1$ be \elpiIn{uva U R} and the \lhs of
$l_2$ be \elpiIn{uva V S}, then, by \cref{inv:uvaarity}, \elpiIn{R}
and \elpiIn{S} have same scope. Let $t$ be the term obtained by replacing all
each name \elpiIn{S}$_i$ in the \rhs of $l_1$ with \elpiIn{R}$_i$, $t$ is
unified with the \rhs of $l_2$ and one of the two links between $l_1$ and $l_2$
is removed from \linkStore. 

TODO: example for this: $\lambda x. \lambda y. F \appsep y \appsep x = X,
\lambda x. \lambda y. F \appsep y \appsep x = Y$

\begin{lemma}
  Forall list of links \elpiIn{L} and \elpiIn{S}, \elpiIn{progress L _ S _}
  terminates
\end{lemma}

\begin{proof}[Proof sketch]
  The addition of rules for \elpiIn{progres1} complicates the function
  \elpiIn{progress}. We can note, however, that they do not prevent the
  termination of \elpiIn{progress}. 1) If a link is activated it is removed from
  \linkStore and the recursive call to \elpiIn{progress} will have a smaller
  list of links to recurse on. Moreover, link activation only runs terminating
  instructions (such as unification). 2) If a link is deduplicated, the
  termination of \elpiIn{progress} is still guaranteed since again we reduce
  \linkStore and the instructions run by link deduplications are all
  terminating. 3) If a link is neither activated nor deduplicated, i.e. it
  remains suspended, then \linkStore remains unchanged like the substitution;
  therefore, \elpiIn{if (L = L1, S1 = S2)} succeeds and \elpiIn{progress}
  terminates.
\end{proof}

TODO: we can have $\lambda x. F_x$ in the substitution if we know that $F$ does
not reduce to $T x$ where x is not free in $T$.

% \subsection{Example}

% In this subsection we show two complete runs of the extended version of \Ue.

% \paragraph{Example 1}
% \begin{center}
%   \elpiIn{flam x\ flam y\ fapp[fuva A, y, x] = flam x\ flam y\ x}
% \end{center}
% % $$\flambda xy.F \appsep y \appsep x = \lambda xy.x$$
% \begin{itemize}
%   \item After compilation: terms are $X0 = \lambda c0.\lambda c1.c0$ with links
%         $\linketaM{c0}{X1_{c0}}{\lambda c1.X2_{c1~c0}}, \linketaM{}{X0}{\lambda
%         c0.X1_{c0}}$ and mappings: $\mapping{C0}{X2}{2}$
%   \item After unification $X0$ is set to $\lambda c0.\lambda c1.c0$
%   \item This unification wakes up the second link, since its \lhs is now
%         instantiated. $X0$ is unified with its \rhs, which assigns $X1_{c0} :=
%         \lambda c1.c0$
%   \item The instantiation of $X1$ wakes the first link, and $\lambda c1.c0$ is
%         unified with $\lambda c1.X2_{c1~c0}$, setting $X2 _{c1~c2} := c2$ by
%         pruning.
%   \item All the links have been solved and the decompilation, assigns the \Fo{}
%         variable \elpiIn{A} to $\lambda xy.y$ 
% \end{itemize}

% \paragraph{Example 2}
% \begin{center}
%   \elpiIn{flam x\ fapp[f, fapp[fuva F, x], x] = fapp[f, flam x\ x]}
% \end{center}
% % $$\flambda xy.F \appsep y \appsep x = \lambda xy.x$$
% \begin{itemize}
%   \item After compilation: terms are $X0 = f~\lambda c0.c0$ with links
%         $\linketaM{}{X0}{\lambda c0.(f~X1_{c0}~c0)}$ and mappings:
%         $\mapping{C0}{X1}{1}$
%   \item After unification $X0$ is set to $f~\lambda c0.c0$
%   \item This unification wakes up the link, since its \lhs is now
%         instantiated. $X0$ is unified with its \rhs, which assigns $X1_{c0} :=
%         \lambda c1.c0$
%   \item The instantiation of $X1$ wakes the first link, and $\lambda c1.c0$ is
%         unified with $\lambda c1.X2_{c1~c0}$, setting $X2 _{c1~c2} := c2$ by
%         pruning.
%   \item All the links have been solved and the decompilation, assigns the \Fo{}
%         variable \elpiIn{A} to $\lambda xy.y$ 
% \end{itemize}


\section{Enforcing Invariant~\ref{inv:uvaarity}}
\label{sec:invariant1}

In \cref{sec:basic-comp-limitations}, we have given two unification problems to
be run one after the other. In the following table we present the entry problem,
its compiled version, with the corresponding list of mapping and links.
%
\printAll
  {{\elpiIn{flam x\ flam y\ fapp [fuva X, y, x] == flam x\ flam y\ x},
    \elpiIn{flam x\ fapp [fcon"f", fapp [fuva X, x], x] == fuva Y}}}
  {{E0 == \lambda x.\lambda y.x,
    E3 == E5}}
  {{\mapping{Y}{E5}{0},
    \mapping{X}{E2}{2}}}
  {{\linketaM{c0}{E4_{c0}}{\lambda x.E2_{c0 x}},
    \linketaM{}{E3}{\lambda x.(f~E4_{x}~x)},
    \linketaM{}{E0}{\lambda x.E1_{x}},
    \linketaM{c0}{E1_{c0}}{\lambda x.E2_{x c0}}}}

We see that the \elpiIn{maybe-eta} as detected $\lambda xy.F \appsep y \appsep
x$ and $\lambda x.f\appsep (F \appsep x) \appsep x$ and replaced them with
respectively the \Ho vars $X$ and $Z$. $X$ is linked with $\lambda x.Y_x$, $Y$
has arity $1$ and is $\eta$-linked with $\lambda y.H\appsep y \appsep x$ and $Z$
is linked to the term $\lambda x.f \appsep G_{x}~x$. However, the mapping
returned by the compilation, does not breaks \cref{inv:map-bijective}: the \Fo{}
variable $F$ is mapped to two different \Ho variables. To address this problem
and enforce \cref{inv:map-bijective}, we clean the mapping with a second phase
after the compilation. This phase is called \elpiIn{map-deduplication}.

Before formally defining this procedure, we need to define some auxiliary
relations. Let \mapStore be the list of mapping and $\langle m_1, m_2 \rangle
\in \mapStore$ such that the arity of the \Ho variable in $m_1$ is smaller than
the one in $m_2$. Let $X$ (resp. $Y$) the \Ho variable of $m_1$ (resp. $m_2$)
and $n = ar(m_1) - ar(m_2)$. We also let $A^i$ be a fresh \Ho variable. We
define the \elpiIn{make-eta-link} relation taking two mappings $\langle m_1, m_2
\rangle$ and returning the following list of link \linketa: $\forall i \in [1..n]$,
{
\def\scopeA{\ensuremath{x_1\dots x_{i-1}}}
\def\scopeB{\ensuremath{x_1\dots x_{i}}}
%
$$ 
  \left\{ 
    \begin{array}{ll}
      \linketaM{\phantom{\scopeA}}{X}      {\lambda x.  A^1_x}         & if~ i = 1 \\
      \linketaM{\scopeA}{A^{i-1}_{\scopeA}}{\lambda x_i.A^i_{\scopeB}} & if~ 1 < i < n\\
      \linketaM{\scopeA}{A^{i-1}_{\scopeA}}{\lambda x_i.Y  _{\scopeB}} & if~ i = n
    \end{array} 
  \right. 
$$
}
\noindent
More concretely, we are saying that for any two mappings, we build as many
\linketa as the difference of the arities between the two mappings. This links
are constructed in such a way that the \Ho variable $v$ with lowest arity is
linked to a fresh variable eta-expended variable $A^1$ having the scope of $v$.
This variable $A^1$ is then linked to a an $\eta$-expanded fresh variable $A^2$
with same scope of $A^1$ and so on. The last link is built between the $A^{n-1}$
(where $n$ is the difference of arities between the two mappings) and the \Ho
variable $u$ with higher arity in the two mappings being considered.

\begin{definition}[map-deduplication]
  Forall mappings $\langle m_1, m_2 \rangle \in \mapStore$, sharing the same
  \Fo{} variable, the list of \linketa $L$ is created thanks to
  \elpiIn{make-eta-link}$m_1~m_2~L$ and is added to \linkStore. Then $m_1$ is
  removed from \mapStore.
\end{definition}

If we take back the example give at the beginning of this section, we can
deduplicate $\mapping{F}{G}{1}, \mapping{F}{H}{2}$ by removing the first mapping
and adding the auxiliary \linketa: \linketaM{x}{G_{x}}{\lambda y.H_{x y}}.

The complete problem to run for resolution is now:
%
\printAll
  {{}}
  {{X = \lambda x.\lambda y.x, 
    Z = f\appsep(\lambda x.x)}}
  {{\mapping{F}{H}{2}}}
  {{\linketaM{x}{Y_{x}}{\lambda y.H_{y x}},
    \linketaM{\phantom{x}}{X}{\lambda x.Y_{x}},
    \linketaM{\phantom{x}}{Z}{\lambda x.f \appsep G_{x}~x},
    \linketaM{x}{G_{x}}{\lambda y.H_{x~y}}}}

After unification of the two terms, $X$ is assigned to $\lambda x.\lambda y.x$.
This assignment makes $l_2$ to progress since the \lhs is materialized and by
unification, between $X$ and $\lambda x.Y_{x}$, $Y_x$ is instantiate to $\lambda
y.x$. Once $Y_x$ is instantiated, $l_1$ can progress, and set $H_{xy}$ to $x$.
After all these progresses, $l_1$ and $l_2$ are remove from \linkStore and the
\elpiIn{progress} fixpoint terminates. Next, the second unification problem is
run, and $Z$ is set to $f\appsep(\lambda x.x)$. This unification wakes up $l_3$
and since $Z$ starts with the \elpiIn{app} node, the $\eta$-expanded version of
$Z$ is unified with $\lambda x.f \appsep G_{x}~x$ and $G_x$ is set to $x$.
As last step, the last link is progressed and the final \Ho substitution is
$\{X _{} \mapsto \lambda x.\lambda y.x, Y _{x} \mapsto \lambda y.x, 
G _{yx} \mapsto y, Z _{} \mapsto f~\lambda x.x, 
H _{x} \mapsto \lambda y.y\}$.

The decompilation phase is only charged, in this example to solve the mappings,
since no suspended links remain. The only mapping in the list is
\mapping{F}{H}{2}, which will assign the $F$ variable in \Fo{} to $\lambda xy.y$

TODO: dire che preserviamo l'invariante che tutte le variable sono fully-applied
  
\section{Handling of \maybebeta}\label{sec:beta}

TODO: say that maybe-eta also work in not(llambda)

% On
% the other hand, we also point out that the \maybeeta detection spot out
% potential $\eta$-expansion for terms that are not in \llambda. For example,
% $\lambda x.F \appsep G_x$ is considered as \maybeeta, since we have the
% application of term whose argument can reduce to $x$.

All the previous sections we have dealt with terms in \llambda, however, it is
often possible to work with terms in \maybebeta and wish to unify them. There
are situtation, for example, where the oracle has given  which $\beta$-reduction problems (\maybebeta) appears any
time we deal with a subterm $t = X t_1 \dots t_n$, where $X$ is flexible and the
list $[t_1 \dots t_n]$ in not in \llambda. This unification problem is not
solvable without loss of generality, since there is not a most general unifier.
If we take back the example given in \cref{sec:nutshell}, the unification $F a =
a$ admits two solutions for $F$: $\rho_1 = \{F \mapsto \lambda x.x\}$ and
$\rho_2 = \{F \mapsto \lambda \_.a\}$. Despite this, it is possible to work with
$\maybebeta$ if an oracle provides a substitution $\rho$ such that $\rho t$
falls again in the \llambda.

On the other hand, the \Ue is not designed to understand how the $\beta$-redexes
work in the object language. Therefore, even if we know that $F$ is assigned
to $\lambda x.x$, \Ue is not able to unify $F a$ with $a$. On the other hand,
the problem $F a = G$ is solvable by \Ue, but the final result is that $G$ is
assigned to $(\lambda x.x) a$ which breaks the invariant saying that the
substitution of the meta language does not generate terms outide \wellb{} (Property \ref{prop:nf}).

The solution to this problem is to modify the compiler such that any sub-term $t$
considered as a potential $\beta$-redex is replaced with a hole $h$ and a new dedicated
link, called \linkbeta.

\begin{elpicode}
  type link-beta tm -> tm -> link.
\end{elpicode}

\def\rhs{\ensuremath{rhs}\xspace}
\def\lhs{\ensuremath{lhs}\xspace}

This link carries two terms, the former representing the variable $h$ for the
new created hole and the latter containing the subterm $t$. As for the \linketa,
we will call $h$ and $t$ respectively the left hand side (\lhs)
and the right hand side (\rhs) of the \linkbeta.

\subsection{Compilation}

\paragraph{Detection of \maybebeta} TODO: \dots

\paragraph{Compilation with \linkbeta}

In order to build a \linkbeta, we need to adapt the compiler so that it can
recognize these ``problematic'' subterms. The following code snippet illustrate
such behavior, we suppose the rule to be added just after \cref{rule:comp-pf}.

\input{code/comp_beta}

A term is \maybebeta if it has the shape \elpiIn{fapp[fuva A|Ag]} and
\elpiIn{distinct Ag} does not hold. In that case, \elpiIn{Ag} is split in two
sublist \elpiIn{Pf} and \elpiIn{Extra} such that former is the longest prefix of
\elpiIn{Ag} such that \elpiIn{distinct Pf} holds. \elpiIn{Extra} is the list
such that \elpiIn{append Pf Extra Ag}. Next important step is to compile
recursively the terms of these lists and allocate a memory adress \elpiIn{B}
from the substitution in order to map the \Fo variable \elpiIn{fuva A} to
the \Ho variable \elpiIn{uva B}. The \linkbeta to return in the end is given
by the term \elpiIn{Beta = app[uva B Scope1 | Extra1]} constituting the \rhs,
and a fresh variable \elpiIn{C} having in scope all the free variables occurring
in \elpiIn{Beta} (this is \lhs). We point out that the \rhs is intentionally
built as an \elpiIn{uva} where \elpiIn{Extra1} are not in scope, since by
invariant, we want all the variables appearing in \Ho to be in \llambda.

\subsection{Progress}

Once created, there exist two main situations waking up a suspended \linkbeta.
The former is strictly connected to the definition of $\beta$-redex and occurs
when the head of \rhs is materialized by the oracle (see
\cref{prop:simulation}). In this case \rhs is safely\marginpar{explain why}
$\beta$-reduced to a new term $t'$ and the result can be unified with \lhs. In
this scenario the \linkbeta has accomplished its goal and can be removed from
\linkStore.

The second circumstance making the \linkbeta to progress is the instantiation of
the variables in the \elpiIn{Extra1} making the corresponding arguments to
reduce to names. In this case, we want to take the list \elpiIn{Scope1} and
append to it the largest prefix of \elpiIn{Extra1} in a new variable
\elpiIn{Scope2} such that \elpiIn{Scope2} remains in \llambda; we call
\elpiIn{Extra2} the suffix of \elpiIn{Extra1} such that the concatenation of
\elpiIn{Scope1} and \elpiIn{Extra1} is the same as the concatenation of
\elpiIn{Scope2} and \elpiIn{Extra2}. Finally, two cases should be considered: 1)
\elpiIn{Extra2} is the empty list, \lhs and rhs can be unified: we have two
terms in \llambda; otherwise 2) the \linkbeta in question is replaced with a
refined version where the \rhs is  \elpiIn{app[uva C Scope2 | Extra2]} and a new
\linketa is added between the \lhs and the new-added variable \elpiIn{C}.
\marginpar{dire che si adatta bene nelle approximation}

An example justifying this second  link manipulation is given by the following
unification problem:

\def\varF{\ensuremath{\textbf{F}}\xspace}
\def\varA{\ensuremath{\textbf{A}}\xspace}
\def\varB{\ensuremath{\textbf{B}}\xspace}

\begin{elpicode}
  f = flam x\ fapp[F, fapp[A, x]].
\end{elpicode}

% \begin{elpicode};
%   f = flam x\ flam y\ fapp[F, fapp[A, x], fapp[B, y]].
% \end{elpicode}

The compilation of these terms produces the new unification problem: $f = X0$

We obtain the mappings $\mapping{F}{\varF}{0}, \mapping{A}{\varA}{1}$ and the links:
%
\begin{gather}
  \linkbetaM{c0}{X3_{c0}}{X2~X1_{c0}}\\
  \linketaM{}{X0}{\lambda c0.X3_{c0}}
\end{gather}

\noindent
where the first link is a \linketa between the variable \texttt{X0}, representing
the right side of the unification problem (it is a \maybeeta) and
\texttt{X3}; and a \linkbeta between the variable \texttt{X3} and the subterm
$\lambda x.X1_x ~ a$ (it is a \maybebeta).
The substitution tells that \substCell{x}{X1_x}{x}.

We can now represent the \hrun execution from this configuration which will, at
first, dereference all the links, and then try to solve them. The only link
being modified is the second one, which is set to \linkbetaM{x}{X3}{X2 x a}. The
\rhs of the link has now a variable which is partially in the PF, we can
therefore remove the original \linkbeta and replace it with the following couple
on links:

\begin{textcode}
  ~$\vdash$~ X1   =~$\eta$~= x\ `X4 x'
x ~$\vdash$~ X3 x =~$\beta$~= x\ `X4 x' a
\end{textcode}

By these links we say that \texttt{X1} is now $\eta$-linked to a fresh variable
\texttt{X4} with arity one. This new variable is used in the new \linkbeta where
the name \texttt{x} is in its scope. This allows

\subsection{Tricky examples}

\begin{elpicode}
  triple ok (@lam x\ @app[@f, @app[@X, x]]) @Y,
  triple ok @X (@lam x\ x),
  triple ok @Y @f
\end{elpicode}

\begin{elpicode}
% @okl 22 [
%   triple ok (@lam x\ @lam y\ @app[@Y, y, x]) @X,
%   triple ok (@lam x\ @f) @X,
% ].
\end{elpicode}

\section{First order approximation}

\otext{Coq can solve this: \coqIn{f 1 2 = X 2}, by setting X to f 1}
\otext{We can re-use part of the algo for $\beta$ given before}


\section{Unif encoding in real life}
\otext{Il ML presentato qui è esattamente elpi}
\otext{Il OL presentato qui è esattamente coq}
\otext{Come implementatiamo tutto ciò nel solver}

\section{Results: stdpp and tlc}
\otext{How may rule are we solving?}
\otext{Can we do some perf test}

\section{Conclusion}

\printbibliography

\clearpage

\input{appendix.tex}

\end{document}