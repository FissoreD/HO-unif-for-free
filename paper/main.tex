\documentclass[sigconf,natbib=false,review]{acmart}
\usepackage[]{biblatex}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
\addbibresource{bib.bib}

\usepackage{myTools}
\usepackage{macros}
\usepackage{enumitem}
\usepackage{intcalc}
\usepackage{nameref}

% TODO: set this fields
%\setcopyright{cc}
%\setcctype{by}
%\copyrightyear{2024}
%\acmYear{XXXX 2024}
%\acmBooktitle{YYY}
%\acmDOI{ZZZZZZZZZZZZ}


% \xspaceaddexceptions{]\}}

\def\elpi{\proglang{elpi}}
\def\coqelpi{\proglang{coq-elpi}}
\def\lambdaprolog{\proglang{$\lambda$-prolog}}
\def\coq{\proglang{coq}}

\newcommand{\library}[1]{\textit{#1}\xspace}
\def\stdpp{\library{stdpp}}
\def\iris{\library{iris}}

\newcommand*{\acronym}[1]{\texttt{#1}\xspace}

\newtheorem{invariant}{Invariant}
\crefname{invariant}{invariant}{invariants}


\def\ol{\acronym{ol}} % object language
\def\ml{\acronym{ml}} % meta language
\def\lf{\acronym{lf}} % logical framework
\def\ho{\acronym{ho}} % higher order
\def\Forall{$\forall$}

\newcommand{\appsep}{\ensuremath{\textcolor{lightgray}{\cdot}}}
\newcommand{\EqualRel}{\ensuremath{=}}
\newcommand{\nEqualRel}{\ensuremath{\new}}
\newcommand{\UnifRel}{\ensuremath{\simeq}}
\newcommand{\nUnifRel}{\ensuremath{\not\simeq}}

\newcommand{\Uo}{\ensuremath{\UnifRel_o}\xspace}
\newcommand{\nUo}{\ensuremath{\nUnifRel_o}\xspace}
\newcommand{\Eo}{\ensuremath{\EqualRel_o}\xspace}
\newcommand{\nEo}{\ensuremath{\nEqualRel_o}\xspace}

\newcommand{\Ue}{\ensuremath{\UnifRel_\lambda}\xspace}
\newcommand{\nUe}{\ensuremath{\nUnifRel_\lambda}\xspace}
\newcommand{\Ee}{\ensuremath{\EqualRel_\lambda}\xspace}
\newcommand{\nEe}{\ensuremath{\nEqualRel_\lambda}\xspace}
\newcommand{\llambda}{\ensuremath{\mathcal{L}_\lambda}\xspace}

\newcommand{\linkMacro}[1]{\ensuremath{#1}\texttt{-link}\xspace}

\newcommand{\linkbeta}{\linkMacro{\beta}}
\newcommand{\linketa} {\linkMacro{\eta}}

\newcommand{\Fo}{\ensuremath{\mathcal{F}_{\!o}\xspace}} % space non va
\newcommand{\Ho}{\ensuremath{\mathcal{H}_o}\xspace}

\newcommand*{\eqtau}{\ensuremath{\mathrel{\overset{\mathrm{\tau}}{=}}}}

\newcommand{\linketaM}[3]{\ensuremath{#1 \vdash #2 =_\eta #3}}
\newcommand{\linkbetaM}[3]{\ensuremath{#1 \vdash #2 =_\beta #3}}
\newcommand{\substCell}[3]{\ensuremath{#1 \vdash #2 = #3}}
\newcommand{\mapping}[3]{\ensuremath{#1 \mapsto #2^#3}}

\newcommand{\lhs}{\ensuremath{\mathrm{lhs}}\xspace}
\newcommand{\rhs}{\ensuremath{\mathrm{rhs}}\xspace}

\newcommand{\linkStore}{\ensuremath{\mathbb{L}}\xspace}
\newcommand{\mapStore}{\ensuremath{\mathbb{M}}\xspace}
\newcommand{\foUnifPb}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\hoUnifPb}{\ensuremath{\mathbb{T}}\xspace}

\include{pb_printer}

\begin{document}

% \title{HO unification from object language to meta language}
\title{Higher-Order unification for free!}
\subtitle{Reusing the meta-language unification for the object language}

\author{Davide Fissore}
\email{davide.fissore@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\author{Enrico Tassi}
\email{enrico.tassi@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\begin{abstract}
  Specifying and implementing a proof system from scratch requires significant effort.
  Logical Frameworks and Higher Order Logic Programming Languages provide
  dedicated, high-level Meta Languages (ML) to facilitate this task in two
  key ways: 1) variable binding and substitution are simplified when ML binders
  represent object logic ones; 2) proof construction, and even proof search, is
  greatly simplified by leveraging the unification procedure provided by the ML.
  Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
  $\lambda$Prolog~\cite{miller_nadathur_2012} and
  Isabelle~\cite{10.1007/978-3-540-71067-7_7}
  which have been utilized to implement various formal systems such as
  First Order Logic~\cite{felty88cade},
  Set Theory~\cite{10.1007/BF00881873},
  Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
  Constructions~\cite{felty93lics}.

  The object logic we are interested in is Coq's~\cite{Coq-refman}
  Calculus of Inductive Constructions (CIC),
  for which we aim to implement a unification procedure \Uo using the ML
  Elpi~\cite{dunchev15lpar}, a dialect of $\lambda$Prolog.
  Elpi's equational theory comprises
  $\eta\beta$ equivalence and comes equipped with a
  higher order unification procedure \Ue restricted to the pattern
  fragment~\cite{miller92jsc}.
  We want \Uo to be as powerful as \Ue but on the object logic CIC.
  Elpi also comes with an encoding for CIC that works well
  for meta-programming~\cite{tassi:hal-01637063,tassi:hal-01897468,gregoire:hal-03800154,newtc}.
  Unfortunately this encoding, which we refer to as \Fo,
  ``underuses'' \Ue by restricting it to first-order unification problems only.
  To address this issue, we propose a better-behaved encoding, \Ho,
  demonstrate how to map unification problems in \Fo{}
  to related problems in \Ho, and illustrate
  how to map back the unifiers found by \Ue, effectively implementing
   \Uo on top of \Ue for the encoding \Fo.

  % We apply this technique to the implementation of a type-class~\cite{wadler89}
  % solver for Coq~\cite{Coq-refman}.
  % Type-class solvers are proof search procedures based on
  % unification that back-chain designated lemmas, providing essential
  % automation to widely used
  % Coq libraries such as Stdpp/Iris~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
  % and TLC~\cite{10.1007/978-3-642-14052-5_15}. These two libraries
  % constitute our test bed.
\end{abstract}

\keywords{Logic Programming, Meta-Programming, Higher-Order Unification, Proof Automation}

\maketitle

\section{Introduction}
\label{sec:intro}

Meta languages such as Elf~\cite{elf}, Twelf~\cite{twelf},
$\lambda$Prolog~\cite{miller_nadathur_2012} and
Isabelle~\cite{10.1007/978-3-540-71067-7_7}
have been utilized to specify various
logics~\cite{felty88cade,books/sp/NipkowPW02,10.1007/BF00881873,felty93lics}.
The use of these meta languages facilitated this task in two
key ways. The first and most well know one is that variable binding and
substitution come for free. %, exploited in all works mentioned above.
The second one is that these meta languages come equipped with some form
of unification, a cornerstone in proof construction and proof search.

% exploited only
%in the notable case of of Higher Order Logic~\cite{books/sp/NipkowPW02}:
%the meta language Isabelle is such a good match for HOL that it could used to
%implement an interactive proof system for the object logic, in addition to
%it specification.\\
The object logic we are interested in is Coq's~\cite{Coq-refman}
Calculus of Inductive Constructions (CIC) and we want to implement a
form of proof search known as type-class~\cite{wadler89,sozeau08} resolution.
In particular we want to leverage the Elpi~\cite{tassi:hal-01637063} meta programming language,
a dialect of $\lambda$Prolog already used to extend
Coq in various ways~\cite{tassi:hal-01637063,tassi:hal-01897468,gregoire:hal-03800154,newtc}.
Type-class solvers are unification based proof search procedures
reminiscent of Prolog that back-chain lemmas taken
from a designated database of ``type class instances'', hence
we can expect that Elpi is a good fit for
implementing such as form of automation. In this paper we focus on one aspect of
this work, namely \emph{how to reuse the higher order unification procedure
of the meta language in order to implement a type-class solver for the object
language}. As it turns out, re-using the unification of the meta language is
not a trivial task.

We take as an example the \coqIn{Decision} and \coqIn{Finite} type classes
from the Stdpp~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
library. The class  \coqIn{Decision}
identifies predicates equipped with a decision procedure, while
\coqIn{Finite} the types whose inhabitants can be enumerated in a (finite) list.
The following three designated \coqIn{Instances} state that:
1) the type \coqIn{fin n}, of natural numbers
smaller than \coqIn{n}, is finite;
2) the predicate \coqIn{nfact n nf}, linking a natural number
\coqIn{n} to the number of its prime factors \coqIn{nf}, is decidable;
3) the universal closure of a predicate has a decision procedure if
its domain is finite and if the predicate is decidable.

\begin{coqcode}
Instance fin_fin: ~$\forall$~n, Finite (fin n).             (* r1 *)
Instance nfact_dec: ~$\forall$~n nf, Decision (nfact n nf). (* r2 *)
Instance forall_dec: ~$\forall$~A P, Finite A ~$\to$~            (* r3 *)
  ~$\forall$~x:A, Decision (P x) ~$\to$~ Decision (~$\forall$~x:A, P x).
\end{coqcode}

\noindent Given this database a type-class solver is expected to
prove the following statement automatically:

\begin{coqcode}
  Decision (~$\forall$~x: fin 7, nfact x 3)                   (* g *)
\end{coqcode}

\noindent
The proof found by the solver back-chains on rule 3 (the only rule
about the $\forall$ quantifier), and then solves the premises with rules
rules 1 and 2 respectively.
Note that rule 3 features a second order parameter \coqIn{P} that stands for
a function of type \coqIn{A ~$\to$~ Prop} (a predicate over \coqIn{A}).
The solver has to infer a value for \coqIn{P} by unifying the conclusion
of rule 3 with the goal, and in particular by solving the unification
problem \coqIn{P x = nfact x 3}. This higher order problem falls in the so
called pattern-fragment \llambda~\cite{miller92jsc} and hence admits a unique
solution \coqIn{P = ~$\lambda$~x.nfact x 3}.

In order to implement such a search in Elpi we shall describe the encoding
of CIC terms and then the encoding of rules. Elpi comes with
an Higher Order Abstract Syntax~\cite{10.1145/53990.54010} datatype of CIC
terms, called \elpiIn{tm}, that features (among others) the following
constructors:

\begin{elpicode}
type lam  tm -> (tm -> tm) -> tm.     % lambda abstraction
type app  list tm -> tm.              % n-ary application
type all  tm -> (tm -> tm) -> tm.     % forall quantifier
type con  string -> tm.               % constants
\end{elpicode}

\noindent
Following $\lambda$Prolog~\cite{miller_nadathur_2012}'s standard syntax,
the meta level binding of a variable \elpiIn{x} in an expression
\elpiIn{e} is written <<\elpiIn{x\ e}>>, and square brackets denote a
list of terms separated by comma. For example the term
<<\coqIn{~$\forall$~y:t, nfact y 3}>> is encoded as follows:

\begin{elpicode}
all (con"t") y\ app[con"nfact", y, con"3"]
\end{elpicode}

\noindent
We now illustrate the encoding of the three instances above as higher-order
logic-programming rules: capital letters denote rule
parameters; \elpiIn{:-} separates the rule's head from the premises and
\elpiIn{pi w\ p} introduces a fresh nominal constant \elpiIn{w}
for the premise \elpiIn{p}.

\begin{elpicode}
finite   (app [con"fin", N]).                         ~\customlabel{clause:r1}{(r1)}~
decision (app [con"nfact", N, NF]).                   ~\customlabel{clause:r2}{(r2)}~
decision (all A x\ app [P, x]) :- finite A,           ~\customlabel{clause:r3}{(r3)}~
  pi w\ decision (app [P, w]).
\end{elpicode}

\noindent
Unfortunately this intuitive encoding of rule \ref{clause:r3} does not work,
since it uses the predicate \coqIn{P} as a first order term: for the meta
language its type is \elpiIn{tm}. If we try to back-chain the rule
\ref{clause:r3} on the encoding of the goal g given below

\begin{elpicode}
decision (all (app [con"fin", con"7"]) y\              ~\customlabel{goal:g}{(g)}~
  app [con"nfact", y, con"3"]).
\end{elpicode}

\noindent
we obtain an unsolvable unification problem \ref{problem:p}:
the two lists of terms have different lengths!
%The root cause is that
%\ref{problem:p} is an higher order in CIC, but becomes
%first order in the meta language due to the ``naive'' encoding.

\begin{elpicode}
app [con"nfact", y, con"3"] = app [P, y]               ~\customlabel{problem:p}{(p)}~
\end{elpicode}

\noindent
In this paper we study a more sophisticated encoding of rules that, on a first
approximation, would shape \ref{clause:r3} as follows:

\begin{elpicode}
decision (all A x\ Pm x) :- link Pm P A, finite A,    ~\customlabel{clause:r3a}{(r3')}~
  pi x\ decision (app [P, x]).
\end{elpicode}

\noindent
Since \elpiIn{Pm} is an higher-order unification variable
of type \elpiIn{tm -> tm},
with \elpiIn{x}
in its scope, the unification problem \ref{problem:pa}
admits one solution:

\begin{elpicode}
app [con"nfact", y, con"3"] = Pm y                    ~\customlabel{problem:pa}{(p')}~
Pm = x\ app [con"nfact", x, con"3"]                   ~\customlabel{solution:pm}{(\rho)}~
\end{elpicode}

\noindent
Once the head of rule \ref{clause:r3a} unifies with the goal \ref{goal:g}
the premise <<\elpiIn{link Pm A P}>> brings the assignment \ref{solution:pm}
back to the domain \elpiIn{tm} of Coq terms:

\begin{elpicode}
P = lam A a\ app [con"nfact", a, con"3"]
\end{elpicode}

\noindent
This simple example is sufficient to show that the encoding we seek
is not trivial and does not only concern the head of rules, but the entire sequence
of unification problems that constitute the execution of a logic program.
In fact
the solution for \elpiIn{P} above generates a
(Coq) $\beta$-redex in the second premise (the predicate
under the \elpiIn{pi w\ }\hspace{-0.4em}). We show below the premise before and
after the instantiation of \elpiIn{P}:

\begin{elpicode}
decision (app[                    P                   , w])
decision (app[ lam A (a\ app [con"nfact", a, con"3"]) , w])
\end{elpicode}

\noindent
In turn this redex prevents the rule \ref{clause:r2} to backchain properly since
the following unification problem has no solution:

\begin{elpicode}
app[ lam A (a\ app [con"nfact", a, con"3"]) , x] =
app[ con"nfact"                             , N, NF]
\end{elpicode}
\noindent
~\\
The root cause of the problems we sketched in this example
is a subtle mismatch between the equational theories and
unification procedures of the meta language and the object language.

The equational theory of CIC is very rich. In
addition to the usual $\eta\beta$-equivalence for functions, terms (hence types)
are compared up to proposition unfolding and fixpoint unrolling. Still,
for efficiency and predictability reasons, most form of automatic proof search
employ a unification procedure that captures a simpler one,
just $\eta\beta$, and that solves higher-order problems
restricted to the pattern fragment \llambda.
We call this unification procedure \Uo{}.

The equational theory of the meta language Elpi is strikingly similar,
since it it comprises $\eta\beta$ (for the meta language functions), and the
unification procedure \Ue{} solves problems in
\llambda as well.

In spite of the similarity the link between \Ue{} and \Uo{} is not trivial,
since the abstraction and application term constructors
the two unification procedures deal with are different.
% For example:\\
% %
% \vspace{4pt}
% {
% \setlength{\tabcolsep}{2pt}
% \begin{tabular}{lcl|}
% \elpiIn{x\ f x} & \Ue{} & \elpiIn{f}\\
% \elpiIn{lam A x\ app[con"f", x]} & \Uo{} & \elpiIn{con"f"} \phantom{mn} \\
% \elpiIn{lam A x\ app[con"f", x]} & \nUe{} & \elpiIn{con"f"}
% \end{tabular}
% \phantom{mn}
% \begin{tabular}{lcl}
% \elpiIn{P x} & \Ue{} & \elpiIn{x}\\
% \elpiIn{app[P, x]} & \Uo{} & \elpiIn{x}\\
% \elpiIn{app[P, x]} & \nUe{} & \elpiIn{x}\\
% \end{tabular}
% }
% \vspace{4pt}
%
\paragraph{Contributions}
In this paper we identify a minimal language \Fo{} in which the problems
sketched in the introduction can be formally described.
We detail an encoding of a logic program on \Fo{} to a strongly related
logic program in \Ho (the language of the meta language) and we show that
the unification procedure of the meta language \Ue{} can be effectively
used to simulate a unification procedure \Uo for the object language that
features $\eta\beta$-conversion in the pattern-fragment.

\todo{fix}\cref{sec:problem-statement} formally states the problem and gives the
intuition behind our solution. \cref{sec:encodings} discusses alternative
term encodings and related works. \cref{sec:grounwork} introduces
the languages \Fo{} and \Ho{}, \cref{sec:simulation} describes a
basic simulation of higher order logic programs.
\cref{sec:eta,sec:invariant1} completes its equational theory
with support for $\eta$-conversion. \cref{sec:beta} deals with the
practical necessity of ``tolerating'' terms outside of the
pattern-fragment and discusses how heuristic can be applied.
Finally \cref{sec:implementation} discusses the implementation in Elpi.

The $\lambda$Prolog code discussed in the paper can be accessed at the
URL: \url{https://github.com/FissoreD/paper-ho}.

\section{Problem statement and solution} %%%%%%%%%%%%%%%%%%%%%%
\label{sec:problem-statement}

\newcommand{\specunif}[3]{
  \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    \exists \rho, %
      \rho #3_1 #1 \rho #3_2  %
        \Leftrightarrow #3_1 #2 #3_2 \mapsto \rho' \subseteq \rho
}


\newcommand{\unifcorrect}[3]{
  % \forall \rho #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    \{#3_1, #3_2\} \subseteq \llambda \Rightarrow
      #3_1 #2 #3_2 \mapsto \rho
        \Rightarrow
          \rho #3_1 #1 \rho #3_2  %
}

\newcommand{\unifcomplete}[3]{
  % \forall #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    \{#3_1, #3_2\} \subseteq \llambda \Rightarrow
      % \forall \rho, %
        \rho #3_1 #1 \rho #3_2  %
          \Rightarrow \exists \rho', #3_1 #2 #3_2 \mapsto \rho' \land \rho' \subseteq \rho
}
\newcommand{\maybeeta}{\ensuremath{\Diamond\eta}\xspace}
\newcommand{\maybebeta}{\ensuremath{\Diamond\beta_0}\xspace}
\newcommand{\notllambda}{\ensuremath{\Diamond\llambda}\xspace}
%\newcommand{\notllambda}{\ensuremath{\Diamond\beta}\xspace}

Even if we encountered the problem working on CIC we devise
a minimal setting to ease its study. In this setting we have
a \Fo{} language (for first order) with a rich(er) equational
theory and a \Ho{} meta language with a simpler one, and we reuse
the unification procedure of \Ho{} in order to implement one for \Fo.


\subsection{Preliminaries: \Fo{} and \Ho{}}

In order to reason about unification we provide a description of the
\Fo{} and \Ho languages where unification variables
are first class terms, i.e. they have a concrete syntax as
per \cref{code:common-terms}.
% We keep these languages
%minimal, for example, we omit the \elpiIn{all} quantifier of CIC we used
%in the example in Section~\ref{sec:intro} together with the type notation of
%terms carried by the \elpiIn{lam} constructor.
%
{
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-13pt}
\begin{figure} %[H]
  \begin{tabular}{ll}
  \begin{minipage}{0.21\textwidth}
   \inputrawelpicode{code/fo_tm}
  \end{minipage}
  &
  \begin{minipage}{0.24\textwidth}
   \inputrawelpicode{code/ho_tm}
  \end{minipage}
  \end{tabular}\vspace{4pt}
  \caption{The \Fo{} and \Ho languages}\vspace{0.3em}
  \label{code:common-terms}
  \Description[code:common-terms]{code:common-terms}
\end{figure}
}
Unification variables (\elpiIn{fuva} term constructor)
in \Fo{} have no explicit scope:
the arguments of an higher order variable are given via the \elpiIn{fapp}
constructor. For example the term <<\coqIn{P x}>> is represented as
<<\elpiIn{fapp[fuva N, x]}>>, where \elpiIn{N} is a memory address and
\elpiIn{x} is a bound variable.\\
In \Ho the representation of <<\coqIn{P x}>> is instead <<\elpiIn{uva N [x]}>>,
since unification variables are higher order and come equipped with an
explicit scope.
%\todo{use faddr for Fo}
%
%faddr and addr are memory addresses, the details are given in bla,
%here they are just unique identifiers for unif variables and their types
%do now allow to mistake one for the other.
%\todo{cleanup}

\paragraph{Notational conventions}

When we write \Ho terms outside code blocks we follow the
usual $\lambda$-calculus notation, reserving $f, g, a, b$ for constants,
$x, y, z$ for bound variables and $X, Y, Z, F, G, H$ for unification variables.
However we need to
distinguish between the ``application'' of a unification variable
to its scope and the application of a term to a list of arguments.
We write the scope of unification variables in subscript
while we use juxtaposition for regular application.
Here a few examples:\\
\vspace{4pt}
{
\setlength{\tabcolsep}{1em}
\begin{tabular}{ll}
  $f\appsep a$                  & \elpiIn{app [con "f", con "a"]}\\
  $\lambda x.\lambda y.F_{x y}$ & \elpiIn{lam x\ lam y\ uva F [x, y]} \\
  $\lambda x.F_{x} \appsep a$   & \elpiIn{lam x\ app [uva F [x], con "a"]} \\
  $\lambda x.F_{x} \appsep x$   & \elpiIn{lam x\ app [uva F [x], x]} \\
\end{tabular}
}
\vspace{4pt}

\noindent
When it is clear from the context we shall use the same syntax for \Fo{} terms
(although we never subscripts unification variables).

We use $s$, $s_1$, \ldots for terms in \Fo{} and $t$, $t_1$ \ldots for
terms in \Ho{}.

\subsection{Equational theories an unification}

In order to specify unification we need to
define the equational theory and
substitution (unification-variable assignment).

\subsubsection{Term equality: \Eo and \Ee}
For both languages we extend the equational theory
over ground terms to the full language by adding the reflexivity of
unification variables (a variable is equal to itself).

The first four rules are common to both equalities
and just define the usual congruence over terms. Since
we use an HOAS encoding they also capture $\alpha$-equivalence.
In addition to that \Eo has rules for $\eta$ and $\beta$-equivalence.

\input{code/feq}

\begin{elpicode}
  ~\PYG{k+kd}{type} \PYG{n+nf}{(\Ee)} \PYG{k+kt}{tm -> tm -> o}~.
  con C ~\Ee~fcon C.
  app A ~\Ee~fapp B :- forall2 ~(\Ee)~ A B.
  lam F ~\Ee~flam G :- pi x\ x ~\Ee~x => F x ~\Ee~G x.
  uva N A ~\Ee~fuva N B :- forall2 ~(\Ee)~ A B.
\end{elpicode}

\noindent
The main point in showing these equality tests is to remark how
weaker \Ee is, and to identify the four rules that need special
treatment in the implementation of \Uo.
For brevity we omit the code of \elpiIn{beta}:
it is sufficient to know that <<\elpiIn{beta F L R}>> computes in \elpiIn{R} the
weak head normal form of <<\elpiIn{app[F|L]}>>.

\paragraph{Substitution: $\rho s$ and $\sigma t$}

We write $\sigma = \{~ X \mapsto t ~\}$ the substitution that assigns
the term $t$ to the variable $X$.
We write $\sigma t$ for the application of
the substitution to a term $t$, and $\sigma X = \{~ \sigma t ~|~ t \in X ~\}$ when
$X$ is a set of terms.
We write $\sigma \subseteq \sigma'$ when $\sigma$ is more
general than $\sigma'$.
The domain of a substitution is the set of unification variables for which
it provides an assignment.
We write $\sigma \cup \sigma'$ set union to denote the concatenation of
two substitutions whose domains are disjoint.
We shall use $\rho$ for \Fo{} substitutions,
and $\sigma$ for the \Ho ones.
\todo{can be made a little more formal}
For brevity, in this section we consider
the substitution for \Fo{} and \Ho{} identical.
We defer to \cref{sec:grounwork} a more precise description
pointing out theirs differences.

\paragraph{Term unification: \Uo vs. \Ue}

Although we provide an implementation of \Ue in the supplementary material
(that we used for testing purposes) we only describe its signature here.

\input{code/ue_type}

The meta language of choice is expected to provide 
an implementation of \Ue that satisfies
the following properties:
%~\ref{prop:correct-ml} and~\ref{prop:complete-ml}.
\begin{gather}
  \unifcorrect{\Ee}{\Ue}{t} \label{prop:correct-ml}\\
  \unifcomplete{\Ee}{\Ue}{t}\label{prop:complete-ml}
\end{gather}

%
% To state precisely the problem we solve we need a \Fo{} representation
% of CIC terms and a \Ho one. We extend the equality over ground
% terms to open ones with the reflexivity of unification variables (that is
% unification variable X is equal to itself, not to another one such a Y).
% We call \Eo that equality in \Fo{} and \Ee its counterpart in \Ho.
% We call \Uo the unification procedure we want to implement and
% \Ue the one provided by the meta language.

We write 
$\sigma t_1 \Ue \sigma t_2 \mapsto \sigma'$ when
$\sigma t_1$ and $\sigma t_2$ unify with substitution $\sigma'$.
We write $t_1 \Ue t_2 \mapsto \sigma$ when
the initial substitution is empty.
Note that if $\sigma t_1 \Ue \sigma t_2 \mapsto \sigma'$ then
the domains of $\sigma$ and $\sigma'$ are disjoint.

Although we provide an implementation of \Uo{} in \cref{sec:founif},
our real goal is the simulation of an entire logic program.

\subsection{The problem: Logic Program Simulation}

We represent a logic program \emph{run} in \Fo{} as
a list \emph{steps} $p$ of length $\mathcal{N}$.
At each step $p$ we unify two terms $\foUnifPb_{p_l}$ and
$\foUnifPb_{p_r}$ taken from the set of all terms \foUnifPb.
\footnote{If the same rule is used multiple times in a run we
just consider as many copies as needed of the terms composing the
rules, with fresh unification variables each time.}
The composition of these steps starting from the
empty substitution $\rho_0$ produces the final
substitution $\rho_\mathcal{N}$, that is the result of the
logic-program execution.
%
\newcommand{\C}[4]{\ensuremath{\langle #1 \rangle}\mapsto(#2,#3,#4)}
\newcommand{\D}[4]{\ensuremath{\langle #1,#2,#3 \rangle^{-1}\mapsto #4}}
\newcommand{\progress}{\ensuremath{\mathrm{progress}}\xspace}
\newcommand{\fstep}{\ensuremath{\mathrm{fstep}}\xspace}
\newcommand{\hstep}{\ensuremath{\mathrm{hstep}}\xspace}
\newcommand{\frun}{\ensuremath{\mathrm{frun}}\xspace}
\newcommand{\hrun}{\ensuremath{\mathrm{hrun}}\xspace}
\newcommand{\stepF}[4]{\ensuremath{\fstep(#1,#2,#3) \mapsto #4}}
\newcommand{\stepFD}[5]{%
\ensuremath{#3 #1_{#2_l} \Uo #3 #1_{#2_r} \mapsto #4 \land #5 = #3 \cup #4}}
\newcommand{\stepH}[6]{\ensuremath{\hstep(#1,#2,#3,#4) \mapsto (#5, #6)}}
\newcommand{\stepHD}[6]{\ensuremath{%
#3 #1_{#2_l} \Ue #3 #1_{#2_r} \mapsto #4 \land \progress(#6,#3 \cup #4) \mapsto (#6',#5)}}
\newcommand{\runF}[3]{\ensuremath{\frun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runFD}[2]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepF{#1}{p}{\rho_{p-1}}{\rho_{p}}}}
\newcommand{\runH}[3]{\ensuremath{\hrun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runHD}[3]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepH{#1}{p}{\sigma_{p-1}}{#3_{p-1}}{\sigma_{p}}{#3_p}}}
\newcommand{\deff}{\ensuremath{\stackrel{{\scriptscriptstyle def}}{=\!=\!\!\!=}}}
%
$$
\begin{array}{l}
\stepF{\foUnifPb}{p}{\rho}{\rho''}
\deff
\stepFD{\foUnifPb}{p}{\rho}{\rho'}{\rho''}\vspace{2pt}\\
\runF{\foUnifPb}{\mathcal{N}}{\rho}
\deff
\runFD{\foUnifPb}{\mathcal{N}}
\end{array}
$$

\noindent 
In order to simulate a \Fo{} logic program in \Ho{} we compile
each term $s \in \Fo{}$ into a term $t \in \Ho{}$. We write this
step $\C{s}{t}{m}{l}$. The implementation of the compiler
is detailed in \cref{sec:compilation,sec:eta,sec:beta}, here we just point
out that it additionally a variable mapping $m$ and list of links $l$.
The variable map connects unification variables in \Ho with variables
in \Fo{} and is used to ``decompile'' the assignment,
$\D{\sigma}{m}{l}{\rho}$. Links are an accessory piece of information whose
description is deferred to \cref{sec:nutshell}.

We simulate each run in \Fo{} with a run in \Ho as follows.
%Note that $\sigma_0$ is the empty substitution.
$$
\begin{array}{l}
\stepH{\hoUnifPb}{p}{\sigma}{\linkStore}{\sigma''}{\linkStore'} \deff\vspace{2pt}\\
  \qquad\stepHD{\hoUnifPb}{p}{\sigma}{\sigma'}{\sigma''}{\linkStore}\vspace{2pt}\\
\end{array}
$$
$$
\begin{array}{l}
  \runH{\foUnifPb}{\mathcal{N}}{\rho} \deff \vspace{2pt}\\
  \qquad \hoUnifPb \times \mapStore \times \linkStore_0 = \{ (t_j,m_j,l_j) | s_j \in \foUnifPb, \C{s_j}{t_j}{m_j}{l_j} \}\vspace{2pt}\\
  \qquad \runHD{\hoUnifPb}{\mathcal{N}}{\linkStore}\vspace{2pt}\\
  \qquad \D{\sigma_{\mathcal{N}}}{\mapStore}{\linkStore_{\mathcal{N}}}{\rho_{\mathcal{N}}}
\end{array}
$$

\noindent
By analogy with \foUnifPb, we write $\hoUnifPb_{p_l}$ and $\hoUnifPb_{p_r}$
for the two \Ho{} terms being unified at step $p$, and we write $\hoUnifPb_p$
for the set $\{ \hoUnifPb_{p_l}, \hoUnifPb_{p_r} \}$.\\
\hstep{} is made of two sub-steps: a call to the meta language
unification and a check for \progress{} on the set of links, that intuitively
will compensate for the weaker equational theory honoured by \Ue.
\hrun{} compiles all terms in \foUnifPb{}, then executes each step and
finally decompiles the solution.
We claim:

\begin{proposition}[Simulation]\label{prop:simulation}
$\forall \foUnifPb, \forall \mathcal{N},$ if $~\foUnifPb \subseteq \llambda$
$$
  \runF{\foUnifPb}{\mathcal{N}}{\rho}
  \Leftrightarrow
  \runH{\foUnifPb}{\mathcal{N}}{\rho}
$$
\end{proposition}

\noindent
That is, the two executions give the same result. Moreover:

\begin{proposition}[Simulation fidelity]\label{prop:fidelity}
In the context of$\;$ \hrun, if $~\foUnifPb \subseteq \llambda$ we have that
$\forall p \in 1 \ldots \mathcal{N},$
$$
\stepF{\foUnifPb}{p}{\rho_{p-1}}{\rho_p}
\Leftrightarrow
\stepH{\hoUnifPb}{p}{\sigma_{p-1}}{\linkStore_{p-1}}{\sigma_p}{\linkStore_p}
$$
\end{proposition}
\noindent
In particular this property guarantees that a \emph{failure} in the \Fo{} run
is matched by a failure in \Ho{} \emph{at the same step}. We consider this
property very important from a practical point of view since it guarantees
that the execution traces are strongly related and in turn this enables a user
to debug a logic program in \Fo{} by looking at its execution trace in
\Ho{}.

%\cref{sec:beta}
%XXX permuting hrun does not change the final result if check does not fail eagerly
% XXX if we want to apply heuristics, we can apply them in decomp to avoid committing to a non MGU too early


% We can define $s_1 \Uo{} s_2$% by specializing the code of \hrun{} to
% %$\foUnifPb = \{ s_1, s_2 \}$ 
% as follows:
% %
% $$
% \begin{array}{l}
% s_1 \Uo s_2 \mapsto \rho \deff \vspace{2pt}\\
% \quad\C{s_1}{t_1}{m_1}{l_1} \land \C{s_2}{t_2}{m_2}{l_2}\vspace{2pt}\\
% \quad    t_1 \Ue t_2 \mapsto \sigma' \land
%     \progress(\{l_1,l_2\},\sigma') \mapsto (L,\sigma'') \land\vspace{2pt}\\
% \quad \D{\sigma''}{\{m_1,m_2\}}{L}{\rho}
% \end{array}
% $$

% \begin{proposition}[Properties of \Uo{} in \llambda]
% \begin{gather}
%   \unifcorrect{\Eo}{\Uo}{s}\label{prop:correct}\\
%   \unifcomplete{\Eo}{\Uo}{s}\label{prop:complete}
% \end{gather}
% \end{proposition}


%In addition to correctness and completeness in \llambda,
We also claim that \hrun
handles terms outside \llambda in the following sense:

\begin{proposition}[Fidelity recovery]
\begin{gather}
  \exists \rho, \rho s_1 \Eo \rho s_2 \Rightarrow
  \C{s_i}{t_i}{m_i}{l_i} \Rightarrow
  t_1 \Ue t_2 \mapsto \sigma \label{prop:compilation-nllam}\\
  \sigma_{p-1} \hoUnifPb_{p} \in \llambda \Rightarrow \label{prop:step-nllam}\\
  \exists \rho,\stepF{\foUnifPb}{p}{\rho}{\rho'} \Leftrightarrow
  \stepH{\hoUnifPb}{p}{\sigma_{p-1}}{\linkStore_{p-1}}{\sigma_{p}}{\linkStore_p} \nonumber
\end{gather}
\end{proposition}

\noindent
Property \ref{prop:compilation-nllam} states that two terms for which
there is a unifier (given by an oracle and not necessarily a most general one),
then the compiler generates two terms that unify in \Ho.\\
%In other words the compiler moves out of the way all problematic terms.
Property \ref{prop:step-nllam} says that if the two terms involved in a step
re-enter \llambda, then \hstep succeeds. This is a typical example
in which the order of the unification problems in a logic-program run
does matter. The simplest example is the sequence $F \UnifRel \lambda x.a$ and
$F \appsep a \UnifRel a$: the second problem is not in \llambda and has two
unifiers, namely $\sigma_1 = \{~ F \mapsto \lambda x.x ~\}$ and
$\sigma_2 = \{~ F \mapsto \lambda x.a ~\}$. The first problem picks $\sigma_2$
making the second problem re-enter \llambda. In other words
\cref{prop:fidelity} \todo{...}

\subsection{The solution (in a nutshell)}
\label{sec:nutshell}
A term $s$ is compiled in a term $t$ where every
``problematic'' sub term $p$ is replaced by a fresh unification variable $h$
and an accessory \emph{link} that represents a suspended unification problem
$h \Ue p$. As a result \Ue is ``well behaved'' on $t$, in the sense that
it does not contradict \Eo as it would otherwise do on the
``problematic'' sub-terms. We now define ``problematic'' and ``well behaved''
more formally.

\begin{definition}[\maybebeta]\label{def:maybebeta}
  \maybebeta is the set of terms of the form $X \appsep x_1 \ldots x_n$
  such that $x_1 \ldots x_n$ are distinct names (of bound variables).
\end{definition}

\noindent
An example of term $t$ in \maybebeta{} is the application $F \appsep x$.
This term is problematic since the application node of
its syntax tree cannot be used to justify a
unification failure, i.e. by properly instantiating $F$ the term
head constructor may become a $\lambda$, or a constant or stay an application.

\begin{definition}[\maybeeta]\label{def:maybeeta}
  \maybeeta is the set of terms $t$ such that $\exists \rho, \rho t$
  is an eta expansion.
\end{definition}

\noindent
An example of term $t$ in \maybeeta{} is
$\lambda x.\lambda y.F \appsep y \appsep x$
since the substitution
$\rho = \{ F \mapsto \lambda a.\lambda b.f \appsep b \appsep a\}$
makes $\rho t = \lambda x.\lambda y.f \appsep x \appsep y$
that is the eta long form of $f$. This term is problematic since
its leading $\lambda$ abstraction cannot justify a
unification failure against a constant or an application.

\begin{definition}[\notllambda]\label{def:notllambda}
  \notllambda is the set of terms of the form $X \appsep t_1 \ldots t_n$
  such that $t_1 \ldots t_n$ are not distinct names.
\end{definition}

\noindent
These terms are problematic for the very same reason terms in \maybebeta are,
but cannot be handled directly by the unification of the meta language, that
is only required to handle terms in \llambda.

% An example of $t$ in \notllambda{} is $F \appsep a$ for a constant $a$.
% Note however tha
% an oracle could provide an assignment $\rho = \{ F \mapsto \lambda x.x\}$
% that makes the resulting term fall back in \llambda.
% \todo{said before}

\newcommand{\subterm}[1]{\ensuremath{\mathcal{P}(#1)}}
We write $\subterm{t}$ the set of sub-terms of $t$, and
%\begin{definition}[Subterms \subterm{t}] The set of sub terms of $t$ is the
%  largest set $\subterm{t}$ that can be obtained by the following rules.
%$$
%\begin{array}{l}
%t \in \subterm{t}\\
%t = f t_1\ldots t_n \Rightarrow \subterm{t_i} \subseteq \subterm{t} \land f \in \subterm{t}\\
%t = \lambda x.t' \Rightarrow \subterm{t'} \subseteq \subterm{t}\\
%\end{array}
%$$
%\end{definition}
%\noindent
we write $\subterm{X} = \bigcup_{t\in X} \subterm{t}$ when $X$ is a set of terms.

\newcommand{\wellb}{\ensuremath{\mathcal{W}}\xspace}
\begin{definition}[Well behaved set]
Given a set of terms $X \subseteq \Ho{}$,
$$
\wellb(X) \Leftrightarrow \forall t \in \subterm{X}, t \not\in (\notllambda{} ~\cup~ \maybeeta{} ~\cup~ \maybebeta{})
$$
\end{definition}

\noindent

\begin{proposition}[\wellb{}-preservation]\label{prop:nf}
$\forall \hoUnifPb, \forall \linkStore, \forall p, \forall \sigma, \forall \sigma'$
$$
\begin{array}{l}
\wellb(\sigma\hoUnifPb) \land
  \sigma\hoUnifPb_{p_l} \Ue \sigma\hoUnifPb_{p_r} \mapsto {\sigma'}
  \Rightarrow \wellb(\sigma' \hoUnifPb)\\
\wellb(\sigma\hoUnifPb) \land
  \progress(\linkStore,\sigma) \mapsto (\_,\sigma')
  \Rightarrow \wellb(\sigma' \hoUnifPb)
\end{array}
$$
\end{proposition}

\noindent
Proposition \ref{prop:nf} is key to prove \cref{prop:simulation,prop:fidelity}:
informally it says that the problematic terms moved on the side by the compiler
are not put back by \hstep, hence \Ue{} can operate properly.
In \cref{sec:compilation,sec:eta,sec:beta}
we describe how the compiler recognizes terms in \maybebeta, \maybeeta and
\notllambda and how \progress takes care of them preserving \wellb
and granting \cref{prop:simulation,prop:fidelity}.

% Note that proposition \ref{prop:nf} does not hold for \hrun as a whole
% since decompilation can introduce (actually restore) problematic terms.

\section{Ground work for the compiler}
\label{sec:grounwork}

% The predicate to test this condition is called \elpiIn{pattern-fragment}:

% \input{code/pattern_fragment}

Unification variables are identified by a
natural number, that represents a memory addresses
The memory and its associated operations are described below:

\input{code/mem_types}

\noindent
If a memory cell is \elpiIn{none}, then the corresponding unification variable
is not set. \elpiIn{assign} sets an unset cell to the given value, while
\elpiIn{new} finds the first unused address and sets it to \elpiIn{none}.

Since each occurrence of a \Ho unification variables has a scope,
its solution needs to be abstracted over it to enable the
instantiation of a single assignment to different scopes.
This is expressed by the \elpiIn{inctx} container, and in particular
its \elpiIn{abs} binding constructor.
On the contrary a solution to a \Fo variable is a plain term.

\input{code/fo_subst}
\input{code/ho_subst}

\noindent
We call \elpiIn{fsubst} the memory of \Fo{}, while we call \elpiIn{subst}
the one of \Ho.
The compiler establishes a mapping between variables of the two languages.

\input{code/comp_base_types}

Each \elpiIn{hvariable} is stored in the mapping together with
its arity so that the code of \ref{clause:malloc} below can preserve:

\begin{invariant}[Unification variable arity]
  Each variable \elpiIn{A}
  in \Ho has a (unique) arity \elpiIn{N} and each occurrence~
  \elpiIn{(uva A L)} is such that \elpiIn{(len L N)} holds
  \label{inv:uvaarity}
\end{invariant}

\input{code/alloc_mapping}

\noindent
When a single \elpiIn{fvariable} occurs multiple times with different numbers
of arguments the compiler generates multiple mappings for it, on a first
approximation, and then makes the mapping bijective by introducing
\linketa; this detail is discussed in section \ref{sec:invariant1}.


\noindent
As we mentioned in section~\ref{sec:nutshell} the compiler
replaces terms in \maybeeta, \maybebeta and \notllambda with fresh
variables linked to the problematic terms. Terms in \maybebeta do not
need a link since \Ho{} variables faithfully represent
the problematic term thanks to their scope.

\input{code/comp_links}

\noindent
The right hand side of a link, the problematic term, can occur under binders.
To accommodate this situation the compiler wraps \elpiIn{baselink} using
the \elpiIn{inctx} container (see, \ref{data:inctx}).

\begin{invariant}[Link left hand side]\label{inv:linklhs}
  The left hand side of a suspended link
  is a variable.
\end{invariant}

\noindent
New links are suspended by construction.
If the left hand side variable is assigned during a step, then 
the link is considered for progress and possibly eliminated.
This is discussed in \cref{sec:eta} and \cref{sec:beta}.


% \input{code/beta_fo}

% \noindent
% The \elpiIn{name} predicate holds only on nominal constants (i.e. bound
% variables).\footnote{Elpi provides it as a builtin, but one could implement it by
% systematically loading the hypothetical rule \elpiIn{name x} every time
% a nominal constant is postulated via \elpiInFN{pi x\ }}
% The choice of using n-ary application, rather than binary, is to make it
% easy to access the application's head. The price we pay is that substituting
% an application in the head of an application should be amended by
% ``flattening'' \elpiIn{fapp} nodes, that is the job of \elpiIn{napp}.
% \footnote{Note that \elpiIn{napp} is an artefact of formalization of \Fo{}
% we do in this presentation and, as we explain later,
% no equivalent of \elpiIn{napp} is needed in \Ho.}
% Finally note that the cut operator is inessential, it could be
% removed at the cost of a verbose test on the head of \elpiIn{L}
% in the second rule about \elpiIn{fapp}: \elpiIn{L}'s head
% can be \elpiIn{fcon}, \elpiIn{flam} or a name.


Applying the substitution corresponds to dereferencing a term with respect to
the memory. To ease the comparison we split \Fo{} dereferencing into a
\elpiIn{fder} step and a \elpiIn{napp} one. The former step replaces references
to memory cells that are set with their values, and has a corresponding
operation in \Ho, namely \elpiIn{deref}. On the contrary \elpiIn{napp}
has no corresponding operation in \Ho, and only ensures that
terms of the form <<\elpiIn{fapp[fapp L1|L2]}>> are replaced by
<<\elpiIn{fapp L3}>> where \elpiIn{L3} is the concatenation of \elpiIn{L1}
and \elpiIn{L2}. The reasons for this asymmetry is
that an \elpiIn{fapp} node with a flexible head is always mapped
to a \elpiIn{uva} (as per \cref{sec:simulation,sec:beta}),
preventing nested applications to materialize.

\input{code/fderef}

\noindent
Applying the substitution in \Ho{} is very similar, with
the caveat that assignments have to be moved to the
current scope, i.e. renaming the \elpiIn{abs}-bound variables
with the names in the scope of the unification variable occurrence.

\input{code/deref}

\noindent
Note that move strongly relies on invariant \ref{inv:uvaarity}: the length
of the arguments of all occurrences of a unification variable and the
number of abstractions in its assignment have to match. In turn
this grants that \elpiIn{move} never fails.

\input{code/move}

\subsection{Notational conventions}


\noindent
When variables $x$ and $y$ can occur in term $t$ we shall write
$t_{xy}$ to stress this fact. 

We write $\sigma = \{~ A_{xy} \mapsto y ~\}$ for the assignment
\elpiIn{abs x\abs y\y} and $\sigma = \{~ A \mapsto \lambda x.\lambda y.y ~\}$
for \elpiIn{lam x\lam y\y}.

When detailing examples we write links as equations between two
terms under a context.
The equality sign is subscripted with
kind of \elpiIn{baselink}. For example $\linkbetaM{x}{A_x}{F_x~a}$ corresponds to:
\begin{elpicode}
abs x\ val (link-beta (uva A [x]) (app[uva F [x],con "a"]))
\end{elpicode}

\todo{notation for problem compilation}


% The first three rules unify terms with same rigid heads, and
% call the unification relation on the sub-terms. If $t_1$ (resp. $t_2$) is an
% assigned variables, $t_1$ is dereferenced to $t_1'$ (resp. $t_2'$) and the
% unification is called between $t_1'$ and $t_2$ (resp. $t_1$ and $t_2'$). If both
% terms are unification variables, we test that their arguments are in the pattern
% fragment, we allocate a new variable $w$ in $\rho_1$ such that $w$ is the
% pruning of the arguments of $t_1$ and $t_2$, we assign both $t_1$ and $t_2$ to
% $w$ and return the new mapping $\rho_2$ containing all the new variable
% assignment. Finally, if only one of the two terms is an unification variable
% $v$, after having verified that $v$ does not occur in the other term $t$, we
% bind $v$ to $t$ and return the new substitution mapping.

% \old

% A key property needed in unification is being able to verify if two terms are
% equal wrt a given equational theory. This relation allow to compare terms under
% a certain substitution mapping, so that any time a variable $v$ is assigned in a
% subterm, a dereferencing of $v$ is performed. After variable dereferencing, the
% test for equality is continued on the new-created subterm.

% The base equality function over terms can be defined as follows:

% The solution we are proposing aim to overcome these unification issues by 1)
% compiling the terms $t$ and $u$ of the OL into an internal version $t'$ and $u'$
% in the ML; 2) unifying $t'$ and $u'$ at the meta level instantiating meta
% variables; 3) decompiling the meta variable into terms of the OL; 4) assigning
% the variables of the OL with the decompiled version of their corresponding meta
% variables. We claim that $t$ and $u$ unify if and only if $t'$ and $u'$ unify
% and that the substitution in the object language is the same as the one returned
% by the ML. \noteE[inline]{same or $\supseteq$ or $\subseteq$}

% In the following section we explain how we deal with term (de)compilation and
% links between unification variables.

\section[Compilation: fo\_tm to tm]{Basic simulation of \Fo{} in \Ho{}}
\label{sec:simulation}

In this section we describe a basic compilation scheme that we refine
later, in the following sections. This scheme is sufficient to implement
a \hstep that respects $\beta$-conversion for terms in \llambda.
The extension to $\eta\beta$-conversion is described in \cref{sec:eta} and
the support for terms outside \llambda in \cref{sec:beta}.

\subsection{Compilation}
\label{sec:compilation}
\noteE[inline]{manca beta normal in entrata}

The main task of the compiler is to recognize \Fo{} variables standing
for functions and map them to higher order variables in \Ho.
In order to bring back the substitution from \Ho{} to \Fo{} the compiler
builds a ``memory map'' connecting the the kind of variables using routine
\ref{clause:malloc}.

The signature of the \elpiIn{comp} predicate below allows for the generation of
links (suspended unification problems) that play no role in this section
but play a major role in \cref{sec:eta} and \cref{sec:beta}.
With respect to \cref{sec:problem-statement} the signature also allows
for updates to the substitution.

\input{code/comp_base}

\noindent
The code above uses that possibility
in order to allocate space for the variables, i.e. sets their memory
address to \elpiIn{none} (a details not worth mentioning in the
previous sections).

\input{code/comp_lam}

\noindent
In the code above the syntax \elpiIn{pi x y\..} is syntactic sugar for
iterated \elpiIn{pi} abstraction, as in \elpiIn{pi x\ pi y\..}.

The auxiliary function \elpiIn{close-links} tests if the bound variable
\elpiIn{v} really occurs in the link. If it is the case the link is wrapped into
an additional \elpiIn{abs} node binding \elpiIn{v}. In this way links generated
deep inside the compiled terms can be moved outside their original context
of binders.

\input{code/comp_close_links}

\noindent
Note that we could remove the first rule, whose solve purpose is to make
links more readable by pruning unused context entries.

\subsubsection{Compilation of terms in \maybebeta}

The following rule is inserted just before rule~\ref{rule:compapp}.

\input{code/comp_base_beta}

\noindent
Note that compiling \elpiIn{Ag} cannot create new mappings nor links, since \elpiIn{Ag}
is made of bound variables and the hypothetical rule loaded by \elpiIn{comp-lam}
(see below) grants this property. Also note that this rule generates no links.


\noindent
The only detail worth discussing is the fact that the procedure updates a
substitution, rather than just crafting one as presented in
section~\ref{sec:problem-statement}. The reason is that the algorithm folds
over a term, updating a substitution while it traverses it.\noteE[inline]{explain better}

\subsection{Execution}
\label{sec:execution}

A step in \Ho consists in unifying two terms and reconsidering all
links for progress. If any of the two tasks fail we say that the entire step
fails, and it is at this granularity that we can relate steps in the
two languages.


\input{code/hstep}

\noindent
Note tha the infix notation \elpiIn{((A ~\Ue~B) C D)} is syntactic sugar for
\elpiIn{((~\Ue\!\!\!~) A B C D)}.

Reconsidering links is a fixpoint, since the progress of a link can update the
substitution and in turn enable another link to progress.

\input{code/progress}

\noindent
In the base compilation scheme \elpiIn{progress1} is the identity
on both the links and the substitution, so the fixpoint trivially terminates.
Sections \ref{sec:eta} and \ref{sec:beta} add rules to \elpiIn{progress1}
and justify why the don't hinder termination. For brevity we omit the code
that applies the substitution \elpiIn{S1} to all terms in \linkStore.

Since compilation moves problematic terms out of the sigh of \Ue{},
that procedure can only perform a partial occur check. For example the
unification problem $X \Ue f~Y$ cannot generate a cyclic substitution alone,
but should be disallowed if a $\linkStore$ contains a link like
$\linketaM{}{Y}{\lambda z.X_z}$: We don't know yet if $Y$ will feature
a lambda in head position, but we surely know it contains $X$, hence
$f~Y$ and that fails the occur check.
The procedure \elpiIn{occur-check-links} is in charge of ensuring that
each link does not represent a (suspended) unification problem doomed
to fail because of occur check. This check is needed in order to
guarantee \cref{prop:fidelity} (simulation fidelity).

\subsection{Substitution decompilation}

Decompiling the substitution requires to first force the
progress of links and then allocating new unassigned variables
in the substitution for \Fo{} and finally decompiling all
assignments. Note that \cref{inv:linklhs} and the
occur check allows us to update the subst.


\input{code/decompile}

\noteE{What is commit-links and complete-mapping?}

\noindent
Decompiling an assignment requires to turn abstractions into
lambdas. For aesthetic purposes we also eta-contract the result
(not needed since \Fo{} equality can do that)

\input{code/decompm}

\noindent
Finally decompiling a term is trivial, now that we have an extended
mapping containing all unassigned variables \Ue may have introduced.

\input{code/decomp}

\noindent
Note that we use beta to build fapp nodes when needed (if Ag is empty
no \elpiIn{fapp} node should appear).


\begin{invariant}

  TODO: dire che il mapping è bijective
  \label{inv:map-bijective}
\end{invariant}

\subsection{Definition of \Uo and its properties}\label{sec:founif}

\input{code/unif_fo}

The code given so far applies to terms in $\beta\eta$-normal form where
unification variables in \Fo{} can occur non linearly but always with
the same number of arguments, and where their arguments are distinct names
(as per \llambda).

\begin{lemma}[Compilation round trip] If
  \elpiIn{comp S T [] M [] _ [] _} then \elpiIn{decomp M T S}
\end{lemma}
\begin{proof}[Proof sketch]
trivial, since the terms are beta normal beta just builds an app. \noteD{Reformulate?}
\end{proof}


\begin{lemma}
Properties \ref{prop:correct} and
\ref{prop:complete} hold for the implementation of \Uo above
\end{lemma}
\begin{proof}[Proof sketch]
 In this setting \Ee is as strong as
\Eo on ground terms. What we have to show is that whenever two different \Fo
terms can be made equal by a substitution $\rho$ (plus the \ref{clause:beta1}
and \ref{clause:beta2} if needed) we can find this $\rho$ by finding
a $\sigma$ via \Ue{} on the corresponding \Ho terms and by decompiling it.
If we look at the \Fo{} terms, the are two interesting cases:
\begin{itemize}
\item \elpiIn{fuva X ~\Uo~s}. In this case after \elpiIn{comp} we have
  $Y \Ue t$ that succeeds with $\sigma = \{ Y \mapsto t\}$ and
  $\sigma$ is decompiled to $\rho = \{ Y \mapsto s\}$.
\item \elpiIn{fapp[fuva X|L] ~\Uo~s}. In this case
 we have $Y_{\vec{x}} \Ue t$ that succeeds with
 $\sigma = \{ \vec{y} \vdash Y \mapsto t[\vec{x}/\vec{y}]\}$ that in turn
 is decompiled to $\rho = \{ Y \mapsto \lambda \vec{y}.s[\vec{x}/\vec{y}]\}$.
 Thanks to \ref{clause:beta1}
 $(\lambda \vec{y}.s[\vec{x}/\vec{y}])~\vec{x} \Eo s$.
\end{itemize}
Since the mapping is a bijection occur check in \Ho{} corresponds to occur
check in \Fo{}.
\end{proof}

\begin{lemma} Properties simulation (\ref{prop:simulation}) and
fidelity (\ref{prop:fidelity}) hold
\end{lemma}
\begin{proof}[Proof sketch]
Since \elpiIn{progress1} is trivial \fstep and \hstep are the same, that is
in this
context where input terms are $\beta\eta$-normal and we disregard $\eta$-equivalence
\Ue is equivalent to \Uo.
\end{proof}

\subsection{Limitations of by this basic scheme}
\label{sec:basic-comp-limitations}
The basic compilation scheme is not about to
deal wit the following problem:
\printAlll
  {{{\lambda x y.X \appsep y \appsep x, \lambda x y.x},{\lambda x. f \appsep (X \appsep x) \appsep x,Y}}}
  {{}}
  {{}}
  {{}}
% \begin{gather}
% \lambda x y.F \appsep y \appsep x = \lambda x y.x \label{eq:unif-eta1}\\
% \lambda x. f \appsep (F \appsep x) \appsep x = G \label{eq:unif-eta2}
% % \lambda x. f \appsep (F \appsep x) \appsep x = f \appsep (\lambda y.y) \label{eq:unif-eta2}
% \end{gather}

\noindent Note that here $X$ is used with different arities, moreover
in the second problem the left hand side happens to be an
eta expansion (of $f (\lambda y.y)$) only after we discover (at run time)
that $X = \lambda x\lambda y.y$ (i.e. that $X$ discards the $x$ argument).
Both problems are addressed in the next two sections.
  
% \subsection{Example}

% OK

% \begin{elpicode}
% Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%       , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr z (s z) ] % $\lambda x.g (F x) = \lambda x.g a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% \end{elpicode}

% KO

% \begin{elpicode}
%   Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%   , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr 0 1   % $A = \lambda x.x$
%            , pr 2 3 ] % $A a = a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% lam x\ app[f, app[X, x]] = Y,
%   lam x\ x) = X.
% \end{elpicode}

% \otext{Goal: $s_1 \Uo s_2$ is compiled into $t_1 \Ue t_2$}
% \otext{What is done: uvars \elpiIn{fo_uv} of OL are replaced into uvars \elpiIn{ho_uv} of the ML}
% \otext{Each \elpiIn{fo_uv} is linked to an \elpiIn{ho_uv} of the OL}
% \otext{Example needing the compiler v0 (tra l'altro lo scope è ignorato):\\ \elpiIn{lam x\ app[con"g",app[uv 0, x]] ~\Uo~lam x\ app[con"g", c"a"]}}
% \otext{Links used to instantiate vars of elpi}
% \otext{After all links, the solution in links are compacted and given to coq}
% \otext{It is not so simple, see next sections (multi-vars, eta, beta)}


% The compilation step is meant to recover the higher-order variables of the OL,
% expressed in a first order way, by replacing them with higher-order variables in
% the ML. In particular, every time a variable of the OL is encountered in the
% original term, it is replaced with a meta variable, and if the OL variable is
% applied to a list of distinct names $L$, then this list becomes the scope of the variable.
% For all the other constructors of
% \elpiIn{tm}, the same term constructor is returned and its arguments are
% recursively compiled. The predicate in charge for term compilation is:

% \elpiIn{type comp tm -> tm -> links -> links -> subst -> subst -> o}.

% \noindent
% where, we take the term of the OL, produce the term of the ML, take a list
% of link and produce a list of new links, take a substitution and return a
% new substitution.

% In particular, due to programming constraints, we need to drag the old subst and
% return a new one extended, if needed, with the new declared meta-variables.

% The following code
% %
% \begin{elpicode}
%   kind link type.
%   type link nat -> nat -> nat -> subst.
% \end{elpicode}
% %
% \noindent
% defines a link, which is a relation between to variables indexes, the first
% being the index of a OL variable and the second being the index of a ML
% variable. The third integer\noteE[inline]{integer or nat?} is the number of term in the
% scope of the two variables, or equivalently, in a typed language, their arity.

% As an example, let's study the following unification problem (a slightly
% modified version from \cref{sec:intro}):

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Uo~
%     lam x\ app [c"decision", app[uv 0, x]]
% \end{elpicode}

% \noindent
% we have the main unification problem where the nested \elpiIn{app} nodes have
% lists of different lengths making the unification to fail. The compilation of
% these terms produces a new unification problem with the following shape:

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Ue~
%     lam x\ app [c"decision", uv 1 [x]]
% \end{elpicode}

% \noindent
% The main difference is the replacement of the subterm \elpiIn{app[uv 0, x]} of
% the OL with the subterm \elpiIn{uv 0 [x]}. Variable indexes are chosen by the
% ML, that is, the index \elpiIn{0} for that unification variable of the OL term
% has not the sam meaning of the index \elpiIn{0} in the ML. There exists two
% different substitution mapping, one for the OL and one for the ML and the indexes
% of variable point to the respective substitution.

% decomp che mappa abs verso lam
% \noindent
% \otext{An other example: \\
%   \elpiIn{lam x\ app[f, app[X, x]] = Y, (lam x\ x) = X.}}

% \section{Use of multivars}

% Se il termine initziale è della forma

% \begin{elpicode}
%   app[con"xxx", (lam x\ lam y\ Y y x), (lam x\ f)]
%   =
%   app[con"xxx",X,X]
% \end{elpicode}

% allora se non uso due X diverse non ho modo di recuperare il quoziente che mi manca.

% a sto punto consideriamo liste di problemi e così da eliminare sta xxx senza
% perdità di generalità (e facciamo problemi più corti, e modellizziamo anche la
% sequenza)

\section{Handling of \maybeeta}\label{sec:eta}
$\eta$-reduction is an equivalence relation where a term of the form
$\lambda x.t \appsep x$ can be converted to $t$ any time $x$ does not occur as a
free variable in $t$. We call $t$ the $\eta$-contraction of
$\lambda x. t \appsep x$.

Following the compilation scheme of \cref{sec:compilation} the
unification problem \foUnifPb is compiled as follows:
%
\printAlll
  {{{\lambda x. X \appsep x, f}}}
  {{{\lambda x. A_x, f}}}
  {{{X,A,1}}}
  {{}}

\noindent
While $\lambda x.X \appsep x \Uo{} f$ does admit the solution
$\rho = \{~ X \mapsto f ~\}$, the corresponding problem in
\hoUnifPb does not:
\elpiIn{lam x\ uva A [x]} and
\elpiIn{con"f"} start with different, rigid, term constructors hence
\Ue{} fails.

In order to guarantee \cref{prop:simulation} we detect
lambdas that can disappear by eta contraction (\cref{sec:etadetection}) and
we modify the compiled terms by putting fresh unification variables
in their place: the problematic term is moved 
from  \hoUnifPb to \linkStore (\cref{sec:etacomp}). The compilation
of the problem \foUnifPb above is refined to: 
%
\printAlll
  {{{\lambda x.X \appsep x,f}}}
  {{{A,f}}}
  {{{X,B,1}}}
  {{{\eta,,A,\lambda x.B_x}}}

\noindent
As per \cref{inv:linklhs} the term on the left is a variable, and its
right counterpart is the
term in \maybeeta. That term has the following property:

\begin{invariant}[\linketa \rhs]
  The \rhs of any \linketa %in \linkStore 
  has the shape $\lambda x.t$
  and $t$ is not a lambda. 
  %where $t_x$ is a \maybeeta term and $x$ is free in $t$.
  \label{inv:link-eta-right}
\end{invariant}

\linketa are kept in the link store \linkStore during execution
and activated when some conditions hold on \lhs or \rhs.
Link activation is implemented by extending the \elpiIn{progress1}
predicate (defined in \cref{sec:execution}).

\subsection{Detection of \maybeeta}\label{sec:etadetection}

When compiling a term $t$ we need to determine if any
subterm $s \in \subterm{t}$ that is of the form $\lambda x. r$,
where $x$ occurs in $r$, can be a $\eta$-expansion, i.e. if
there exists a substitution $\rho$ such that $\rho (\lambda x.r) \Eo s$.
The detection of lambda abstractions that can ``disappear''
is not as trivial as it may seems, here a few examples:
%
\begin{center}
  \begin{tabular}{lll}
    %Term & Status & Evidence \\\hline
    $\lambda x. f \appsep (A \appsep x)$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.x ~\}$ \\
    $\lambda x. f \appsep (A \appsep x) \appsep x$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.a ~\}$\\
    $\lambda x. f \appsep x \appsep (A \appsep x)$ & $\not\in\maybeeta$ &\\
    $\lambda x. \lambda y. f \appsep (A \appsep x) \appsep (B \appsep y \appsep x)$ & $\in\maybeeta$ & $\rho = \{~ A \mapsto \lambda x.x,~ B \mapsto \lambda y.\lambda x.y ~\}$
  \end{tabular}
\end{center}
\vspace{4pt}

% In the examples above, the first term is a \maybeeta since $A_x$ can
% reduce to $x$ by setting $A_x = \lambda x.x$, 
% the second one is not a \maybeeta since it exists no substitution
% for $A_x$ such that $A_x$ reduces to $x$ and $x$ is not free in the subterm $f \appsep x$.
\noindent
The first two examples are easy, and show how a unification variable can expose
or erase a variable in their scope and turn the resulting term in an $\eta$-expansion or not.\\
The third example shows that when a variable occurs outside the scope of a unification
variable it cannot be erased and can hence prevent a term from being an $\eta$-expansion.\\
The last example shows the recursive nature of the check we need to implement.
The term starts with a spine of two lambdas hence the whole term
is in \maybeeta iff the inner term $\lambda y.f\appsep (A \appsep x) \appsep (B \appsep y \appsep x)$
is in \maybeeta itself. If it is, it could $\eta$-contract to
$f \appsep (A \appsep x)$ making $\lambda x.f \appsep (A \appsep x)$ a potential
$\eta$-expansion.\\
We can now define more formally how \maybeeta terms are detected together with
its auxiliary functions:

\newcommand{\reduceto}{\emph{may-contract-to}}
\begin{definition}[\reduceto]
  A $\beta$-normal term $s$ \reduceto{} a name $x$ if there exists a
  substitution $\rho$ such that $\rho s \Eo{} x$.
\end{definition}

\begin{lemma}\label{lem:reduceto}
A $\beta$-normal term $s = \lambda x_1 \ldots x_n.t$
%, where $x, x_1\ldots x_n$ can occur in $t$, 
\reduceto{} $x$ only if one of the following three conditions holds:
\begin{enumerate}
  \item $n = 0$ and $t = x$;
  \item $t$ is the application of $x$ to a list
     of terms $l$ and each $l_i$ \reduceto{} $x_i$
     (e.g. $\lambda x_1 \ldots x_n.x \appsep x_1 \ldots x_n \Eo{} x$) ;
  \item $t$ is a unification variable with scope
    $W$, and for any $v \in \{ x, x_1 \ldots x_n \}$,
    there exists a $w_i \in W$, such that $w_i$ \reduceto{} $v$
    (if $n = 0$ this is equivalent to $x \in W$).
\end{enumerate}
\end{lemma}
\begin{proof}[Proof sketch]
Since our terms are in $\beta$-normal form there is only
one rule that can play a role (namely \ref{clause:eta1}),
hence if the term $s$ is not exactly $x$ (case 1)
it can only be an $\eta$-expansion of $x$, or a unification
variable that can be assigned to $x$, or a combination of both.
If $s$ begins with a lambda, then the lambda can only disappear by $\eta$
contraction. In that case the term $t$ is under the spine of binders
$x_1\ldots x_n$, $t$ can either be $x$ applied to terms that can
\reduceto{} these variables (case 2), or a unification variable
that can be assigned to that application (case 3).
\end{proof}

% \noindent
% Note that this condition does not require the term to be in \llambda.
% \noteE[inline]{Is this relevant}

\newcommand{\occursrigid}{\emph{occurs-rigidly}\xspace}
\newcommand{\occurrigid}{\emph{occur-rigidly}\xspace}
\begin{definition}[\occursrigid]\label{def:occrigid}
  A name $x$ \occursrigid{} in a $\beta$-normal term $t$, if $\forall \rho, x \in
  \subterm{\rho t}$
\end{definition}

In other words $x$ \occursrigid in $t$ if it occurs in $t$
outside of the scope of a unification variable $X$, otherwise an instantiation
of $X$ can make $x$ disappears from $t$.
Moreover, note that $\eta$-contracting $t$ cannot make $x$ disappear, since
$x$ is not a locally bound variable inside $t$.

We can now derive the implementation for \maybeeta detection:

\newcommand{\testmaybeeta}{\emph{maybe-eta}\xspace}
\begin{definition}[\testmaybeeta]\label{def:testmaybeeta}
  Given a $\beta$-normal term
  $s = \lambda x_1 \ldots x_n.t$, \testmaybeeta{} $s$ holds if any
  of the following holds:
  \begin{enumerate}
    \item $t$ is a constant or a name applied to the arguments
      $l_1 \ldots l_m$ such that 
      $m \geq n$ and for every $i$ such that $m - n < i \leq m$
      the term  $l_i$
      \reduceto{} $x_i$, and
      no $x_i$ \occursrigid{} in $l_1 \ldots l_{m-n}$;
    \item $t$ is a
      unification variable with scope $W$ and
      for each $x_i$ there exists a $w_j \in W$ such that $w_j$
      \reduceto{} $x_i$.
  \end{enumerate}
\end{definition}
\begin{lemma}[\maybeeta detection]\label{lem:maybeeta}
  If $t$ is a $\beta$-normal term and \testmaybeeta{} $t$ holds,
  then $t \in \maybeeta$.
\end{lemma}
\begin{proof}[Proof sketch]
Follows from \cref{def:occrigid} and \cref{lem:reduceto}
\end{proof}

\noindent
Remark that the converse of \cref{lem:maybeeta} does not hold: 
there exists a term $t$ satisfying the criteria (1) of
\cref{def:testmaybeeta} that is not in $\maybeeta$, i.e.
there exists no substitution $\rho$ such that $\rho t$ is an
$\eta$-expansion. A simple counter example is
$\lambda x. f \appsep (A \appsep x) \appsep (A \appsep x)$
since $x$ does not \occurrigid{} in the first argument
of $f$,
and the second argument of $f$ \reduceto{} $x$.
In other words $A \appsep x$
may either use or discard $x$, but our analysis does not
take into account that \emph{the same
term} cannot have two contrasting behaviors.

As we will see in the rest of this section this is not a problem
since it does not break
\cref{prop:simulation} nor \cref{prop:fidelity}.
% A term in \maybeeta{} is compiled to a
% unification variable and a link (see \cref{sec:etacomp}):
% the link makes progress (see \cref{sec:etaprogress})
% in the same step in which the
% variable is instantiated, and that compensates
% for this coarse analysis.

% The implementation we propose for the \maybeeta relation is given below.

% \input{code/maybe_eta}

% Here a complex maybeeta example
% \begin{gather}
%   T = \lambda y. f \appsep A_{xy} \appsep (B \appsep a \appsep (\lambda z.y\appsep C_z)) \appsep D_x
% \end{gather}

\subsection{Compilation and decompilation}\label{sec:etacomp}

% Thanks to the \elpiIn{maybe-eta} predicate, we can detect ``$\eta$-problematic''
% terms and, consequently replace them with fresh \Ho unification variables at
% compilation time. The code below illustrate how this relation is used to for
% term compilation.

\paragraph{Compilation}
The following rule is inserted just before rule~\ref{rule:complam} from the code in
\cref{sec:compilation}.

\input{code/comp_eta}

\noindent
The rule triggers when the input term \elpiIn{flam F} is in
\maybeeta. It compiles \elpiIn{flam F} to \elpiIn{lam F1} but puts the fresh
variable \elpiIn{A} in its place. This variable sees all the names free in
\elpiIn{lam F1}. The critical part of this rule is the creation of the \linketa,
which relates the variable \elpiIn{A} with \elpiIn{lam F1}.
This link clearly validates \cref{inv:linklhs}.

\begin{corollary}
  The \rhs of any \linketa has exactly one lambda abstraction, hence
  the rule above respects \cref{inv:link-eta-right}.
  \label{cor:rhs-eta-onelamb}
\end{corollary}

\begin{proof}[Proof sketch]
  By contradiction, suppose that the rule above is triggered and that
  the \rhs of the link is $\lambda x.\lambda y.t_{xy}$.
  If $\testmaybeeta{}~\lambda y.t_{xy}$ holds the recursive call to
  \elpiIn{comp} (made by \elpiIn{comp-lam}) must have put a fresh variable
  in its place, so this case is impossible.
  Otherwise, if $\testmaybeeta{}~\lambda y.t_{xy}$ does not hold, also
  $\testmaybeeta{}~\lambda x.\lambda y.t_{xy}$ does not hold, contradicting
  the assumption that the rule triggered.
\end{proof}

\paragraph{Decompilation}
Decompilation of the remaining \linketa (i.e. the \linketa that have been
activated) is performed by iterating over them and unifying \lhs and \rhs. Note
that this unification never fails, since \lhs is a flexible term not appearing
in any other \linketa (by \cref{def:progressetadedup}).

\subsection{Progress}\label{sec:etaprogress}

\linketa are meant to delay the unification of ``problematic'' terms until
we know for sure if the term has to be $\eta$-contracted or not.

\newcommand{\progressetaleft}{\emph{progress-$\eta$-left}\xspace}
\begin{definition}[\progressetaleft]\label{def:progressetaleft}
A link \linketaM{\Gamma}{X}{T} is removed from \linkStore when
$X$ becomes rigid. Let $y\in\Gamma$, there are two cases:
\begin{enumerate}
  \item if $X = a$ or $X = y$ or $X = f \appsep a_1\ldots a_n$
    we unify the $\eta$-expansion of $X$ with $T$, that is we run
    $\lambda x.X \appsep x\Ue{} T$
    \item if $X = \lambda x.t$ we run $X \Ue{} T$.
\end{enumerate}
\end{definition}

\newcommand{\progressetaright}{\emph{progress-$\eta$-right}\xspace}
\begin{definition}[\progressetaright]\label{def:progressetaright} A link
\linketaM{\Gamma}{X}{T} is removed from \linkStore when either 1)
$\testmaybeeta~T$ does not hold (anymore) or 2) by $\eta$-contracting $T$ to
$T'$, $T'$ is a term not starting with the \elpiIn{lam} constructor. In the
first case, $X$ is unified with $T$ and in the second one, $X$ is unified with
$T'$ (under the context $\Gamma$).
\end{definition}

There is a third case in which a link is removed from \linkStore, namely
when the \lhs is assigned to a variable that is the \lhs of another
\linketa.

\newcommand{\progressetadedup}{\emph{progress-$\eta$-deduplicate}\xspace}
\begin{definition}[\progressetadedup]\label{def:progressetadedup}
  A link \linketaM{\Gamma}{X_{\vec{s}}}{T} is removed from \linkStore when
  another link \linketaM{\Delta}{X_{\vec{r}}}{T'} is in  \linkStore.
  By \cref{inv:uvaarity} the length of $\vec{s}$ and $\vec{r}$ is the same
  hence we can move the term $T'$ from $\Delta$ to $\Gamma$ by renaming its
  bound variables, i.e. $T'' = T'[\vec{r}/\vec{s}]$.
  We then run $T \Ue{} T''$ (under the context $\Gamma$).
\end{definition}

% \noteD[inline]{Below the proof of \cref{prop:nf}, ho usato 3 lemmi ausiliari,
% forse si può compattare in una prova più piccola?}
\begin{lemma}
  Given a \linketa $l$, the unification done by \progressetaleft is between
  terms in $\wellb$  
  \label{lemma:unif-eta-1}
\end{lemma}

\begin{proof}[Proof sketch]
  Let $\sigma$ be the substitution, which is  $\wellb(\sigma)$ (by
  \cref{prop:nf}). $\lhs \in \sigma$, therefore $\wellb(\lhs)$. By
  \cref{def:progressetaleft}, if 1) \lhs is a name, a constant of an
  application, then, $\lambda x.\lhs \appsep x$ is unified with \rhs. By
  \cref{inv:link-eta-right}, $\rhs = \lambda x. t$, therefore $\wellb(t)$.
  Otherwise, 2) \lhs has \elpiIn{lam} as functor, \rhs should not be an
  $\eta$-expansion, so, $\wellb(\rhs)$. In both cases, unification is
  performed between terms in \wellb.
\end{proof}

\begin{lemma}
  Given a \linketa $l$, the unification done by \progressetaright is between
  terms in \wellb.
  \label{lemma:unif-eta-2}
\end{lemma}

\begin{proof}[Proof sketch]
  \lhs is variable, and, by \cref{def:progressetaright}, \rhs is either no more
  a \maybeeta, i.e. \rhs is not a $\eta$-expansion and, so, $\wellb(\rhs)$.
  Otherwise, \rhs can reduce to a term which cannot be a $\eta$-expansion, and,
  so, $\wellb(\rhs)$. In both cases, unification is done between terms in
  \wellb.
\end{proof}

\begin{lemma}
  Given a \linketa $l$, the unification done by \progressetadedup is between
  terms in \wellb.
  \label{lemma:unif-eta-3}
\end{lemma}

\begin{proof}
  The unification is done between the \rhs of two
  \linketa. Both \rhs has the shape $\lambda x.t$, with $\wellb(t)$, therefore,
  the unification is done between well-behaved terms.
\end{proof}

\begin{lemma}
  The introduction of \linketa guarantees \fullref{prop:nf}
  \label{lemma:unif-wellb}
\end{lemma}

\begin{proof}[Proof sketch]
  By \cref{lemma:unif-eta-1,lemma:unif-eta-2,lemma:unif-eta-3}, every
  unification performed by the activation of a \linketa is done between
  terms in \wellb, therefore, the substitution remains \wellb.
  \noteD[inline]{Bisogna aggiungere un lemma nella \cref{sec:nutshell} che dice che
  unificare due termini in \wellb, in una $\sigma$, tale che $\wellb(\sigma)$, 
  non invalida \wellb}
\end{proof}

\begin{lemma}
  \elpiIn{progress} terminates.
  \label{lemma:prog-eta-terminates}
\end{lemma}

\begin{proof}[Proof sketch]
  Rules \cref{def:progressetaleft,def:progressetaright} and
  \cref{def:progressetadedup} remove one link from \linkStore, hence they
  cannot be applied indefinitely.
  Moreover each rule only relies on terminating operations such as \Ue,
  $\eta$-contraction, $\eta$-expansion, relocation (a recursive copy of a
  finite term).
  % The addition of rules for \elpiIn{progres1} complicates the function
  % \elpiIn{progress}. We can note, however, that they do not prevent the
  % termination of \elpiIn{progress}. 1) If a link is activated it is removed from
  % \linkStore and the recursive call to \elpiIn{progress} will have a smaller
  % list of links to recurse on. Moreover, link activation only runs terminating
  % instructions (such as unification). 2) If a link is deduplicated, the
  % termination of \elpiIn{progress} is still guaranteed since again we reduce
  % \linkStore and the instructions run by link deduplications are all
  % terminating. 3) If a link is neither activated nor deduplicated, i.e. it
  % remains suspended, then \linkStore remains unchanged like the substitution;
  % therefore, \elpiIn{if (L = L1, S1 = S2)} succeeds and \elpiIn{progress}
  % terminates.
\end{proof}

\begin{lemma}[Fidelity with \linketa]
  The introduction 
  of \linketa guarantees \fullref{prop:fidelity} 
  \label{lemma:fidelity-maybeeta}
\end{lemma}

\begin{proof}[Proof sketch]
  \progressetaleft and \progressetadedup activate a \linketa when, in the
  original unification problem, a \maybeeta term is unified with respectively a
  well-behaved term or another \maybeeta term. In both cases, the links trigger
  a unification which succeeds iff the same unification in \Fo{} succeeds,
  guaranteeing \cref{prop:fidelity}. \progressetaright never fails, in fact,
  this progression refines a variable to a rigid term and plays no role in 
  \cref{prop:fidelity}.
  % If 1) a \linketa is activated by \progressetaleft, then unification is done
  % between a \maybeeta term $t_1$ and a term $t_2$ (with $\wellb(t_2)$). This
  % activation performs a unification which succeeds iff the original problem in
  % \Fo{} succeeds. If 2) a \linketa is activated by \progressetadedup, then the
  % unification is done between two \maybeeta terms, and again this unification
  % succeeds iff it succeeds in \Fo{}. Finally, if 3) a \linketa is activated by
  % \progressetaright, the unification, done between a variable and a term,
  % always succeeds, this is what we expect to guarantee fidelity, since we
  % are essentially removing a hole added by the compilation in the place of a
  % \maybeeta subterm. In all the cases fidelity is respected.
\end{proof}

\paragraph{Example of \progressetaleft}

The example at the beginning of \cref{sec:eta}, once
$\sigma = \{~ A \mapsto f ~\}$, triggers \progressetaleft since the link
becomes \linketaM{}{f}{\lambda x.B_{x}} and the \lhs is a constant.
In turn the rule runs $\lambda x.f \appsep x \Ue{} \lambda x.B_{x}$,
resulting in $\sigma = \{~ A \mapsto f ~;~ B_{x} \mapsto f ~\}$.
Decompilation the generates $\rho = \{~ X \mapsto f ~\}$, since
$X$ is mapped to $B$ and
$f$ is the $\eta$-contracted version of $\lambda x.f \appsep x$.

\paragraph{Example of \progressetadedup}

A very basic example of \linketa deduplication, is given below:
% make test ONLY=7002 TEX=tex
\printAlll
  {{{\lambda x.(X\appsep x),\lambda x.(Y\appsep x)}}}
  {{{A,C}}}
  {{{X,B,1},
    {Y,D,1}}}
  {{{\eta,,A,\lambda x.B_{x}},
    {\eta,,C,\lambda x.D_{x}}}}

\noindent
The result of $A \Ue{} C$ is that the two \linketa share the same \lhs.
By unifying the two \rhs we get
$\sigma = \{ A~ \mapsto C, B \mapsto D ~\}$.
In turn, given the map \mapStore, this second assignment is decompiled to
$\rho = \{~ X \mapsto Y ~\}$ as expected.

We delay at the end of  next section an example of \linketa progression due to
\progressetaright


\section{Enforcing Invariant~\ref{inv:uvaarity}}
\label{sec:invariant1}

We report here the problem given in \cref{sec:basic-comp-limitations} where
$X$ is used with two different arities and the output of the compilation does
not respect \cref{inv:map-bijective} (merging the two mappings
for $s$ would break \cref{inv:uvaarity}).
In this section we explain how to replace the duplicate mapping with some
\linketa{} in order to restore the invariants.
% make test ONLY=7001 TEX=tex
\printAlll
  {{{\lambda x.\lambda y.(X\appsep y\appsep x),\lambda x.\lambda y.x},
    {\lambda x.(f\appsep (X\appsep x)\appsep x),Y}}}
  {{{A,\lambda x.\lambda y.x},
    {D,F}}}
  {{{X,E,1},
    {Y,F,0},
    {X,C,2}}}
  {{{\eta,,D,\lambda x.(f\appsep E_{x}\appsep x)},
    {\eta,,A,\lambda x.B_{x}},
    {\eta,x,B_{x},\lambda y.C_{y x}}}}

We see that the \elpiIn{maybe-eta} as identified $\lambda xy.X \appsep y \appsep
x$ and $\lambda x.f\appsep (X \appsep x) \appsep x$ and the compiler has
replaced them with $A$ and $D$ respectively.
% $A$ is linked with $\lambda x.B_x$, $B$
% has arity $1$ and is $\eta$-linked with $\lambda y.C\appsep y \appsep x$ and $D$
% is linked to the term $\lambda x.f \appsep E_{x}~x$. 
However, the mapping \mapStore breaks \cref{inv:map-bijective}: the \Fo{}
variable $X$ is mapped to two different \Ho variables. To address this problem
we adjust the compiler's output with a \elpiIn{map-deduplication} procedure.

\newcommand{\alignarity}{\emph{align-arity}}
\begin{definition}[\alignarity] Given two mappings
  $m_1 : X \mapsto A^m$ and
  $m_2 : X \mapsto C^n$ where $m < n$ and $d = n - m$,
  $\alignarity{}~ m_1 ~ m_2$ generates the following $d$ links, one
  for each $i$ such that $0 \leq i < d$,
\[%
  \linketaM{x_0 \ldots x_{m+i}}
           {B^i_{x_0 \ldots x_{m+i}}}
           {\lambda x_{m+i+1}.B^{i+1}_{x_0 \ldots x_{m+i+1}}}
\]%
where $B^i$ is a fresh variable of arity $m+i$, and $B^0 = A$ as well as $B^d = C$.
\end{definition}

The intuition is that we $\eta$-expand the occurrence of the variable
with lower arity to match the higher arity. Since each \linketa can
add exactly one lambda, we need as many links as the difference between the
two arities.

\newcommand{\mapdeduplication}{\emph{map-deduplication}}

\begin{definition}[\mapdeduplication]
  Forall mappings $m_1, m_2\in \mapStore$ such that 
  $m_1 : X \mapsto A^m$ and
  $m_2 : X \mapsto C^n$ and $m < n$
  we remove $m_1$ from \mapStore and
  add to \linkStore the result of $\alignarity{}~m_1~m_2$.
\end{definition}

If we look back the example give at the beginning of this section, we can
deduplicate $\mapping{X}{E}{1}, \mapping{X}{C}{2}$ by removing the first mapping
and adding the auxiliary \linketa: \linketaM{x}{E_{x}}{\lambda y.C_{x y}}.
After deduplication the compiler output is as follows:
% make test ONLY=7001 TEX=tex
\printAlll
  {{{\lambda x.\lambda y.(X\appsep y\appsep x),\lambda x.\lambda y.x},
    {\lambda x.(f\appsep (X\appsep x)\appsep x),Y}}}
  {{{A,\lambda x.\lambda y.x},
    {D,F}}}
  {{{Y,F,0},
    {X,C,2}}}
  {{{\eta,x,E_{x},\lambda y.C_{x y}},
    {\eta,,D,\lambda x.(f\appsep E_{x}\appsep x)},
    {\eta,,A,\lambda x.B_{x}},
    {\eta,x,B_{x},\lambda y.C_{y x}}}}

In this example, $\hoUnifPb_1$ assigns $A$ which triggers $\linkStore_3$ and
then $\linkStore_4$ by \cref{def:progressetaleft}. $C_{yx}$ is therefore
assigned to $x$ (the second variable of its scope). We can finally see the
\progressetaright of $\linkStore_1$: its \rhs is now $\lambda y.y$ ($C_{xy}$
gives $y$). Since it is no more in \maybeeta, $\lambda y.y$ is unified with
$E_x$. Moreover, $\linkStore_2$ is also triggered due to
\cref{def:progressetaright}: $\lambda x.(f \appsep (\lambda y.y) \appsep x)$ is
$\eta$-reducible to $f \appsep (\lambda y.y)$ which is a term not starting with
the \elpiIn{lam} constructor.

% After unification of the two terms, $X$ is assigned to $\lambda x.\lambda y.x$.
% This assignment makes $l_2$ to progress since the \lhs is materialized and by
% unification, between $X$ and $\lambda x.Y_{x}$, $Y_x$ is instantiate to $\lambda
% y.x$. Once $Y_x$ is instantiated, $l_1$ can progress, and set $H_{xy}$ to $x$.
% After all these progresses, $l_1$ and $l_2$ are remove from \linkStore and the
% \elpiIn{progress} fixpoint terminates. Next, the second unification problem is
% run, and $Z$ is set to $f\appsep(\lambda x.x)$. This unification wakes up $l_3$
% and since $Z$ starts with the \elpiIn{app} node, the $\eta$-expanded version of
% $Z$ is unified with $\lambda x.f \appsep G_{x}~x$ and $G_x$ is set to $x$.
% As last step, the last link is progressed and the final \Ho substitution is
% $\{X _{} \mapsto \lambda x.\lambda y.x, Y _{x} \mapsto \lambda y.x, 
% G _{yx} \mapsto y, Z _{} \mapsto f~\lambda x.x, 
% H _{x} \mapsto \lambda y.y\}$.
% The decompilation phase is only charged, in this example to solve the mappings,
% since no suspended links remain. The only mapping in the list is
% \mapping{F}{H}{2}, which will assign the $F$ variable in \Fo{} to $\lambda xy.y$

% \noteE[inline]{dire che preserviamo l'invariante che tutte le variable sono fully-applied
% }
\section{Handling of \notllambda}\label{sec:beta}

% On
% the other hand, we also point out that the \maybeeta detection spot out
% potential $\eta$-expansion for terms that are not in \llambda. For example,
% $\lambda x.F \appsep G_x$ is considered as \maybeeta, since we have the
% application of term whose argument can reduce to $x$.

% \noteE[inline]{IIRC, second order unification, where variables can stand for functions, is semi-decidable, indeed Huet's algorith enumerates all solutions. Third order, functions that take functions, is undecidable, proved by Dowek. IMO here the problem is that there is no unique solution, (semi)decidability is a secondary point. This paragraph needs fixing.}
% \noteD[inline]{I've rewritten it, it is clearer?}
In general, unification between \notllambda terms admits more then one
solution and committing one of them in the substitution does not guarantee
\cref{prop:complete}. For instance, $X \appsep a \Uo a$ 
admits two different substitutions: $\rho_1 = \{X \mapsto \lambda x.x\}$
and $\rho_2 = \{X \mapsto \lambda \_.a\}$. Prefer one over the other may break
future unifications.

It is the case, however, that, given a list of unification problems, $\foUnifPb_1\dots
\foUnifPb_n$ with $\foUnifPb_n$ in \notllambda, the resolution of
$\bigwedge_{i=0}^{n-1}\foUnifPb_i$ gives a partial substitution $\rho$, such
that $\rho\foUnifPb_n$ falls again in \llambda.
%
% make test ONLY=7003 TEX=TEX + deactivate beta tex
\printAlll
  {{{X,\lambda x.Y},
    {(X\appsep a),a}}}
  {{{A,\lambda x.B},
    {(A\appsep a),a}}}
  {{{Y,B,0},
    {X,A,0}}}
  {{}}

In the example above, we see that $\foUnifPb_1$ instantiates $X$ so that
$\foUnifPb_2$ can be solved in \llambda.
% \noteE[inline]{it is even a ground term, there is no unification left to perform actually}
% \noteD[inline]{i don't understand the note}
On the other hand, we see that, 
\Ue can't solve the compiled problems \hoUnifPb. In
fact, the resolution of $\hoUnifPb_1$ gives the substitution $\sigma = \{ A
\mapsto \lambda x. B\}$, but the dereferencing of $\hoUnifPb_2$ gives the 
non-unifiable problem $(\lambda x. B) \appsep a \nUe a$.

To address
this unification problem, term compilation should capture the
terms in \notllambda and replace them with fresh variables.
This replacement should produce links that we call \linkbeta.

\linkbeta guarantees \cref{inv:linklhs} and the term on the \rhs has the
following property:

\newcommand{\rhsBetaHead}{\ensuremath{X_{s_1\dots s_n}}}
\newcommand{\rhsBeta}{\ensuremath{\rhsBetaHead\appsep t_1\dots t_m}\xspace}
% \noteE[inline]{Io direi $X_{s_1\ldots s_n}\appsep l_1\ldots l_m$
% ... where S = [s1 .. sn] e L = [l1 .. lm]}

\begin{invariant}[\linkbeta \rhs]
  The \rhs of any \linkbeta has the shape \rhsBeta such that $X$ is a
  unification variable with scope $s_1\dots s_n$ and $t_1\dots t_m$ is a list of
  terms. This is equivalent to \\\elpiIn{app[uva X S | L]}, where \elpiIn{S}~$=
  s_1\dots s_n$ and \elpiIn{L}~$=t_1\dots t_m$.
  \label{inv:beta-rhs}
\end{invariant}

% \linkbeta are put in \linkStore and activated when \rhs falls in \llambda. 
% \noteE[inline]{un po' ridondante con 8.2, non so se serva}

% This property can be relaxed, to accept approximations: a dedicated
% section is given in a future section
\begin{lemma}[\linkbeta with rigid \lhs]
  If the \lhs of a \linkbeta is instantiated to a rigid term and its \rhs
  counterpart is still in \notllambda,
  the original unification problem is not in \llambda
  % \noteE[inline]{non capisco cosa vuoi dire con "the current...". Data la prova sotto vuoi dire che il problem originale sarebbe stato fuori... e quindi falliamo}
  %\noteE[inline]{Is it clearer?}
  and the unification fails.
  \label{lemma:keep-fidelity}
\end{lemma}

\begin{proof}[Proof sketch]
  Given $X \appsep t_1\dots t_n \Ue t$ where $t$ is a rigid term and
  $t_1\dots t_n$ is not in \llambda. By construction, $X \appsep t_1\dots t_n$
  is replaced with a variable $Y$, and the \linkbeta \linkbetaM{\Gamma}{Y}{X
  \appsep t_1\dots t_n} is created. If $Y$ is instantiated to the rigid term $t$,
  and \rhs is still in \notllambda, then the original \Fo{} unification problem
  is between two terms in \notllambda. Unification fails.
\end{proof}

% From \cref{lemma:keep-fidelity}, we can deduce the following corollary

% \begin{corollary}
%   Given a \linkbeta \linkbetaM{\Gamma}{X}{T}, if it exists a second link
%   $l\in\linkStore$, then unification fails.   
% \end{corollary}

\subsection{Compilation and decompilation}

Detection of \notllambda is quite simple to implement in the compiler, since it
is sufficient to detect applications with flexible head and argument that
are not in \llambda. The following rule for \notllambda compilation is inserted 
just before rule~\ref{rule:compapp}.


\input{code/comp_beta}

The list \elpiIn{Ag} is split into the list \elpiIn{Pf} and \elpiIn{Extra} such
that \elpiIn{append Pf Extra Ag} and \elpiIn{Pf} is the largest prefix of
\elpiIn{Ag} such that \elpiIn{Pf} is in \llambda. The \rhs of the \linkbeta is
the application of a fresh variable \elpiIn{C} having in scope all the free
variables appearing in the compiled version of \elpiIn{Pf} and \elpiIn{Extra}. The
variable \elpiIn{B}, returned has the compiled term, is a fresh variable having in
scope all the free variables occurring in \elpiIn{Pf1} and \elpiIn{Extra1}

% In the following, we pose $X_{s_1\dots s_n}$ to represent a variable $X$ with
% the list of distinct names $s_1\dots s_n$ as scope. Moreover, $X_{s_1\dots
% s_n}\appsep t_1\dots t_m$ is the application of that variable to the list of
% terms $t_1\dots t_m$. Note that \rhsBeta is equivalent to \elpiIn{app[uva N S |
% T]}.

\begin{invariant}
  The \rhs of a \linkbeta has the shape \rhsBeta.
\end{invariant}

\begin{corollary}
  Let \rhsBeta be the \rhs of a \linkbeta, then $m > 0$.
\end{corollary}

\begin{proof}[Proof sketch]
  Assume we have a \linkbeta, by contradiction, if $m = 0$, then the original
  \Fo{} term has the shape \elpiIn{fapp[fuva M | Ag]} where \elpiIn{Ag} is a
  list of distinct names (i.e. the list \elpiIn{Extra} is empty). This case is
  however captured by rule~\ref{rule:complam} (from \cref{sec:compilation}) and
  no \linkbeta is produced which contradicts our initial assumption.
\end{proof}

\begin{corollary}
  Let \rhsBeta be the \rhs of a \linkbeta, then $t_1$ either appears in $s_1\dots s_n$ or it is 
  not a name.
\end{corollary}

\begin{proof}[Proof sketch]
  By construction, the lists $s_1\dots s_n$ and $t_1\dots t_m$ are built by splitting
  the list \elpiIn{Ag} from the original term \elpiIn{fapp [fuva A|Ag]}.
  $s_1\dots s_n$ is the longest prefix of the compiled terms in \elpiIn{Ag} which is
  in \llambda. Therefore, by definition of \llambda, $t_1$ must appear  
  in $s_1\dots s_n$, otherwise $s_1\dots s_n$ is not the longest prefix in
  \llambda, or it is a term with a constructor of \elpiIn{tm} as functor.  
\end{proof}

\noteE[inline]{Dire che maybe eta fa il detect anche su 
termini che non sono il llambda, oppure dirlo in section of maybeeta + dare un
esempio?}

\paragraph{Decompilation}
During \elpiIn{progress}, as claimed in \cref{inv:beta-rhs}, the decompilation
can only have \linkbeta with not instantiated \lhs. In this case, \lhs is
unified with \rhs.
\noteD[inline]{not really sure of this, we can have $F\appsep a = \lambda x.G x$.
In this case when do we fail: for sure in decompile. But to respect fidelity,
we should fail immediately: we have a \linkbeta and a \linketa with same \lhs}

\subsection{Progress}

\newcommand{\progBetaLL}{\emph{progress-beta-\llambda}\xspace}
\newcommand{\progBetaRH}{\emph{progress-beta-rigid-head}\xspace}
\newcommand{\progBetaDedup}{\emph{progress-beta-dedup}\xspace}

The activation of a \linkbeta is performed when its \rhs falls under \llambda
under a given substitution.

\begin{definition}[\progBetaLL]
  Given a substitution $\sigma$ and a \linkbeta \linkbetaM{\Gamma}{T}{\rhsBeta}
  such that $\sigma t_1$ is a name, say $t$, and $t\notin s_1\dots s_n$. If $m =
  0$, then the \linkbeta is removed and \lhs is unified with \rhsBetaHead.
  If $m > 0$, then the \linkbeta is replaced by a refined version
  $\linkbetaM{\Gamma}{T}{Y_{s_1\dots s_n,t}\appsep t_2\dots t_m}$ with reduced
  list of arguments and $Y$ being a fresh variable. Moreover, the new link
  \linketaM{\Gamma}{X_{s_1\dots s_n}}{\lambda x.Y_{s_1\dots s_n,x}} is added to 
  \linkStore.

  % A link \linkbetaM{\Gamma}{T}{\rhsBeta} is removed from \linkStore, if given
  % the substitution $\sigma$, $\sigma t_1$ is a name, say $t$, such that, $t
  % \notin s_1\dots s_n$. In this case, let $Y$ a fresh variable, then
  % \linketaM{\Gamma}{X_{s_1\dots s_n}}{\lambda x.Y_{s_1\dots s_n,x}} is added to
  % \linkStore, and 1) if $m = 1$ then $Y_{s_1\dots s_n, t}$ is unified with $T$,
  % 2) otherwise, the refined \linkbeta, \linkbetaM{\Gamma}{T}{M_{s_1\dots
  % s_n,t}\appsep t_2\dots t_m}, is added to \linkStore.
  \label{def:progBetaLL}
  % % \noteE[inline]{non è chiaro. la sostituzione immagino sia la corrente, non se ne esiste una. Poi non è chiaro se otherwise si riferische a in this case. Usa un enumerate}
  % %\noteE[inline]{Is it clearer?}
  % \noteE[inline]{l1 or t1? Forse è più chiaro dire che il ilnk beta viene raffinato con link beta cone meno argomenti, Se poi il numero di argomenti extra è 0 il tutto è in llambda e quindi viene buttato via. In questo modo la terminazione è ancora più chiara perchè si vede già che prima decresce la lista di argomenti e poi il numero di beta}
  \noteD{L'ho riformulato}
\end{definition}

\begin{definition}[\progBetaRH]
  A link \linkbetaM{\Gamma}{X}{\rhsBeta} is removed from
  \linkStore if \rhsBetaHead is instantiated to a term $t$ and the
  $\beta$-reduced term $t'$ obtained from the application of $t$ to
  $l_1\dots l_m$ is in \llambda. Moreover, $X$ is unified to $t$.
  \label{def:progBetaRH}
\end{definition}

\noteD{added the def below to respect fidelity}
% Example of this `X a = Y a'
\begin{definition}[\progBetaDedup]
  Given a \linkbeta $l_1$ and second link $l_2 \in\linkStore$, such that they
  share the same \lhs. In this case, the two \rhs are unified and a $l_2$ is
  removed from \linkStore.
  \label{def:progBetaDedup}
\end{definition}

\begin{lemma}
  \elpiIn{progress} terminates
\end{lemma}

\begin{proof}[Proof sketch]
  Let $l$ a \linkbeta in the store \linkStore. If $l$ is activated by
  \progBetaRH, then it disappears from \linkStore and \elpiIn{progress}
  terminates. Otherwise, the \rhs of $l$ is made by a variable applied to $m$
  arguments. At each activation of \progBetaLL, $l$ is replaced by a new
  \linkbeta $l^1$ having $m-1$ arguments. At the $m^{th}$ iteration, the
  \linkbeta $l^m$ has no more arguments and is removed from \linkStore.
  Note that at the $m^{th}$ iteration, $m$ new \linketa have been added to
  \linkStore, however, by \cref{lemma:prog-eta-terminates}, the algorithm
  terminates. Finally \progBetaDedup also guarantees termination since it 
  makes a unification $\mathbb{U}$ and if $\mathbb{U}$ fails, then 
  \elpiIn{progress} terminates and if $\mathbb{U}$ succeeds, 
  the recursive calls to \elpiIn{progress} have a specialized \linkbeta\dots  

  % \Cref{def:progBetaRH} makes \elpiIn{progress} terminates, since it makes a
  % \linkbeta disappear from \linkStore. On the other hand, \cref{def:progBetaLL},
  % creates each time a new \linketa and replace the old \linkbeta with a new one.
  % This progression can however triggered at most $m$ times, since each new
  % \linkbeta as a smaller list of applied variables. At the $m^{th}$ progression,
  % the \linkbeta is removed from \linkStore which is now filled by $m$ new
  % \linketa. By \cref{lemma:prog-eta-terminates}, we know that \elpiIn{progress}
  % terminates if \linkStore is made by only \linketa and therefore
  % \elpiIn{progress} still terminates.
  %\noteE[inline]{is it ok?}
  \noteE[inline]{funziona. per essere più precisi io parlerei di ordine lessicografico (tipico ordine ben fondato usato per dimostrare terminazione). Nl nostro caso è la tripla (argomenti extra dei beta, numero di beta, numero di eta).}
  \noteD{da finire}
\end{proof}

\begin{corollary}
  Given a \linkbeta, the variables occurring in its \rhs are in \llambda.
  % \noteE[inline]{vuoi dire: le variabili che occorrono nel rhs sono in...?}
  \noteD[inline]{is it clearer?}
\end{corollary}

\begin{proof}[Proof sketch]
  By construction, the \rhs of \linkbeta has the shape \rhsBeta, $s_1\dots s_n$
  is in \llambda and all the terms $t_1\dots t_n$ are in \llambda, too. If a
  \linkbeta is triggered by \progBetaRH, then, by \cref{def:progBetaRH}, that
  link is removed by \linkStore, and the property is satisfied. If the \linketa
  is activated by \progBetaLL, then, by \cref{def:progBetaLL}, the new \linkbeta
  as a variable as a scope which is still in \llambda. 
\end{proof}

\begin{lemma}[Fidelity with \linkbeta]
  The introduction of \linkbeta guarantees \cref{prop:fidelity} 
\end{lemma}

\begin{proof}[Proof sketch]
  Let \hoUnifPb a unification problem and $\sigma$ a substitution
  such that $\hoUnifPb \in \notllambda$. 
  If $\sigma\hoUnifPb$ is in \llambda, then by
  \cref{def:progBetaLL,def:progBetaRH}, the \linkbeta associated to the subterm of
  \hoUnifPb have been solved and removed. The
  unification is done between terms in \llambda and by \cref{lemma:fidelity-maybeeta}
  fidelity is guaranteed. If $\sigma\hoUnifPb$ is in \notllambda,
  then, by \cref{lemma:keep-fidelity}, the unification fails, as per the
  corresponding unification in \Fo{}.
\end{proof}

\paragraph{Example of \progBetaLL}
Consider the \linkbeta below:

% make test ONLY=7004 TEX=tex
\printAlll
  {{{X,\lambda x.x},
    {\lambda x.(Y\appsep (X\appsep x)),f}}}
  {{{A,\lambda x.x},
    {B,f}}}
  {{{Y,D,0},
    {X,A,0}}}
  {{{\eta,,A,\lambda x.E_{x}},
    {\eta,,B,\lambda x.C_{x}},
    {\beta,x,C_{x},(D\appsep E_{x})}}}

\noindent
Initially the \linkbeta \rhs is a variable $D$ applied to the $E_x$.
The first unification problem results in $\sigma =
\{A \mapsto \lambda x.x\}$. In turn this instantiation
triggers $\linkStore_1$ by \progressetaleft 
and $E_x$ is assigned to $x$.
Under this substitution the \linkbeta becomes
\linkbetaM{x}{C_x}{(D \appsep x)}, and by \progBetaLL
it is replaced with the link:
\linketaM{}{E}{\lambda x.D_x}, while $C_x$ is unified with $D_x$. The second unification
problem assigns $f$ to $B$, that in turn activates
the second \linketa ($f$ is assigned to $C$), and then all the remaining links
are solved. The final \Ho substitution is $\sigma = \{A _{} \mapsto \lambda x.x, 
B _{} \mapsto f, C _{x} \mapsto (f\appsep x), 
D _{} \mapsto f, E _{x} \mapsto x, F _{x} \mapsto C_{x} \}$ and is decompiled into $\rho = \{X \mapsto \lambda x.x,
Y \mapsto f\}$.

\paragraph{Example of \progBetaRH}
We can take the example provided in \cref{sec:beta}. The problem is compiled
into:
%
% make test ONLY=7003 TEX=tex
\printAlll
  {{{X,\lambda x.Y},
    {(X\appsep a),a}}}
  {{{A,\lambda x.B},
    {C,a}}}
  {{{Y,B,0},
    {X,A,0}}}
  {{{\beta,,C,(A\appsep a)}}}

The first unification problems is solved by the substitution $\sigma = \{A
\mapsto \lambda x.B\}$. The \linkbeta becomes
\linkbetaM{}{C}{((\lambda x.B) \appsep a)} whose \rhs can be $\beta$-reduced to
$B$. $B$ is in \llambda and is unified with $C$. The resolution of the second
unification problem
gives the final substitution $\sigma = \{A \mapsto \lambda x.B, B \mapsto C, C
\mapsto a\}$ which is decompiled into $\rho = \{X \mapsto \lambda x.a, Y \mapsto
a\}$.
 
\subsection{Relaxing lemma \nameref{lemma:keep-fidelity}}

\newcommand{\progBetaNoLLWait}{\emph{progress-beta-\notllambda}}

% from https://www.cs.mcgill.ca/~bpientka/papers/unif_miller60.pdf
Working with terms in \llambda is sometime too restrictive. There exists systems
such as $\lambda$Prolog~\cite{lamProlog}, Abella~\cite{gacek2008abella}, which 
delay the resolution of \notllambda unification problems if the substitution
is not able to put them in \llambda.
%
% make test ONLY=7005 TEX=tex
\printAlll
  {{{(X\appsep a),a},
    {X,\lambda x.Y}}}
  {{}}
  {{}}
  {{}}

In the example above, $\foUnifPb_1$ is in \notllambda and the object language
cannot solve it, and, by \cref{prop:fidelity}, the meta language neither.
However, we can be more permissive, and relax \cref{lemma:keep-fidelity}. This
modification is quite simple to manage: we are introducing a new \notllambda
progress rule, say \progBetaNoLLWait, by which, if \lhs is rigid and \rhs is
flexible, the considered \linkbeta is kept in the store and no progression is
done\footnote{This new rule trivially guarantees the termination of progress}.
\progBetaNoLLWait makes \elpiIn{occur-check-links} partial, since the check is
possible only on links with a variable on the \lhs. This means that we can have
two links \linkbetaM{}{X}{Y\appsep a} and \linkbetaM{}{f\appsep X}{Y\appsep a}
where the occur check does not throw an error. Note however, that the
decompilation of the two links will force the unification of $X$ to $Y\appsep a$
and then the unification of $f\appsep (Y \appsep a)$ to $Y\appsep a$, which
fails by the occur check of \Ue.

A second strategy to deal with problem that are in \notllambda is to make some
approximation. This is the case for example of the unification algorithm of Coq
used in its type class solver~\cite{sozeau08}. The approximation consists in
forcing a choice (among the others) when the unification problem is in
\notllambda. For instance, in $X \appsep a \appsep b = Y \appsep b$, the last
argument of the two terms is the same, therefore $Y$ is assigned to $X a$. Note
that this is of course an approximation, since $\sigma = \{X = \lambda x.Y, Y =
\_\}$ is another valid substitution for the original problem. This approximation
can be easily introduced in our unification procedure, by adding new custom 
\linkbeta progress rules.

% \noteD{Paragraph for decompile in case of \maybebeta}
Decompilation of \linkbeta is possible by extending \elpiIn{commit-link} with
new heuristics.


\section{Actual implementation in Elpi}\label{sec:implementation}

In this paper we show a minimized example. The full code is there.
But we also have to code things in Coq-Elpi.

The main difference between the presentation in the previous sections and
the actual implementation for Coq is that the main loop \hrun is replaced by
the one of Prolog that chains calls to the unification procedure. In order
implement the store of links we resort to Elpi's CLP engine and
use constraints (suspended goals) to represent links, and constraint
handling rules to implement progress operations involving more than one link.

\todo{finish}
about the progress of 1 link:

\begin{elpicode}
link-eta L R :- suspend-condition L R Holes, !,
  declare_constraint (link-eta L R) Holes.
link-eta L R :-
  progress. % e.g. L = R.
\end{elpicode}

about the progress of 2 links:

\begin{elpicode}
constraint link-eta {
  rule (N1 ~$\triangleright$~ G1 ?- link-eta (uvar X LX1) T1) % match
    /  (N2 ~$\triangleright$~ G2 ?- link-eta (uvar X LX2) T2) % remove
    |  (relocate LX1 LX2 T2 T2')             % condition
   <=> (N1 ~$\triangleright$~ G1 ?- T1 = T2').                % new goal
}
\end{elpicode}

Remark how the invariant about uvar arity makes this easy, since LX1 and LX2
have the same length. Also note that N1 only contains the names of the first
link (while relocate runs in the disjoint union) and Elpi ensures that
T2' can live in N1.


\section{Other encodings and related work}\label{sec:encodings}

\noindent
One could ignore the similarity between \Uo{} and \Ue{} and ``just''
describe the object language unification procedure in the meta language by
crafting a \elpiIn{unif} routine and using it as follows in
rule \ref{clause:r3}:

\begin{elpicode}
decision X :- unif X (all A x\ app [P, x]), finite A,
  pi x\ decision (app [P, x]).
\end{elpicode}

\noindent
This choice would underuse the logic programming engine provided by
the meta language since, by removing any datum from the head of rules,
indexing degenerates. Moreover the unification procedure \elpiIn{unif}
programmed in the meta language is likely to be an order of magnitude
slower than one that is built-in.

% Paper \cite{10.1145/2966268.2966272} introduces semi-shallow.
Another possibility is to avoid having the application and abstraction nodes
in the syntax tree, and use the ones of meta language, as in the following:

\begin{elpicode}
finite (fin N).
decision (nfact N NF).
decision (all A x\ P x) :- finite A, pi x\ decision (P x).
\end{elpicode}

\noindent
There are two reasons for dismissing this encoding. The first one is that
in CIC it is not always possible to adopt it since the type system
of the meta language is too weak to accommodate for the one of the 
object language. In CIC the lambda abstraction has to carry a type in order to
make type checking decidable. Moreover CIC allows for functions with a
variable arity, like the following example:

\begin{coqcode}
Fixpoint arr T n := if n is S m then T -> arr T m else T.
Definition sum n : arr nat n := ...
Check sum 2   7 8   : nat.
Check sum 3   7 8 9 : nat.
\end{coqcode}

\noindent
The type system of the $\lambda$Prolog is too stringent to accept this terms.\\
The second reason is that the CIC encoding provided by Elpi is used for meta
programming (extending) the Coq system, hence it must accommodate the
manipulation of terms that are now know in advance (not even defined in Coq)
without using introspection primitives such as Prologs's \texttt{functor}
and \texttt{arg}. In this sense constants have to live in an open world, like
the \elpiIn{string} data type used in the examples so far.

In the literature we could find related encoding of the Calculus of
Constructions~\cite{felty93lics}. The goal of that work was to exhibit
a logic program performing proof checking in CC and hence relate the
proof system of intuitionistic higher-order logic (that animates $\lambda$Prolog
programs) with the Calculus of Constructions. The encoding is hence tailored
toward a different goal, and utilizes three relations to represent the
equational theory of CC. Section 6 contains a discussion about the use of the
unification procedure of the meta language in presence of non ground goals, but
the authors do not aim at exploiting it to the degree we want.\todo{sucks}

\todo{cite isabelle's TC, that are baked in}

\section{Conclusion}

Benefits: less work, reuse efficient ho unif (3x faster), indexing,

Future: tabling and static analysis (reuse for ML again).

Very little is Coq specific. Applies to all OL that are not a subsystem of 
HOL, or for ML that are used for meta programming.

\printbibliography

\clearpage

\input{appendix.tex}

\end{document}