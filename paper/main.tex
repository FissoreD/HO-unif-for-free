\documentclass[sigconf,natbib=false,review]{acmart}
\usepackage[]{biblatex}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
\addbibresource{bib.bib}

\usepackage{myTools}
\usepackage{macros}

% TODO: set this fields
%\setcopyright{cc}
%\setcctype{by}
\copyrightyear{2024}
\acmYear{XXXX 2024}
\acmBooktitle{YYY}
\acmDOI{ZZZZZZZZZZZZ}


% \xspaceaddexceptions{]\}}

\def\elpi{\proglang{elpi}}
\def\coqelpi{\proglang{coq-elpi}}
\def\lambdaprolog{\proglang{$\lambda$-prolog}}
\def\coq{\proglang{coq}}

\newcommand{\library}[1]{\textit{#1}\xspace}
\def\stdpp{\library{stdpp}}
\def\iris{\library{iris}}

\newcommand*{\acronym}[1]{\texttt{#1}\xspace}

\newtheorem{invariant}{Invariant}

\def\ol{\acronym{ol}} % object language
\def\ml{\acronym{ml}} % meta language
\def\lf{\acronym{lf}} % logical framework
\def\ho{\acronym{ho}} % higher order
\def\Forall{$\forall$}

\newcommand{\appsep}{\ensuremath{\textcolor{lightgray}{\cdot}}}
\newcommand{\EqualRel}{\ensuremath{=}}
\newcommand{\nEqualRel}{\ensuremath{\new}}
\newcommand{\UnifRel}{\ensuremath{\simeq}}
\newcommand{\nUnifRel}{\ensuremath{\not\simeq}}

\newcommand{\Uo}{\ensuremath{\UnifRel_o}\xspace}
\newcommand{\nUo}{\ensuremath{\nUnifRel_o}\xspace}
\newcommand{\Eo}{\ensuremath{\EqualRel_o}\xspace}
\newcommand{\nEo}{\ensuremath{\nEqualRel_o}\xspace}

\newcommand{\Ue}{\ensuremath{\UnifRel_\lambda}\xspace}
\newcommand{\nUe}{\ensuremath{\nUnifRel_\lambda}\xspace}
\newcommand{\Ee}{\ensuremath{\EqualRel_\lambda}\xspace}
\newcommand{\nEe}{\ensuremath{\nEqualRel_\lambda}\xspace}
\newcommand{\llambda}{\ensuremath{\mathcal{L}_\lambda}\xspace}

\newcommand{\linkbeta}{\texttt{link-}\ensuremath{\beta}\xspace}
\newcommand{\linketa}{\texttt{link-}\ensuremath{\eta}\xspace}

\newcommand{\Fo}{\ensuremath{\mathcal{F}_{\!o}\xspace}} % space non va
\newcommand{\Ho}{\ensuremath{\mathcal{H}_o}\xspace}

\newcommand*{\eqtau}{\ensuremath{\mathrel{\overset{\mathrm{\tau}}{=}}}}

\newcommand{\linketaM}[3]{\ensuremath{#1 \vdash #2 =_\eta #3}}
\newcommand{\linkbetaM}[3]{\ensuremath{#1 \vdash #2 =_\beta #3}}
\newcommand{\substCell}[3]{\ensuremath{#1 \vdash #2 = #3}}
\newcommand{\mapping}[3]{\ensuremath{#1 \mapsto #2^#3}}

\newcommand{\lhs}{\ensuremath{\mathrm{lhs}}\xspace}
\newcommand{\rhs}{\ensuremath{\mathrm{rhs}}\xspace}

\begin{document}

\title{HO unification from object language to meta language}

\author{Davide Fissore}
\email{davide.fissore@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\author{Enrico Tassi}
\email{enrico.tassi@inria.fr}
\affiliation{%
  \institution{Université Côte d'Azur, Inria}
  % \city{Nice}
  \country{France}}

\begin{abstract}
  Specifying and implementing a logic from scratch requires significant effort.
  Logical Frameworks and Higher Order Logic Programming Languages provide
  dedicated, high-level Meta Languages (ML) to facilitate this task in two
  key ways: 1) variable binding and substitution are simplified when ML binders
  represent object logic ones; 2) proof construction, and even proof search, is
  greatly simplified by leveraging the unification procedure provided by the ML.
  Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
  $\lambda$Prolog~\cite{miller_nadathur_2012} and
  Isabelle~\cite{10.1007/978-3-540-71067-7_7}
  which have been utilized to implement various formal systems such as
  First Order Logic~\cite{felty88cade},
  Set Theory~\cite{10.1007/BF00881873},
  Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
  Constuctions~\cite{felty93lics}.

  The object logic we are interested in is Coq's~\cite{Coq-refman}
  Dependent Type Theory (DTT),
  for which we aim to implement a unification procedure \Uo using the ML
  Elpi~\cite{dunchev15lpar}, a dialect of $\lambda$Prolog.
  Elpi's equational theory comprises
  $\eta\beta$ equivalence and comes equipped with a
  higher order unification procedure \Ue restricted to the pattern
  fragment~\cite{miller92jsc}.
  We want \Uo to be as powerful as \Ue but on the object logic DTT.
  Elpi also comes with an encoding for DTT that works well
  for meta-programming~\cite{tassi:hal-01637063,tassi:hal-01897468,gregoire:hal-03800154,newtc}.
  Unfortunately this encoding, which we refer to as \Fo,
  ``underuses'' \Ue by restricting it to first-order unification problems only.
  To address this issue, we propose a better-behaved encoding, \Ho,
  demonstrate how to map unification problems in \Fo{}
  to related problems in \Ho, and illustrate
  how to map back the unifiers found by \Ue, effectively implementing
   \Uo on top of \Ue for the encoding \Fo.

  We apply this technique to the implementation of a type-class~\cite{wadler89}
  solver for Coq~\cite{Coq-refman}.
  Type-class solvers are proof search procedures based on
  unification that back-chain designated lemmas, providing essential
  automation to widely used
  Coq libraries such as Stdpp/Iris~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
  and TLC~\cite{10.1007/978-3-642-14052-5_15}. These two libraries
  constitute our test bed.
\end{abstract}

\keywords{Logic Programming, Meta-Programming, Higher-Order Unification, Proof Automation}

\maketitle

\section{Introduction}
\label{sec:intro}

Specifying and implementing a logic from scratch requires significant effort.
Logical Frameworks and Higher Order Logic Programming Languages provide
dedicated, high-level Meta Languages (ML) to facilitate this task in two
key ways: 1) variable binding and substitution are simplified when ML binders
represent object logic ones; 2) proof construction, and even proof search, is
greatly simplified by leveraging the unification procedure provided by the ML.
Notable examples of ML are Elf~\cite{elf}, Twelf~\cite{twelf},
$\lambda$Prolog~\cite{miller_nadathur_2012} and
Isabelle~\cite{10.1007/978-3-540-71067-7_7}
which have been utilized to implement various formal systems such as
First Order Logic~\cite{felty88cade},
Set Theory~\cite{10.1007/BF00881873},
Higher Order Logic~\cite{books/sp/NipkowPW02}, and even the Calculus of
Constuctions~\cite{felty93lics}.

The object logic we are interested in is Coq's~\cite{Coq-refman}
Dependent Type Theory (DTT), and we want to code a type-class~\cite{wadler89}
solver for Coq~\cite{Coq-refman} using the Coq-Elpi~\cite{tassi:hal-01637063}
meta programming framework.
Type-class solvers are unification based proof search procedures
that combine a set of designated lemmas in order to providing essential
automation to widely used Coq libraries.

As the running example we take the \coqIn{Decide} type class,
from the Stdpp~\cite{JUNG_KREBBERS_JOURDAN_BIZJAK_BIRKEDAL_DREYER_2018}
library. The class identifies predicates equipped with a decision procedure.
The following three designated lemmas (called \coqIn{Instances} in the
type-class jargon) state that: 1) the type \coqIn{fin n}, of natural numbers
smaller than \coqIn{n} is finite; 2) the predicate \coqIn{nfact n nf},
linking a natural number \coqIn{n} to its prime factors \coqIn{nf}, is decidable;
3) the universal closure of a predicate has a decision procedure if the
predicate has and if its domain is finite.

\begin{coqcode}
Instance fin_fin n : Finite (fin n).              (* r1 *)
Instance nfact_dec n nf : Decision (nfact n nf).  (* r2 *)
Instance forall_dec A P : Finite A ~$\to$~             (* r3 *)
  ~$\forall$~x:A, Decision (P x) ~$\to$~ Decision (~$\forall$~x:A, P x).
\end{coqcode}

\noindent Under this context of instances a type-class solver is able to prove
the following statement automatically by back-chaining.

\begin{coqcode}
  Check _ : Decision (forall y: fin 7, nfact y 3).       ~\customlabel{goal:g}{(g)}~
\end{coqcode}

\noindent
The encoding of DTT provided by Elpi, that we will discuss at length later in
section~\ref{sec:encodings,sec:lang-spec} and ~\ref{}, is an Higher Order Abstract
Syntax (HOAS) datatype \elpiIn{tm} featuring (among others) the following
constructors:

\begin{elpicode}
type lam  tm -> (tm -> tm) -> tm.     % lambda abstraction
type app  list tm -> tm.              % n-ary application
type all  tm -> (tm -> tm) -> tm.     % forall quantifier
type con  string -> tm.               % constants
\end{elpicode}

\noindent
Following standard $\lambda$Prolog~\cite{miller_nadathur_2012}
the concrete syntax to abstract, at the meta level, an expression
\elpiIn{e} over a variable \elpiIn{x}
is <<\elpiIn{x\ e}>>, and square brackets denote a list of
terms separated by comma. As an example we show the encoding of the Coq term
<<\coqIn{~$\forall$~y:t, nfact y 3}>>:

\begin{elpicode}
all (con"t") y\ app[con"nfact", y, con"3"]
\end{elpicode}

\noindent
We now illustrate the encoding of the three instances above as higher-order
logic-programming rules: capital letters denote rule
parameters; \elpiIn{:-} separates the rule's head from the premises;
\elpiIn{pi w\ p} introduces a fresh nominal constant \elpiIn{w}
for the premise \elpiIn{p}.

\begin{elpicode}
finite (app[con"fin", N]).                            ~\customlabel{clause:r1}{(r1)}~
decision (app [con"nfact", N, NF]).                   ~\customlabel{clause:r2}{(r2)}~
decision (all A x\ app[P, x]) :- finite A,            ~\customlabel{clause:r3}{(r3)}~
  pi w\ decision (app[P, w]).
\end{elpicode}

\noindent
Unfortunately this translation of rule \ref{clause:r3} uses the
predicate \coqIn{P} as a first order term: for the meta
language its type is \elpiIn{tm}.
If we try to backchain the rule \ref{clause:r3} on the encoding of the goal
\ref{goal:g} given below

\begin{elpicode}
decision (all (app[con"fin", con"7"]) y\
  app[con"nfact", y, con"3"]).
\end{elpicode}

\noindent
we obtain an unsolvable unification problem \ref{problem:p}:
the two lists of terms have different lengths!
%The root cause is that
%\ref{problem:p} is an higher order in DTT, but becomes
%first order in the meta language due to the ``naive'' encoding.

\begin{elpicode}
app[con"nfact", y, con"3"] = app[P, y]                 ~\customlabel{problem:p}{(p)}~
\end{elpicode}

\noindent
In this paper we study a more sophisticated encoding of Coq terms allowing
us to rephrase the problematic rule \ref{clause:r3} as follows:

\begin{elpicode}
decision (all A x\ Pm x) :- decomp Pm P A, finite A,   ~\customlabel{clause:r3a}{(r3a)}~
  pi x\ decision (app[P, x]).
\end{elpicode}

\noindent
Since \elpiIn{Pm} is an higher-order unification variable
of type \elpiIn{tm -> tm},
with \elpiIn{x}
in its scope, the unification problem \ref{problem:pa}
admits one solution:

\begin{elpicode}
app[con"nfact", y, con"3"] = Pm y                     ~\customlabel{problem:pa}{(p')}~
Pm = x\ app[con"nfact", x, con"3"]     % assignment for Pm
A = app[con"fin", con"7"]              % assignment for A
\end{elpicode}

\noindent
After unifying the head of rule \ref{clause:r3a} with the goal, Elpi runs
the premise <<\elpiIn{decomp Pm A P}>> that is in charge of bringing the
assignment for \elpiIn{Pm} back to the domain \elpiIn{tm} of Coq terms:

\begin{elpicode}
P = lam A a\ app[con"nfact", a, con"3"]
\end{elpicode}

\noindent
This simple example is sufficient to show that the encoding we seek
is not trivial and does not only concern the head of rules, but the entire sequence
of unification problems that constitute the execution of a logic program.
In fact
the solution for \elpiIn{P} above generates a
(Coq) $\beta$-redex in the second premise (the predicate
under the \elpiIn{pi w\ }\hspace{-0.4em}):

\begin{elpicode}
decision (app[lam A (a\ app[con"nfact", a, con"3"]), w])
\end{elpicode}

\noindent
In turn this redex prevents the rule \ref{clause:r2} to backchain properly since
the following unification problem has no solution:

\begin{elpicode}
app[lam A (a\ app[con"nfact", a, con"3"]), x] =
app[con"nfact", N, NF]
\end{elpicode}
\noindent
~\\
The root cause of the problems we sketched in the running example
is that the unification procedure \Ue of the meta language is not aware
of the equational theory of the object logic, even if both theories
include $\eta\beta$-conversion and admit most general
unifiers for unification problems in the pattern fragment \llambda~\cite{miller92jsc}.

\paragraph{Contributions}
In this paper we discuss alternative encodings of Coq in
Elpi (Section~\ref{sec:encodings}), then we identify a minimal language \Fo{}
in which the problems sketched here can be fully described.
We then detail an encoding \elpiIn{comp} from \Fo{} to \Ho (the language of
the meta language) and a decoding \elpiIn{decomp} to relate the unifiers
bla bla.. TODO citare Teyjus.
The code discussed in the paper can be accessed at the URL:
\url{https://github.com/FissoreD/paper-ho}.

\section{Problem statement} %%%%%%%%%%%%%%%%%%%%%%
\label{sec:problem-statement}

The equational theory of Coq's Dependent Type Theory is very rich. In
addition to the usual $\eta\beta$-equivalence for functions, terms (hence types)
are compared up to proposition unfolding and fixpoint unrolling. Still,
for efficiency and predictability reasons, most form of automatic proof search
employ a unification procedure that captures a simpler one,
just $\eta\beta$, and that solves higher-order problems
restricted to the pattern fragment $\llambda$~\cite{miller92jsc}.
We call this unification procedure \Uo{}.

The equational theory of the meta language Elpi that we want to use to
implement a form of proof automation is strikingly similar, since it
it comprises $\eta\beta$ (for the meta language functions), and the
unification procedure \Ue{} solves higher-order problems in
$\llambda$.

In spite of the similarity the link between \Ue{} and \Uo{} is not trivial,
since the abstraction and application term constructors
the two unification procedures deal with are different. For example

\begin{tabular}{lcl}
\elpiIn{x\ f x} & \Ue{} & \elpiIn{f}\\
\elpiIn{lam A x\ app[con"f", x]} & \Uo{} & \elpiIn{con"f"}\\
\elpiIn{lam A x\ app[con"f", x]} & \nUe{} & \elpiIn{con"f"} \\
\elpiIn{P x} & \Ue{} & \elpiIn{x}\\
\elpiIn{app[P, x]} & \Uo{} & \elpiIn{x}\\
\elpiIn{app[P, x]} & \nUe{} & \elpiIn{x}\\
\end{tabular}

\noindent
One could ignore this similarity, and ``just'' describe the object language
unification procedure in the meta language, that is crafting a \elpiIn{unif}
predicate to be used as follows in rule \ref{clause:r3}:

\begin{elpicode}
decision X :- unif X (all A x\ app[P, x]), finite A,
  pi x\ decision (app[P, x]).
\end{elpicode}

\noindent
This choice would underuse the logic programming engine provided by
the metalanguage since by removing any datum from the head of rules
indexing degenerates. Moreover the unification procedure built in the
meta language is likely to be faster than one implemented in it,
especially if the meta language is interpreted as Elpi is.

To state precisely the problem we solve we need a \Fo{} representation
of DTT terms and a \Ho one.
We call \Eo the equality over ground terms in \Fo,
\Ee the equality over ground terms in \Ho,
\Uo the unification procedure we want to implement and
\Ue the one provided by the meta language.
TODO extend \Eo and \Ee with reflexivity on uvars.

\newcommand{\specunif}[3]{
  #3_i \in \llambda \Rightarrow %
    \exists \rho, %
      \rho #3_1 #1 \rho #3_2  %
        \Leftrightarrow #3_1 #2 #3_2 \mapsto \rho' \subseteq \rho
}


\newcommand{\unifcorrect}[3]{
  % \forall \rho #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    #3_i \in \llambda \Rightarrow
      #3_1 #2 #3_2 \mapsto \rho
        \Rightarrow
          \rho #3_1 #1 \rho #3_2  %
}

\newcommand{\unifcomplete}[3]{
  % \forall #3_1 #3_2, %
    % \{#3_1, #3_2\} \subseteq \llambda \Rightarrow %
    #3_i \in \llambda \Rightarrow
      % \forall \rho, %
        \rho #3_1 #1 \rho #3_2  %
          \Rightarrow \exists \rho', #3_1 #2 #3_2 \mapsto \rho' \land \rho' \subseteq \rho
}

We write $t_1 \Ue t_2 \mapsto \sigma$ when $t_1$ and $t_2$ unify
with substitution $\sigma$; we write $\sigma t$ for the application of
the substitution to $t$, and $\sigma X = \{ \sigma t | t \in X\}$ when
$X$ is a set; we write $\sigma \subseteq \sigma'$ when $\sigma$ is more
general than $\sigma'$. We assume that the unification of our meta
language is correct:
%
\begin{gather}
  \unifcorrect{\Ee}{\Ue}{t} \label{prop:correct-ml}\\
  \unifcomplete{\Ee}{\Ue}{t}\label{prop:complete-ml}
\end{gather}

\newcommand{\C}[4]{\ensuremath{\langle #1 \rangle}\mapsto(#2,#3,#4)}
\newcommand{\D}[4]{\ensuremath{\langle #1,#2,#3 \rangle^{-1}\mapsto #4}}

We illustrate a compilation $\C{s}{t}{m}{l}$ that
maps a term $s$ in \Fo{} to a term $t$ in \Ho, a variable mapping $m$ and
list of links $l$.
The variable map connects unification variables in \Ho with variables
in \Fo{} and is used to ``decompile'' the assignment,
$\D{\sigma}{m}{l}{\rho}$. Links represent problematic sub-terms which
are linked to the unification variable that stands in their place in the
compiled term. These links are checked for or progress XXX improve....

We represent a logic program \emph{run} in \Fo as
a list \emph{steps} $p$ of length $\mathcal{N}$. Each made of a
unification problem between terms $\mathcal{S}_{p_l}$ and
$\mathcal{S}_{p_r}$ taken from the set of all terms $\mathcal{S}$.
The composition of these steps starting from the
empty substitution $\rho_0$ produces the final
substitution $\rho_\mathcal{N}$.
\footnote{If the same rule is used multiple time in a run we
just consider as many copies as needed of the terms composing the
rules, with fresh unification variables each time}
The initial here $\rho_0$ is the empty substitution
%
\newcommand{\progress}{\ensuremath{\mathrm{progress}}\xspace}
\newcommand{\fstep}{\ensuremath{\mathrm{fstep}}\xspace}
\newcommand{\hstep}{\ensuremath{\mathrm{hstep}}\xspace}
\newcommand{\frun}{\ensuremath{\mathrm{frun}}\xspace}
\newcommand{\hrun}{\ensuremath{\mathrm{hrun}}\xspace}
\newcommand{\stepF}[4]{\ensuremath{\fstep(#1,#2,#3) \mapsto #4}}
\newcommand{\stepFD}[5]{%
\ensuremath{#3 #1_{#2_l} \Uo #3 #1_{#2_r} \mapsto #4 \land #5 = #3 \cup #4}}
\newcommand{\stepH}[6]{\ensuremath{\hstep(#1,#2,#3,#4) \mapsto (#5, #6)}}
\newcommand{\stepHD}[6]{\ensuremath{%
#3 #1_{#2_l} \Ue #3 #1_{#2_r} \mapsto #4 \land \progress(#6,#3 \cup #4) \mapsto (#6',#5)}}
\newcommand{\runF}[3]{\ensuremath{\frun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runFD}[2]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepF{#1}{p}{\rho_{p-1}}{\rho_{p}}}}
\newcommand{\runH}[3]{\ensuremath{\hrun(#1,#2) \mapsto #3_{#2}}}
\newcommand{\runHD}[3]{\ensuremath{%
\bigwedge_{p = 1}^{#2} \stepH{#1}{p}{\sigma_{p-1}}{#3_{p-1}}{\sigma_{p}}{#3_p}}}
\newcommand{\deff}{\ensuremath{\stackrel{{\scriptscriptstyle def}}{=\!=\!\!\!=}}}
\newcommand{\linkStore}{\ensuremath{\mathbb{L}}\xspace}

$$
\begin{array}{l}
\stepF{\mathcal{S}}{p}{\rho}{\rho''}
\deff
\stepFD{\mathcal{S}}{p}{\rho}{\rho'}{\rho''}\vspace{2pt}\\
\runF{\mathcal{S}}{\mathcal{N}}{\rho}
\deff
\runFD{\mathcal{S}}{\mathcal{N}}
\end{array}
$$

We simulate each run in \Fo{} with a run in \Ho as follows.
Note that $\sigma_0$ is the empty substitution.
$$
\begin{array}{l}
\stepH{\mathcal{T}}{p}{\sigma}{\linkStore}{\sigma''}{\linkStore'} \deff\vspace{2pt}\\
  \qquad\stepHD{\mathcal{T}}{p}{\sigma}{\sigma'}{\sigma''}{\linkStore}\vspace{2pt}\\
\runH{\mathcal{S}}{\mathcal{N}}{\rho} \deff \vspace{2pt}\\
  \qquad \mathcal{T} \times \mathbb{M} \times \linkStore_0 = \{ (t_j,m_j,l_j) | s_j \in \mathcal{S}, \C{s_j}{t_j}{m_j}{l_j} \}\vspace{2pt}\\
  \qquad \runHD{\mathcal{T}}{\mathcal{N}}{\linkStore}\vspace{2pt}\\
  \qquad \D{\sigma_{\mathcal{N}}}{\mathbb{M}}{\linkStore_{\mathcal{N}}}{\rho_{\mathcal{N}}}
\end{array}
$$

\noindent
Here \hstep{} is made of two sub-steps: a call to \Ue (on the compiled
terms) and a call to \progress{} on the set of links. We claim the following:

\begin{proposition}[Simulation]\label{prop:simulation}
$\forall \mathcal{S}, \forall \mathcal{N},$
$$
  \runF{\mathcal{S}}{\mathcal{N}}{\rho}
  \Leftrightarrow
  \runH{\mathcal{S}}{\mathcal{N}}{\rho}
$$
\end{proposition}

\noindent
That is, the two executions give the same result. Moreover:

\begin{proposition}[Simulation fidelity]\label{prop:fidelity}
In the context of~ \hrun, if $~\mathcal{T} \subseteq \llambda$ we have that
$\forall p \in 1 \ldots \mathcal{N},$
$$
\stepF{\mathcal{S}}{p}{\rho_{p-1}}{\rho_p}
\Leftrightarrow
\stepH{\mathcal{T}}{p}{\sigma_{p-1}}{\linkStore}{\sigma_p}{\_}
$$
\end{proposition}
\noindent
In particular this property guarantees that a \emph{failure} in the \Fo{} run
is matched by a failure in \Ho{} \emph{at the same step}. We consider this
property very important from a practical point of view since it guarantees
that the execution traces are strongly related and in turn this enables a user
to debug a logic program in \Fo{} by looking at its execution trace in
\Ho{}.

XXX permuting hrun does not change the final result if check dooes not fail eagerly

XXX if we want to apply heuristics, we can apply them in decomp to avoid committing to
a non MGU too early


We can define $s_1 \Uo{} s_2$ by specializing the code of \hrun{} to
$\mathcal{S} = \{ s_1, s_2 \}$ as follows:
%
$$
\begin{array}{l}
s_1 \Uo s_2 \mapsto \rho \deff \vspace{2pt}\\
\quad\C{s_1}{t_1}{m_1}{l_1} \land \C{s_2}{t_2}{m_2}{l_2}\vspace{2pt}\\
\quad    t_1 \Ue t_2 \mapsto \sigma' \land
    \progress~(\{l_1,l_2\},\sigma') \mapsto (L,\sigma'') \land\vspace{2pt}\\
\quad \D{\sigma''}{\{m_1,m_2\}}{L}{\rho}
\end{array}
$$

\begin{proposition}[Properties of \Uo{}]
\begin{gather}
  \unifcorrect{\Eo}{\Uo}{s}\customlabel{prop:correct}{(correct)}\\
\unifcomplete{\Eo}{\Uo}{s}\customlabel{prop:complete}{(complete)}\\
% \forall \rho'\rho,
  \rho s_1 \Eo \rho s_2 \Rightarrow
  \rho' \subseteq \rho \Rightarrow
  \rho's_i \in \llambda \Rightarrow
  \rho' s_1 \Uo \rho' s_2 %\label{prop:simulation}
\end{gather}
\end{proposition}

Properties \ref{prop:correct} and \ref{prop:complete} state, respectively, that
in \llambda the implementation of \Uo is correct, complete and returns the most
general unifier.

\marginpar{fix}Property \ref{prop:simulation} states that \Uo, hence our compilation scheme,
is resilient to unification problems outside \llambda solved by
a third party. We believe this property is of practical interest since we
want the user to be able to add heuristics via hand written rules
to the ones obtained by our compilation scheme. A Typical example
is the following problem \ref{problem:q} that is outside \llambda:

\begin{elpicode}
app [F, con"a"] = app[con"f", con"a", con"a"]          ~\customlabel{problem:q}{(q)}~
F = lam x\ app[con"f",x,x]                             ~\customlabel{heuristic:h}{(h)}~
\end{elpicode}

\noindent
Instead of rejecting it our scheme accepts it and guarantees that if
\ref{heuristic:h} is given (after the compilation part of the scheme, as
a run time hint) then ...


\subsection{The intuition in a nutshell}
\label{sec:nutshell}
A term $s$ is compiled in a term $t$ where every
``problematic'' sub term $p$ is replaced by a fresh unification variable $h$
and an accessory link that represent a suspended unification problem
$h \Ue p$. As a result \Ue is ``well behaved'' on $t$, that is it does not
contradict \Eo as it would otherwise do on ``problematic'' terms.
We now define ``problematic'' and ``well behaved'' more formally.

\newcommand{\maybeeta}{\ensuremath{\Diamond\eta}\xspace}
\newcommand{\maybebeta}{\ensuremath{\Diamond\beta}\xspace}
\begin{definition}[\maybeeta]
  $\maybeeta = \{ t ~|~ \exists \rho, \rho t ~\mathrm{is~an~eta~expansion} \}$
\end{definition}

\noindent
An example of term $t$ in \maybeeta{} is
$\lambda x.\lambda y.F~y~x$
since the substitution
$\rho = \{ F \mapsto \lambda a.\lambda b.fba\}$
makes $\rho t = \lambda x.\lambda y.f x y$
that is the eta long form of $f$. This term is problematic since
its rigid part, the $\lambda$-abstractions, cannot justify a
unification failure against, say, a constant.

\begin{definition}[\maybebeta]
  $\maybebeta = \{ X t_1 \ldots t_n ~|~ X t_1 \ldots t_n \not\in \llambda \}$.
\end{definition}

\noindent
An example of $t$ in \maybebeta{} is $F a$ for a constant $a$. Note however tha
an oracle could provide an assignment $\rho = \{ F \mapsto \lambda x.x\}$
that makes the resulting term fall outside of \maybebeta.

\newcommand{\subterm}[1]{\ensuremath{\mathcal{P}(#1)}}
\begin{definition}[Subterms \subterm{t}] The set of sub terms of $t$ is the
  largest set $\mathcal{P(t)}$ that can be obtained by the following rules.
$$
\begin{array}{l}
t \in \subterm{t}\\
t = f t_1\ldots t_n \Rightarrow \subterm{t_i} \subseteq \subterm{t} \land f \in \subterm{t}\\
t = \lambda x.t' \Rightarrow \subterm{t'} \subseteq \subterm{t}\\
\end{array}
$$
\end{definition}

\noindent
We write $\subterm{X} = \bigcup_{t\in X} \subterm{t}$ when $X$ is a set of terms.

\newcommand{\wellb}{\ensuremath{\mathcal{W}}\xspace}
\begin{definition}[Well behaved set]
Given a set of terms $X \subseteq \Ho{}$,
$$
\wellb(X) \Leftrightarrow \forall t \in \subterm{X}, t \not\in (\maybebeta{} ~\cup~ \maybeeta{})
$$
\end{definition}

\noindent

\begin{proposition}[\wellb{}-preservation]\label{prop:nf}
$\forall \mathcal{T}, \forall \linkStore, \forall p, \forall \sigma, \forall \sigma'$
$$
\wellb(\sigma\mathcal{T}) \land
\stepH{\mathcal{T}}{p}{\sigma}{\linkStore}{\sigma'}
\Rightarrow \wellb(\sigma' \mathcal{T})
$$
\end{proposition}

\noindent
A less formal way to state \ref{prop:nf} is that \hstep{} never
``commits'' an unneeded $\lambda$-abstraction in $\sigma$ (a $\lambda$
that could be erased by an $\eta$-contraction),
nor puts in $\sigma$ a flexible application outside \llambda{} (an application
node that could be erased by a $\beta$-reduction).

Note that proposition \ref{prop:nf} does not hold for \Uo{} since
decompilation can introduce (actually restore) terms in
\maybeeta or \maybebeta that were move out of the way (put in $\linkStore$)
during compilation.

\section{Alternative encodings and related work}

Paper \cite{10.1145/2966268.2966272} introduces semi-shallow.

Our encoding of DTT may look ``semi shallow'' since we use the meta-language
lambda abstraction but not its application (for the terms of type \elpiIn{tm}).
A fully shallow encoding unfortunately does not fit our use case, although
it would make the running example work:

\begin{elpicode}
finite (fin N).
decision (nfact N NF).
decision (all A x\ P x) :- finite A, pi x\ decision (P x).
\end{elpicode}

\noindent
There are two reasons for dismissing this encoding. The first one is that
in DTT it is not always possible to adopt it since the type system
of the meta language is too weak to accommodate terms with a variable arity,
like the following example:

\begin{coqcode}
Fixpoint arr T n := if n is S m then T -> arr T m else T.
Definition sum n : arr nat n := ...
Check sum 2   7 8   : nat.
Check sum 3   7 8 9 : nat.
\end{coqcode}

\noindent
The second reason is the encoding for Coq is used for meta programming the
system, hence it must accommodate the manipulation of terms that are now
know in advance (not even defined in Coq) without using introspection
primitives such as Prologs's \texttt{functor} and \texttt{arg}.

In the literature we could find a few related encoding of DTT.
TODO In~\cite{felty93lics} is related and make the
discrepancy between the types of ML and DTT visible. In this case
one needs 4 application nodes. Moreover the objective is an encoding
of terms, proofs, not proof search. Also note the conv predicate,
akin to the unif we rule out.

TODO This other paper~\cite{10.1007/978-3-031-38499-8_25} should also be cited.

None of the encodings above provide a solution to our problem.

\section{Preliminaries: \Fo{} and \Ho}
\label{sec:lang-spec}

In order to reason about unification we provide a description of the
\Fo{} and \Ho languages where unification variables
are first class terms, i.e. they have a concrete syntax. We keep these languages
minimal, for example, we omit the \elpiIn{all} quantifier of DTT we used
in the example in Section~\ref{sec:intro} together with the type notation of
terms carried by the \elpiIn{lam} constructor.
%
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-13pt}

\begin{figure}[H]
  \begin{tabular}{ll}
  \begin{minipage}{0.21\textwidth}
   \inputrawelpicode{code/fo_tm}
  \end{minipage}
  &
  \begin{minipage}{0.24\textwidth}
   \inputrawelpicode{code/ho_tm}
  \end{minipage}
  \end{tabular}\vspace{4pt}
  \caption{The \Fo{} and \Ho languages}\vspace{0.3em}
  \label{code:common-terms}
  \Description[code:common-terms]{code:common-terms}
\end{figure}

\noindent
Unification variables (\elpiIn{fuva} term constructor)
in \Fo{} have no explicit scope:
the arguments of an higher order variable are given via the \elpiIn{fapp}
constructor. For example the term \coqIn{P x} is represented as
\elpiIn{fapp[fuva N, x]}, where \elpiIn{N} is a memory address and
\elpiIn{x} is a bound variable.\\
In \Ho the representation of \coqIn{P x} is instead \elpiIn{uva N [x]},
since unification variables come equipped with an explicit scope.
We say that the unification variable occurrence \elpiIn{uva N L} is in
\llambda if and only if \elpiIn{L} is made of distinct names. The
predicate to test this condition is called \elpiIn{pattern-fragment}:

\input{code/pattern_fragment}

\noindent
The \elpiIn{name} builtin predicate tests if a term is a bound variable.
\footnote{one could always load name x for every x under a pi and get rid of the name builtin}

In both languages unification variables are identified by a natural number
representing a memory address.
The memory and its associated operations are described below:

\input{code/mem_types}

\noindent
If a memory cell is \elpiIn{none}, then the corresponding unification variable
is not set. \elpiIn{assign} sets an unset cell to the given value, while
\elpiIn{new} finds the first unused address and sets it to \elpiIn{none}.\marginpar{is new used?}

Since in \Ho unification variables have a scope, their solution needs to be
abstracted over it to enable the instantiation of a single
solution to different scopes. This is obtained via the \elpiIn{inctx}
container, and in particular via its \elpiIn{abs} binding constructor.
On the contrary a solution to a \Fo variable is a plain term.

\input{code/fo_subst}
\input{code/ho_subst}

\noindent
We call \elpiIn{fsubst} the memory of \Fo{}, while we call \elpiIn{subst}
the one of \Ho.
Both have the invariant that they are not cyclic, TODO explain.
Other invariant: the terms in ho\_subst never contains eta and beta expansion

\input{code/comp_base_types}

\begin{invariant}[Unification variable arity]\label{inv:uvaarity}
Each variable \elpiIn{A}
in \Ho has a (unique) arity \elpiIn{N} and each occurrence~
\elpiIn{(uva A L)} is such that \elpiIn{(len L N)} holds
\label{invariant:arity}
\end{invariant}

\noindent
The compiler establishes a mapping between variables of the two languages.
In order to preserve invariant \ref{inv:uvaarity} we store the
arity of each \elpiIn{hvariable} in the mapping and we reuse an existing
mapping only if the arity matches.

TODO: add ref to \cref{sec:invariant1}

\input{code/alloc_mapping}

\noindent
When a single \elpiIn{fvariable} occurs multiple times with different numbers
of arguments the compiler generates multiple mappings for it, on a first
approximation, and then makes the mapping bijective by introducing
\linketa; this detail is discussed in section \ref{sec:eta}.

As we mentioned in section~\ref{sec:nutshell} the compiler
replaces terms in \maybeeta and \maybebeta with fresh variables
linked to the problematic terms. Each class of problematic terms
has a dedicated link.

\input{code/comp_links}

\noindent
The right hand side of a link, the problematic term, can occur under binders.
To accommodate this situation the compiler wraps \elpiIn{baselink} using
the \elpiIn{inctx} container.

\begin{invariant}[Link left hand side]\label{inv:linklhs}
  The left hand side of a new link
  is a variable.
\end{invariant}

\noindent
If the variable is assigned during a run the link is considered for
progress and possibly eliminated. This is discussed in
section~\ref{sec:eta}.\marginpar{is this the right section?}

\subsection{Notational conventions}

When we write \Ho terms outside code blocks we follow the
usual $\lambda$-calculus notation, reserving $f, g, a, b$ for constants,
$x, y, z$ for bound variables and $X, Y, Z, F, G, H$ for unification variables.
However we need to
distinguish between the ``application'' of a unification variable
to its scope and the application of a term to a list of arguments.
We write the scope of unification variables in subscript
while we use juxtaposition for regular application.
Here a few examples:
\vspace{5pt}

\begin{tabular}{ll}
  $f~ a$ &  \elpiIn{app[con "f", con "a"]}\\
  $\lambda x.F_{x} ~ a$ & \elpiIn{lam x\ app[uva F [x], con "a"]} \\
  $\lambda x.\lambda y.F_{x y}$ & \elpiIn{lam x\ lam y\ uva F [x, y]} \\
  $\lambda x.F_{x} ~ x$ & \elpiIn{lam x\ app[uva F [x], x]} \\
\end{tabular}
\vspace{5pt}

\noindent
When detailing examples we write links as equations between terms under a context.
The equality sign is subscripted with
kind of \elpiIn{baselink}. For example $\linkbetaM{x}{A}{F_x~a}$ corresponds to:
\begin{elpicode}
abs x\ val (link-beta (uva A []) (app[uva F [x],con "a"]))
\end{elpicode}

\noindent
When it is clear from the context we shall use the same syntax for \Fo{} terms
(although we never subscripts unification variables).

\subsection{Equational theory and Unification}

In order to express properties \ref{prop:correct, prop:complete, prop:simulation}
we need to equip \Fo{} and \Ho with term equality,
substitution application and unification.

\paragraph{Term equality: \Eo vs. \Ee} We extend the equational theory
over ground terms to the full languages by adding the reflexivity of
unification variables (a variable is equal to itself).

The first four rules are common to both equalities and correspond to $\alpha$-equivalence.
In addition to that \Eo has rules for $\eta$ and $\beta$-equivalence.

\input{code/feq}

\begin{elpicode}
  ~\PYG{k+kd}{type} \PYG{n+nf}{(\Ee)} \PYG{k+kt}{tm -> tm -> o}~.
  con C ~\Ee~fcon C.
  app A ~\Ee~fapp B :- forall2 ~(\Ee)~ A B.
  lam F ~\Ee~flam G :- pi x\ x ~\Ee~x => F x ~\Ee~G x.
  uva N A ~\Ee~fuva N B :- forall2 ~(\Ee)~ A B.
\end{elpicode}

\noindent
The main point in showing these equality tests is to remark how weaker \Ee is,
and to identify the four rules that need special treatment in
the implementation of \Ue.

For reference, \elpiIn{(beta T A R)} reduces away \elpiIn{lam} nodes in head
position in \elpiIn{T} whenever the list \elpiIn{A} provides a corresponding
argument.

\input{code/beta_fo}

\noindent
The \elpiIn{name} predicate holds only on nominal constants (i.e. bound
variables). Elpi provides it as a builtin, but one could implement it by
systematically loading the hypothetical rule \elpiIn{name x} every time
a nominal constant is postulated via \elpiIn{pi x\ }.

\paragraph{Substitution application: $\rho s$ and $\sigma t$}

Applying the substitution corresponds to dereferencing a term with respect to
the memory. To ease the comparison we split \Fo dereferencing into a
\elpiIn{fder} step and a \elpiIn{napp} one. The former step replaces references
to memory cells that are set with their values, ans has a corresponding
operation in \Ho, namely \elpiIn{deref}. On the contrary \elpiIn{napp},
in charge of ``flattening'' \elpiIn{fapp} nodes, has no corresponding
operation in \Ho. The reasons for this asymmetry is that an \elpiIn{fapp}
node with a flexible head is always mapped to a \elpiIn{uva} (as per
sections \ref{sec:compilation,sec:beta}), preventing nested applications to
materialize.

\input{code/fderef}

\noindent
Note that the cut operator is inessential, it could be
removed at the cost of a verbose test on the head of \elpiIn{L}
in the last rule (\elpiIn{L} head
can be \elpiIn{fcon}, \elpiIn{flam} or a name).

Applying the substitution in \Ho{} is very similar, with
the caveat that assignments have to be moved to the
current scope, i.e. renaming the \elpiIn{abs}-bound variables
with the names in the scope of the unification variable occurrence.

\input{code/deref}

\noindent
Note that move strongly relies on invariant \ref{inv:uvaarity}: the length
of the arguments of all occurrences of a unification variable and the
number of abstractions in its assignment have to match. In turn
this grants that \elpiIn{move} never fails.

\input{code/move}

\paragraph{Term unification: \Uo vs. \Ue}

In this paper we assume to have an implementation of \Ue that satisfies
properties~\ref{prop:correct-ml} and~\ref{prop:complete-ml}. Although we provide an
implementation in the appendix (that we used for testing purposes) we only
describe its signature here. Elpi is expected to provide this brick, as well as
any other implementation of $\lambda$Prolog.

\input{code/ue_type}

\noindent
The only detail worth discussing is the fact that the procedure updates a
substitution, rather than just crafting one as presented in
section~\ref{sec:problem-statement}. The reason is that the algorithm folds
over a term, updating a substitution while it traverses it.\marginpar{explain better}

% The first three rules unify terms with same rigid heads, and
% call the unification relation on the sub-terms. If $t_1$ (resp. $t_2$) is an
% assigned variables, $t_1$ is dereferenced to $t_1'$ (resp. $t_2'$) and the
% unification is called between $t_1'$ and $t_2$ (resp. $t_1$ and $t_2'$). If both
% terms are unification variables, we test that their arguments are in the pattern
% fragment, we allocate a new variable $w$ in $\rho_1$ such that $w$ is the
% pruning of the arguments of $t_1$ and $t_2$, we assign both $t_1$ and $t_2$ to
% $w$ and return the new mapping $\rho_2$ containing all the new variable
% assignment. Finally, if only one of the two terms is an unification variable
% $v$, after having verified that $v$ does not occur in the other term $t$, we
% bind $v$ to $t$ and return the new substitution mapping.

% \old

% A key property needed in unification is being able to verify if two terms are
% equal wrt a given equational theory. This relation allow to compare terms under
% a certain substitution mapping, so that any time a variable $v$ is assigned in a
% subterm, a dereferencing of $v$ is performed. After variable dereferencing, the
% test for equality is continued on the new-created subterm.

% The base equality function over terms can be defined as follows:

% The solution we are proposing aim to overcome these unification issues by 1)
% compiling the terms $t$ and $u$ of the OL into an internal version $t'$ and $u'$
% in the ML; 2) unifying $t'$ and $u'$ at the meta level instantiating meta
% variables; 3) decompiling the meta variable into terms of the OL; 4) assigning
% the variables of the OL with the decompiled version of their corresponding meta
% variables. We claim that $t$ and $u$ unify if and only if $t'$ and $u'$ unify
% and that the substitution in the object language is the same as the one returned
% by the ML. \todo{same or $\supseteq$ or $\subseteq$}

% In the following section we explain how we deal with term (de)compilation and
% links between unification variables.

\section[Compilation: fo\_tm to tm]{Basic simulation of \Fo{} in \Ho{}}
\label{sec:compilation}

In this section we describe a basic compilation scheme that we refine
later, in the following sections. This scheme is sufficient to implement
an \Uo{} that respects $\beta$-conversion for terms in \llambda. The extension to
$\eta\beta$-conversion is described in Section \ref{sec:eta} and the support
for terms outside \llambda in Section \ref{sec:beta}.

\subsection{Compilation}
\marginpar{manca beta normal in entrata}

The main task of the compiler is to recognize \Fo{} variables standing
for functions and map them to higher order variables in \Ho.
In order to bring back the substitution from \Ho{} to \Fo{} the compiler
builds a ``memory map'' connecting the the kind of variables using routine
\ref{clause:malloc}.

The signature of the \elpiIn{comp} predicate below allows for the generation of
links (suspended unification problems) that play no role in this section
but play a major role in Sections \ref{sec:eta} and \ref{sec:beta}.
With respect to \ref{sec:problem-statement} the signature also allows
for updates to the substitution.  The code below only allocates space
for the variables, i.e. sets their memory address to \elpiIn{none},
a details not worth mentioning in the previous discussion.

\input{code/comp_base}

\noindent
This preliminary version of \elpiIn{comp} recognizes \Fo{} variables
applied to a (possibly empty) duplicate free list of names (i.e.
\elpiIn{pattern-fragment} detects variables in \llambda).
Note tha compiling \elpiIn{Ag} cannot create new mappings nor links, since \elpiIn{Ag}
is made of bound variables and the hypothetical rule loaded by \elpiIn{comp-lam}
(see below) grants this property.

\input{code/comp_lam}

\noindent
In the code above the syntax \elpiIn{pi x y\..} is syntactic sugar for
iterated \elpiIn{pi} abstraction, as in \elpiIn{pi x\ pi y\..}.

The auxiliary function \elpiIn{close-links} tests if the bound variable
\elpiIn{v} really occurs in the link. If it is the case the link is wrapped into
an additional \elpiIn{abs} node binding \elpiIn{v}. In this way links generated
deep inside the compiled terms can be moved outside their original context
of binders.

\input{code/comp_close_links}

\noindent
Note that we could remove the second rule, whose purpose is to make
links more readable by pruning unneeded abstractions (unused context entries).

\subsection{Execution}
\label{sec:execution}

A step in \Ho consists in unifying two terms and reconsidering all
links for progress. If any of the two tasks fail we say that the entire step
fails, and it is at this granularity that we can relate steps in the
two languages.


\input{code/hstep}

\noindent
Note tha the notation \elpiIn{((A ~\Ue~B) C D)} is syntactic sugar for
\elpiIn{((~\Ue~) A B C D)}.

Reconsidering links is a fixpoint, since the progress of a link can update the
substitution and in turn enable another link to progress.

\input{code/progress}

\noindent
In the base compilation scheme \elpiIn{progress1} is the identity
on both the links and the substitution, so the fixpoint trivially terminates.
Sections \ref{sec:eta} and \ref{sec:beta} add rules to \elpiIn{progress1}
and justify why the don't hinder termination.

TODO: discuss occur check

\subsection{Substitution decompilation}

Decompiling the substitution requires to first force the
progress of links and then allocating new unassigned variables
in the substitution for \Fo{} and finally decompiling all
assignments. Note that \ref{inv:linklhs} and the
occur check allows us to update the subst.


\input{code/decompile}

\noindent
Decompiling an assignment requires to turn abstractions into
lambdas. For aestetic purposes we also eta-contract the result
(not needed since Fo equality can do that)

\input{code/decompm}

\noindent
Finally decompiling a term is trivial, now that we have an extended
mapping containing all unassigned variables \Ue may have introduced.

\input{code/decomp}

\noindent
Note that we use beta to build fapp nodes when needed (if Ag is empty
no \elpiIn{fapp} node should appear).

\subsection{Definition of \Uo and its properties}

\input{code/unif_fo}

The code given so far applies to terms in $\beta\eta$-normal form where
unification variables in \Fo{} can occur non linearly but always with
the same number of arguments, and where their arguments are distinct names
(as per \llambda).

\begin{lemma}[Compilation round trip] If
  \elpiIn{comp S T [] M [] _ [] _} then \elpiIn{decomp M T S}
\end{lemma}
\begin{proof}[Proof sketch]
trivial, since the terms are beta normal beta just builds an app.
\end{proof}


\begin{lemma}
Properties \ref{prop:correct} and
\ref{prop:complete} hold for the implementation of \Uo above
\end{lemma}
\begin{proof}[Proof sketch]
 In this setting \Ee is as strong as
\Eo on ground terms. What we have to show is that whenever two different \Fo
terms can be made equal by a substitution $\rho$ (plus the \ref{clause:beta1}
and \ref{clause:beta2} if needed) we can find this $\rho$ by finding
a $\sigma$ via \Ue{} on the corresponding \Ho terms and by decompiling it.
If we look at the \Fo{} terms, the are two interesting cases:
\begin{itemize}
\item \elpiIn{fuva X ~\Uo~s}. In this case after \elpiIn{comp} we have
  $Y \Ue t$ that succeeds with $\sigma = \{ Y \mapsto t\}$ and
  $\sigma$ is decompiled to $\rho = \{ Y \mapsto s\}$.
\item \elpiIn{fapp[fuva X|L] ~\Uo~s}. In this case
 we have $Y_{\vec{x}} \Ue t$ that succeeds with
 $\sigma = \{ \vec{y} \vdash Y \mapsto t[\vec{x}/\vec{y}]\}$ that in turn
 is decompiled to $\rho = \{ Y \mapsto \lambda \vec{y}.s[\vec{x}/\vec{y}]\}$.
 Thanks to \ref{clause:beta1}
 $(\lambda \vec{y}.s[\vec{x}/\vec{y}])~\vec{x} \Eo s$.
\end{itemize}
Since the mapping is a bijection occur check in \Ho{} corresponds to occur
check in \Fo{}.
\end{proof}

\begin{lemma} Properties simulation (\ref{prop:simulation}) and
fidelity (\ref{prop:fidelity}) hold
\end{lemma}
\begin{proof}[Proof sketch]
Since \elpiIn{progress1} is trivial \fstep and \hstep are the same, that is
in this
context where input terms are $\beta\eta$-normal and we disregard $\eta$-equivalence
\Ue is equivalent to \Uo.
\end{proof}

\subsection{Limitations of by this basic scheme}

\begin{gather}
\lambda x y.F~y~x = \lambda x y.x\\
\lambda x. f~(F~x)~x = f~(\lambda y.y)
\end{gather}
Note that here $F$ is used with different arities, moreover
in the second problem the left hand side happens to be an
eta expansion (of $f (\lambda y.y)$) only after we discover that
$F = \lambda x\lambda y.y$ (i.e. that $F$ discards the $x$ argument).
Both problems are addressed in the next section.
  
% \subsection{Example}

% OK

% \begin{elpicode}
% Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%       , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr z (s z) ] % $\lambda x.g (F x) = \lambda x.g a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% \end{elpicode}

% KO

% \begin{elpicode}
%   Terms [ flam x\ fapp[fcon"g",fapp[fuva z, x]]
%   , flam x\ fapp[fcon"g", fcon"a"] ]
% Problems = [ pr 0 1   % $A = \lambda x.x$
%            , pr 2 3 ] % $A a = a$
% lam x\ app[con"g",uva z [x]] ~\Uo~lam x\ app[con"g", con"a"]
% link z z (s z)
% HS = [some (abs x\con"a")]
% S = [some (flam x\fcon a)]
% lam x\ app[f, app[X, x]] = Y,
%   lam x\ x) = X.
% \end{elpicode}

% \otext{Goal: $s_1 \Uo s_2$ is compiled into $t_1 \Ue t_2$}
% \otext{What is done: uvars \elpiIn{fo_uv} of OL are replaced into uvars \elpiIn{ho_uv} of the ML}
% \otext{Each \elpiIn{fo_uv} is linked to an \elpiIn{ho_uv} of the OL}
% \otext{Example needing the compiler v0 (tra l'altro lo scope è ignorato):\\ \elpiIn{lam x\ app[con"g",app[uv 0, x]] ~\Uo~lam x\ app[con"g", c"a"]}}
% \otext{Links used to instantiate vars of elpi}
% \otext{After all links, the solution in links are compacted and given to coq}
% \otext{It is not so simple, see next sections (multi-vars, eta, beta)}


% The compilation step is meant to recover the higher-order variables of the OL,
% expressed in a first order way, by replacing them with higher-order variables in
% the ML. In particular, every time a variable of the OL is encountered in the
% original term, it is replaced with a meta variable, and if the OL variable is
% applied to a list of distinct names $L$, then this list becomes the scope of the variable.
% For all the other constructors of
% \elpiIn{tm}, the same term constructor is returned and its arguments are
% recursively compiled. The predicate in charge for term compilation is:

% \elpiIn{type comp tm -> tm -> links -> links -> subst -> subst -> o}.

% \noindent
% where, we take the term of the OL, produce the term of the ML, take a list
% of link and produce a list of new links, take a substitution and return a
% new substitution.

% In particular, due to programming constraints, we need to drag the old subst and
% return a new one extended, if needed, with the new declared meta-variables.

% The following code
% %
% \begin{elpicode}
%   kind link type.
%   type link nat -> nat -> nat -> subst.
% \end{elpicode}
% %
% \noindent
% defines a link, which is a relation between to variables indexes, the first
% being the index of a OL variable and the second being the index of a ML
% variable. The third integer\todo{integer or nat?} is the number of term in the
% scope of the two variables, or equivalently, in a typed language, their arity.

% As an example, let's study the following unification problem (a slightly
% modified version from \cref{sec:intro}):

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Uo~
%     lam x\ app [c"decision", app[uv 0, x]]
% \end{elpicode}

% \noindent
% we have the main unification problem where the nested \elpiIn{app} nodes have
% lists of different lengths making the unification to fail. The compilation of
% these terms produces a new unification problem with the following shape:

% \begin{elpicode}
%   lam x\ app[c"decision", app[c"nfact", x, c"3"]] ~\Ue~
%     lam x\ app [c"decision", uv 1 [x]]
% \end{elpicode}

% \noindent
% The main difference is the replacement of the subterm \elpiIn{app[uv 0, x]} of
% the OL with the subterm \elpiIn{uv 0 [x]}. Variable indexes are chosen by the
% ML, that is, the index \elpiIn{0} for that unification variable of the OL term
% has not the sam meaning of the index \elpiIn{0} in the ML. There exists two
% different substitution mapping, one for the OL and one for the ML and the indexes
% of variable point to the respective substitution.

% decomp che mappa abs verso lam
% \noindent
% \otext{An other example: \\
%   \elpiIn{lam x\ app[f, app[X, x]] = Y, (lam x\ x) = X.}}

% \section{Use of multivars}

% Se il termine initziale è della forma

% \begin{elpicode}
%   app[con"xxx", (lam x\ lam y\ Y y x), (lam x\ f)]
%   =
%   app[con"xxx",X,X]
% \end{elpicode}

% allora se non uso due X diverse non ho modo di recuperare il quoziente che mi manca.

% a sto punto consideriamo liste di problemi e così da eliminare sta xxx senza
% perdità di generalità (e facciamo problemi più corti, e modellizziamo anche la
% sequenza)

\section{Handling of \maybeeta}\label{sec:eta}

$\eta$-reduction is an equivalence relation over terms where a term of the form
$\lambda x.t \appsep x$ can be converted to $t$ any time $x$ does not occur as a
free variable in $t$. We call $\lambda x. t \appsep x$ the $\eta$-expanded
version of $t$. The implementation of the \elpiIn{comp} relation given in
\cref{sec:compilation} compiles the \Fo{} terms $t_1 = $\elpiIn{flam x\ fapp
[fuva A, x]} and $t_2 =$ \elpiIn{fcon "f"} into the \Ho terms $t'_1 =
$\elpiIn{lam x\ uva A' x} and $t'_2 =$ \elpiIn{fcon "f"} with mapping
\mapping{A}{A'}{1}. However, if the oracle sets \elpiIn{A'} to the constant
\elpiIn{"f"}, the unification of $t'_1$ and $t'_2$ in the meta language will
fail even though $t_1 \Eo t_2$. The reason of this failure is attributed to the
fact that $t'_1 =$\elpiIn{lam x\ app[con "f", x]} cannot be unified with $t'_2
=$\elpiIn{con "f"} since the two terms have different rigid heads. We solve this
unification problem by adapting the \elpiIn{comp} relation such that it
recognizes \maybeeta subterms $s$ and replaces them with fresh \Ho variables
$v$. This link between the variable $v$ and the subterm $t$ is stored in what we
call \linketa which is an object with the following type

\elpiIn{type link-eta tm -> tm -> baselink}

\noindent
where, as sketched in \cref{sec:lang-spec}, the term on the left hand side
(\lhs) is linked with its left counterpart (\rhs).

\linketa are added in the link store (\linkStore) and activated when special
conditions are satisfied on \lhs or \rhs. These link activations are managed by
extending the \elpiIn{progress1} predicate (see \cref{sec:execution}).
We claim that \linketa progression does not contradict \cref{inv:linklhs} and we
add the following invariant:

\begin{invariant}[\linketa \rhs]
  The \rhs of a \linketa having the shape $\lambda x.F_x$
  where $F_x$ is a term not starting with the \elpiIn{lam} constructor.
  \label{invariant:link-eta-right}
\end{invariant}

In the next three subsections we explain how we detect \maybeeta terms, how we
compile them and how \linketa are activated during the execution of the program
and provide justification for why these two invariants remain true.

\subsection{Detection of \maybeeta}

\subsection{Compilation}

\paragraph{Detection of \maybeeta} The main modification of the compiler to solve this
unification issue consists in identifying all the subterms of a term $t$ that
are \maybeeta. In particular, a term $t$ is a \maybeeta, if it can reduce to a
$\eta$-expansion under a certain substitution $\sigma$. The code verifying this
property is given below:

\input{code/maybe_eta}

The entry point is depicted by the rule~\ref{rule:maybeeta} which takes a name
$n$, a term $t$ and a list of bound variables $L$ (originally it is the
singleton containing $n$). This rule checks if $t$ is a term of the form $T
\appsep n$ (for a term $T$), together with the auxiliary predicate
\elpiIn{reducible-to} which ensures if a term $t$ can reduce to a name $n$.
\marginpar{explain better: we start from $\lambda x.F x$}
The \elpiIn{maybe-eta} predicate dispatches the calls to \elpiIn{reducible-to};
three cases should be considered: 1) $t$ is a variable $v$, then $t$ can be an
$\eta$-expansion if at least one of the terms in the scope of $v$ is a
$\maybeeta$ of $n$; 2) $t$ is a lambda-term, then we recursively call
\elpiIn{maybe-eta} on the body of $t$ under a local name $x$ which is added to
the list $L$; 3) $t$ is an application, then $t$ is an $\eta$ expansion if i)
the last arguments of $t$ can be reduced one by one to the binders in the list
$L$ (we reverse the list in rule, since, by construction, this list is built in
reversed order) and ii) none of the first arguments of the application contain a
rigid occurrence of name in $L$.

As rapidly said before, \elpiIn{reducible-to} tells if a term $t$ reduce to a
name $n$, or equivalently if $\exists \sigma, \sigma t = n$. This predicate also
takes the list of all the binders explored (this list is originally empty). A
term $t$ reduces to a name $n$ if 1) $n = t$; 2) $t$ is a variable $v$, then $t$
reduce to a $n$ if it exists an arugment in the scope of $v$ reducing to $n$ and
forall name $n'$ in $L$, there is an argument reducing to $n'$ \marginpar{Note
that this function is partial: the arg in the scope should be distinct}; 3) $t$
is a lambda abstraction, then we call recursively \elpiIn{reducible-to} on the
body of the abstraction with a new local name added to the list $L$; 4) $t$ is
an application of $n$ to a list of arguments $L'$, then all the arguments should
reduce to the respective name in the list $L$.

Finally, a name $n$ occurs rigidly in a term $t$ if $n$ occurs in a subterm $t'$
of $t$ such that $t'$ does not appear in the scope of a variable.

An example of \maybeeta detection over the bound variable $x$ is the following:
\marginpar{maybe more examples in appendix}
%
\begin{gather}
  T = \lambda y. f \appsep A_{xy} \appsep (B \appsep a \appsep (\lambda z.y\appsep C_z)) \appsep D_x
\end{gather}

The correct call to \elpiIn{maybe-eta} is \elpiIn{maybe-eta x T L} with
\elpiIn{L = [x]}. At first we go under the abstraction $\lambda y$ adding $y$ to
$L$. Then we find an application, where we verify that 1) $A_{xy}$ does not
contain $x$ and $y$ rigidly which is the case; 2) $B \appsep a \appsep (\lambda z.y\appsep (C_z))$
and $D_x$ can respectively reduce to $y$ and $x$. The latter reduction is
evident, since $D$ has $x$ in scope; the former subterm can reduce to $y$ since
$B$ is a variable and it exists an argument ($\lambda z.y\appsep C_z$) reducible to
$y$: under the binder $z$, we have the application of $y$ with a variable with
$z$ in scope. Note that \maybeeta, only tells if it exists a substitution making
a term an eta expansion on any term $t$, i.e, $t$ can be in $\maybeeta \cup
\maybebeta$ without the constraint of being in \llambda, as our example shows. A
possible substitution making the term $T$ in the example an $\eta$-expansion is
$\sigma = \{A \mapsto \lambda x.\lambda y.a, B \mapsto \lambda x.\lambda y.y,
C \mapsto \lambda x.x, D \mapsto \lambda x.x\}$.

\paragraph{Compilation with \linketa} Thanks to the \elpiIn{maybe-eta}
predicate, we can detect ``$\eta$-problematic'' terms and, consequently replace
them with a fresh \Ho unification variable at compilation time. The code
below illustrate this dedicated compilation:
% TODO: maybe ref to \cref{sec:nutshell}

\input{code/comp_eta}

\marginpar{Where This rule is put in the code ?}
This rule is applied on \Fo{} lambda-abstractions, tests if their body $F$ is an
\maybeeta wrt to a local fresh binder $x$, and if so, it compiles $F$ to the \Ho
term \elpiIn{F1} and returns a \Ho fresh variable $A$ having in scope the free
names occurring in \elpiIn{F1}. As sketch at the very end of
\cref{sec:lang-spec}, each time a subterm $t$ in \Fo is replaced with a \Ho
variable $v$, we build a \elpiIn{link-eta} between $v$ and and the term $t'$
obtained by the compilation of $t$.

A \elpiIn{link-eta}\footnote{\elpiIn{@val-link-eta A B} is syntactic sugar for
\elpiIn{val (link-eta A B)}}
is defined as

\elpiIn{type link-eta tm -> tm -> baselink}


\noindent
We call the two terms carried by the link respectively left and right hand side,
called respectively \lhs and \rhs.

\subsection{Progress}

\linketa are meant to suspend the unification of two terms, that is, if we have
a \maybeeta term $t$ which should be unified with a term $t'$ we don't want to
unify them with \Ue. As said before this would break unification but it can also
introduce \maybeeta in the substitution of \Ho.

In order to activate a \linketa, we need to implement new rules for the
\elpiIn{progress1} predicate. There are two cases making a \linketa to progress,
1) \lhs is instantiated to a rigid term, in this case \lhs is unified with \rhs.
TODO: the right eta hand side is eta-expanbded if it is an app/con; 2) \rhs can
be $\eta$-reduced to a term with rigid head, in this case \lhs and \rhs are
again unified. If one of these two condition is satisfied, the link has
fulfilled is task and can be removed from the list of suspended links; if none
the condition succeeds, the link is kept for a further iteration of
\elpiIn{progress}.

TODO: dire che scendiamo sotto i vari abs che formano il contesto? 
TODO: example for case 1: $\lambda x. \lambda y. F \appsep y \appsep x = f$
TODO: example for case 2: $\lambda x. \lambda y. F \appsep y \appsep x = G, F = \lambda x. \lambda y. a$

A second way to progress \linketa, that we call \linketa deduplication, is to
check if \linkStore contains two \linketa $l_1$ and $l_2$ with same \lhs. This
situation occurs if two \maybeeta terms are unified with a same unification
variable. In this case, we can unify the $l_1$ and $l_2$ \rhs (that, by
construction are both on the form $\lambda x. T_x$) and remove one of the two
links.

TODO: example for this: $\lambda x. \lambda y. F \appsep y \appsep x = X,
\lambda x. \lambda y. F \appsep y \appsep x = Y$

We can note that the 1) insertion of these rules for \elpiIn{progress1} do not
prevent the termination of \elpiIn{progress}, since, a link activation runs
terminating operations (such as term unification and link-removal); 2) \linketa
deduplication runs again terminating operations and 3) if none of these two 
situations is performed, then the substitution and \linkStore
Note that if the link remain suspended \elpiIn{progress} continues to terminate,
since, it would mean that the condition of the \elpiIn{if}-branchement succeds
and the \elpiIn{progress} terminates its execution.


\begin{lemma}
  We never add eta-expansions in the substitution
\end{lemma}

\begin{proof}[Proof sketch]
\end{proof}



TODO: we can however have $\lambda x. F_x$ if we know that $F$ does not reduce
to $T x$ where x is not free in $T$.

\section{Enforcing Invariant~\ref{invariant:arity}}
\label{sec:invariant1}
Deduplicate mapping code etc...
  
\section{Handling of \maybebeta}\label{sec:beta}

$\beta$-reduction problems (\maybebeta) appears any time we deal with a subterm $t
= X t_1 \dots t_n$, where $X$ is flexible and the list $[t_1 \dots t_n]$ in not
in \llambda. This unification problem is not solvable without loss of
generality, since there is not a most general unifier. If we take back the
example given in \cref{sec:nutshell}, the unification $F a = a$ admits two solutions for $F$:
$\rho_1 = \{F \mapsto \lambda x.x\}$ and $\rho_2 = \{F \mapsto \lambda \_.a\}$.
Despite this, it is possible to work with $\maybebeta$ if an oracle provides a
substitution $\rho$ such that $\rho t$ falls again in the \llambda.

On the other hand, the \Ue is not designed to understand how the $\beta$-redexes
work in the object language. Therefore, even if we know that $F$ is assigned
to $\lambda x.x$, \Ue is not able to unify $F a$ with $a$. On the other hand,
the problem $F a = G$ is solvable by \Ue, but the final result is that $G$ is
assigned to $(\lambda x.x) a$ which breaks the invariant saying that the
substitution of the meta language does not generate terms outide \wellb{} (Property \ref{prop:nf}).

The solution to this problem is to modify the compiler such that any sub-term $t$
considered as a potential $\beta$-redex is replaced with a hole $h$ and a new dedicated
link, called \linkbeta.

\begin{elpicode}
  type link-beta tm -> tm -> link.
\end{elpicode}

\def\rhs{\ensuremath{rhs}\xspace}
\def\lhs{\ensuremath{lhs}\xspace}

This link carries two terms, the former representing the variable $h$ for the
new created hole and the latter containing the subterm $t$. As for the \linketa,
we will call $h$ and $t$ respectively the left hand side (\lhs)
and the right hand side (\rhs) of the \linkbeta.

\subsection{Compilation}

\paragraph{Detection of \maybebeta} TODO: \dots

\paragraph{Compilation with \linkbeta}

In order to build a \linkbeta, we need to adapt the compiler so that it can
recognize these ``problematic'' subterms. The following code snippet illustrate
such behavior, we suppose the rule to be added just after \cref{rule:comp-pf}.

\input{code/comp_beta}

A term is \maybebeta if it has the shape \elpiIn{fapp[fuva A|Ag]} and
\elpiIn{distinct Ag} does not hold. In that case, \elpiIn{Ag} is split in two
sublist \elpiIn{Pf} and \elpiIn{Extra} such that former is the longest prefix of
\elpiIn{Ag} such that \elpiIn{distinct Pf} holds. \elpiIn{Extra} is the list
such that \elpiIn{append Pf Extra Ag}. Next important step is to compile
recursively the terms of these lists and allocate a memory adress \elpiIn{B}
from the substitution in order to map the \Fo variable \elpiIn{fuva A} to
the \Ho variable \elpiIn{uva B}. The \linkbeta to return in the end is given
by the term \elpiIn{Beta = app[uva B Scope1 | Extra1]} constituting the \rhs,
and a fresh variable \elpiIn{C} having in scope all the free variables occurring
in \elpiIn{Beta} (this is \lhs). We point out that the \rhs is intentionally
built as an \elpiIn{uva} where \elpiIn{Extra1} are not in scope, since by
invariant, we want all the variables appearing in \Ho to be in \llambda.

\subsection{Progress}

Once created, there exist two main situations waking up a suspended \linkbeta.
The former is strictly connected to the definition of $\beta$-redex and occurs
when the head of \rhs is materialized by the oracle (see
\cref{prop:simulation}). In this case \rhs is safely\marginpar{explain why}
$\beta$-reduced to a new term $t'$ and the result can be unified with \lhs. In
this scenario the \linkbeta has accomplished its goal and can be removed from
\linkStore.

The second circumstance making the \linkbeta to progress is the instantiation of
the variables in the \elpiIn{Extra1} making the corresponding arguments to
reduce to names. In this case, we want to take the list \elpiIn{Scope1} and
append to it the largest prefix of \elpiIn{Extra1} in a new variable
\elpiIn{Scope2} such that \elpiIn{Scope2} remains in \llambda; we call
\elpiIn{Extra2} the suffix of \elpiIn{Extra1} such that the concatenation of
\elpiIn{Scope1} and \elpiIn{Extra1} is the same as the concatenation of
\elpiIn{Scope2} and \elpiIn{Extra2}. Finally, two cases should be considered: 1)
\elpiIn{Extra2} is the empty list, \lhs and rhs can be unified: we have two
terms in \llambda; otherwise 2) the \linkbeta in question is replaced with a
refined version where the \rhs is  \elpiIn{app[uva C Scope2 | Extra2]} and a new
\linketa is added between the \lhs and the new-added variable \elpiIn{C}.
\marginpar{dire che si adatta bene nelle approximation}

An example justifying this second  link manipulation is given by the following
unification problem:

\def\varF{\ensuremath{\textbf{F}}\xspace}
\def\varA{\ensuremath{\textbf{A}}\xspace}
\def\varB{\ensuremath{\textbf{B}}\xspace}

\begin{elpicode}
  f = flam x\ fapp[F, fapp[A, x]].
\end{elpicode}

% \begin{elpicode};
%   f = flam x\ flam y\ fapp[F, fapp[A, x], fapp[B, y]].
% \end{elpicode}

The compilation of these terms produces the new unification problem: $f = X0$

We obtain the mappings $\mapping{F}{\varF}{0}, \mapping{A}{\varA}{1}$ and the links:
%
\begin{gather}
  \linkbetaM{c0}{X3_{c0}}{X2~X1_{c0}}\\
  \linketaM{}{X0}{\lambda c0.X3_{c0}}
\end{gather}

\noindent
where the first link is a \linketa between the variable \texttt{X0}, representing
the right side of the unification problem (it is a \maybeeta) and
\texttt{X3}; and a \linkbeta between the variable \texttt{X3} and the subterm
$\lambda x.X1_x ~ a$ (it is a \maybebeta).
The substitution tells that \substCell{x}{X1_x}{x}.

We can now represent the \hrun execution from this configuration which will, at
first, dereference all the links, and then try to solve them. The only link
being modified is the second one, which is set to \linkbetaM{x}{X3}{X2 x a}. The
\rhs of the link has now a variable which is partially in the PF, we can
therefore remove the original \linkbeta and replace it with the following couple
on links:

\begin{textcode}
  ~$\vdash$~ X1   =~$\eta$~= x\ `X4 x'
x ~$\vdash$~ X3 x =~$\beta$~= x\ `X4 x' a
\end{textcode}

By these links we say that \texttt{X1} is now $\eta$-linked to a fresh variable
\texttt{X4} with arity one. This new variable is used in the new \linkbeta where
the name \texttt{x} is in its scope. This allows

\subsection{Tricky examples}

\begin{elpicode}
  triple ok (@lam x\ @app[@f, @app[@X, x]]) @Y,
  triple ok @X (@lam x\ x),
  triple ok @Y @f
\end{elpicode}

\begin{elpicode}
% @okl 22 [
%   triple ok (@lam x\ @lam y\ @app[@Y, y, x]) @X,
%   triple ok (@lam x\ @f) @X,
% ].
\end{elpicode}

\section{First order approximation}

\otext{Coq can solve this: \coqIn{f 1 2 = X 2}, by setting X to f 1}
\otext{We can re-use part of the algo for $\beta$ given before}


\section{Unif encoding in real life}
\otext{Il ML presentato qui è esattamente elpi}
\otext{Il OL presentato qui è esattamente coq}
\otext{Come implementatiamo tutto ciò nel solver}

\section{Results: stdpp and tlc}
\otext{How may rule are we solving?}
\otext{Can we do some perf test}

\section{Conclusion}

\printbibliography

\clearpage

\input{appendix.tex}

\end{document}